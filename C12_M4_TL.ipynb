{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Environment Setup"
      ],
      "metadata": {
        "id": "1xYX7QszxC9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As necessary, install the required Python packages"
      ],
      "metadata": {
        "id": "IOQaubgDxEhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHstEYgv3jk",
        "outputId": "fa33f586-7436-4ade-88c1-e714a3126e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.22.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.22.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.52.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.2.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn mlflow flask scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core data and ML libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pickle\n",
        "import os\n",
        "import datetime\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import logging\n",
        "import uuid\n",
        "\n",
        "# For model registry and experiment tracking\n",
        "import mlflow\n",
        "\n",
        "# For model serving\n",
        "import flask\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# For drift detection and monitoring\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "674U5eQlxPXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Intake & Feature Management"
      ],
      "metadata": {
        "id": "yCYEFto3xSY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Data Collection"
      ],
      "metadata": {
        "id": "9lr4cl1nxTbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download and load the dataset\n",
        "def get_raw_data():\n",
        "    \"\"\"\n",
        "    Downloads the telco churn dataset or loads it if already exists\n",
        "    Returns the raw dataframe\n",
        "    \"\"\"\n",
        "    # In a real scenario, this might be pulling from a database or API\n",
        "    # For this example, we'll use a local CSV file or download it if it doesn't exist\n",
        "\n",
        "    # Create data directory if it doesn't exist\n",
        "    data_dir = Path(\"data\")\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    raw_data_path = data_dir / \"telco_churn_raw.csv\"\n",
        "\n",
        "    # Check if we already have the file\n",
        "    if not raw_data_path.exists():\n",
        "        # If not, we'll create a simple synthetic dataset\n",
        "        print(\"Creating synthetic telco churn dataset...\")\n",
        "\n",
        "        # Create synthetic data\n",
        "        np.random.seed(42)\n",
        "        n_samples = 1000\n",
        "\n",
        "        # Generate synthetic features\n",
        "        data = {\n",
        "            'customer_id': [f'CUST-{i:05d}' for i in range(n_samples)],\n",
        "            'gender': np.random.choice(['Male', 'Female'], size=n_samples),\n",
        "            'senior_citizen': np.random.choice([0, 1], size=n_samples),\n",
        "            'partner': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'dependents': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'tenure': np.random.randint(0, 72, size=n_samples),\n",
        "            'phone_service': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'multiple_lines': np.random.choice(['Yes', 'No', 'No phone service'], size=n_samples),\n",
        "            'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], size=n_samples),\n",
        "            'online_security': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'online_backup': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'streaming_tv': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'streaming_movies': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], size=n_samples),\n",
        "            'paperless_billing': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'payment_method': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], size=n_samples),\n",
        "            'monthly_charges': np.random.uniform(20, 120, size=n_samples),\n",
        "            'total_charges': np.random.uniform(100, 8000, size=n_samples),\n",
        "        }\n",
        "\n",
        "        # Churn is more likely for month-to-month contracts and high monthly charges\n",
        "        probabilities = []\n",
        "        for i in range(n_samples):\n",
        "            prob = 0.2  # Base probability\n",
        "            if data['contract'][i] == 'Month-to-month':\n",
        "                prob += 0.2\n",
        "            if data['monthly_charges'][i] > 80:\n",
        "                prob += 0.15\n",
        "            if data['tenure'][i] < 12:\n",
        "                prob += 0.15\n",
        "            probabilities.append(min(prob, 0.9))\n",
        "\n",
        "        data['churn'] = np.random.binomial(1, probabilities)\n",
        "        data['churn'] = ['Yes' if x == 1 else 'No' for x in data['churn']]\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(raw_data_path, index=False)\n",
        "        print(f\"Dataset saved to {raw_data_path}\")\n",
        "    else:\n",
        "        print(f\"Loading dataset from {raw_data_path}\")\n",
        "        df = pd.DataFrame(pd.read_csv(raw_data_path))\n",
        "\n",
        "    # Record data intake in our log\n",
        "    logging.basicConfig(filename='mlops_pipeline.log', level=logging.INFO)\n",
        "    logging.info(f\"Data ingested at {datetime.datetime.now()}: {len(df)} records\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the raw data\n",
        "raw_data = get_raw_data()\n",
        "\n",
        "# Display first few rows\n",
        "print(f\"Loaded {len(raw_data)} rows\")\n",
        "raw_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "w9w6gwKtxVrf",
        "outputId": "57041b08-e4bf-4901-ed39-dadfc1382952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from data/telco_churn_raw.csv\n",
            "Loaded 1000 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  customer_id  gender  senior_citizen partner dependents  tenure  \\\n",
              "0  CUST-00000    Male               1     Yes         No       6   \n",
              "1  CUST-00001  Female               0      No         No      34   \n",
              "2  CUST-00002    Male               0      No         No      54   \n",
              "3  CUST-00003    Male               0      No         No      13   \n",
              "4  CUST-00004    Male               0      No        Yes       9   \n",
              "\n",
              "  phone_service    multiple_lines internet_service      online_security  \\\n",
              "0            No               Yes               No                  Yes   \n",
              "1            No  No phone service      Fiber optic  No internet service   \n",
              "2           Yes  No phone service               No                  Yes   \n",
              "3            No  No phone service      Fiber optic                  Yes   \n",
              "4            No  No phone service               No                  Yes   \n",
              "\n",
              "         online_backup         tech_support streaming_tv     streaming_movies  \\\n",
              "0                  Yes  No internet service          Yes                  Yes   \n",
              "1                  Yes                   No           No                   No   \n",
              "2                  Yes  No internet service           No                  Yes   \n",
              "3                   No                  Yes           No  No internet service   \n",
              "4  No internet service  No internet service          Yes                   No   \n",
              "\n",
              "         contract paperless_billing    payment_method  monthly_charges  \\\n",
              "0        Two year                No     Bank transfer        26.875095   \n",
              "1        One year               Yes       Credit card        70.739409   \n",
              "2  Month-to-month                No       Credit card        52.891978   \n",
              "3        One year               Yes  Electronic check        70.831169   \n",
              "4  Month-to-month               Yes       Credit card        22.397545   \n",
              "\n",
              "   total_charges churn  \n",
              "0    4951.885351    No  \n",
              "1    1586.779855    No  \n",
              "2    2353.696176    No  \n",
              "3    3859.820909    No  \n",
              "4    7639.333018   Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>senior_citizen</th>\n",
              "      <th>partner</th>\n",
              "      <th>dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>phone_service</th>\n",
              "      <th>multiple_lines</th>\n",
              "      <th>internet_service</th>\n",
              "      <th>online_security</th>\n",
              "      <th>online_backup</th>\n",
              "      <th>tech_support</th>\n",
              "      <th>streaming_tv</th>\n",
              "      <th>streaming_movies</th>\n",
              "      <th>contract</th>\n",
              "      <th>paperless_billing</th>\n",
              "      <th>payment_method</th>\n",
              "      <th>monthly_charges</th>\n",
              "      <th>total_charges</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUST-00000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer</td>\n",
              "      <td>26.875095</td>\n",
              "      <td>4951.885351</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CUST-00001</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>70.739409</td>\n",
              "      <td>1586.779855</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUST-00002</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>54</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>52.891978</td>\n",
              "      <td>2353.696176</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CUST-00003</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>13</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.831169</td>\n",
              "      <td>3859.820909</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CUST-00004</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>22.397545</td>\n",
              "      <td>7639.333018</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_data",
              "summary": "{\n  \"name\": \"raw_data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"CUST-00521\",\n          \"CUST-00737\",\n          \"CUST-00740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senior_citizen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partner\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dependents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 71,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          9,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_lines\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No phone service\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"internet_service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"No\",\n          \"Fiber optic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"online_security\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No internet service\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"online_backup\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tech_support\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"No internet service\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"streaming_tv\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"streaming_movies\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Two year\",\n          \"One year\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paperless_billing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payment_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Credit card\",\n          \"Mailed check\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"monthly_charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.8709966659831,\n        \"min\": 20.02408745178665,\n        \"max\": 119.95051897085165,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          40.146149579316045,\n          113.7987865459497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2270.0411316649793,\n        \"min\": 119.39123290636934,\n        \"max\": 7997.418321412529,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          3955.675234530337,\n          3385.7406101684564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"churn\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Data Versioning"
      ],
      "metadata": {
        "id": "q9Mr1p4bxZPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_versioned_dataset(df, version=None):\n",
        "    \"\"\"\n",
        "    Create a versioned snapshot of the dataset\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to version\n",
        "        version: Version string (if None, a timestamp will be used)\n",
        "\n",
        "    Returns:\n",
        "        version: The version string used\n",
        "        path: Path to the saved versioned data\n",
        "    \"\"\"\n",
        "    # Create versioned data directory\n",
        "    versioned_data_dir = Path(\"data/versioned\")\n",
        "    versioned_data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Generate version if not provided\n",
        "    if version is None:\n",
        "        version = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save versioned data\n",
        "    versioned_path = versioned_data_dir / f\"telco_data_v{version}.csv\"\n",
        "    df.to_csv(versioned_path, index=False)\n",
        "\n",
        "    # Save version metadata\n",
        "    metadata = {\n",
        "        \"version\": version,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows\": len(df),\n",
        "        \"num_features\": len(df.columns),\n",
        "        \"feature_names\": list(df.columns),\n",
        "        \"description\": f\"Telco churn data version {version}\"\n",
        "    }\n",
        "\n",
        "    metadata_path = versioned_data_dir / f\"telco_data_v{version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    print(f\"Created versioned dataset {version} at {versioned_path}\")\n",
        "    logging.info(f\"Created versioned dataset {version} with {len(df)} records at {datetime.datetime.now()}\")\n",
        "\n",
        "    return version, versioned_path\n",
        "\n",
        "# Create a versioned snapshot of our raw data\n",
        "initial_version, versioned_raw_path = create_versioned_dataset(raw_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7MVkufMxjSa",
        "outputId": "e2e84e34-7597-490a-853c-79d42ab9455d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created versioned dataset 20250512_172103 at data/versioned/telco_data_v20250512_172103.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Data Cleaning and Validation"
      ],
      "metadata": {
        "id": "bz9vWnRpxgwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_validate_data(df, version):\n",
        "    \"\"\"\n",
        "    Clean and validate the data\n",
        "\n",
        "    Args:\n",
        "        df: Raw DataFrame\n",
        "        version: Version string for tracking\n",
        "\n",
        "    Returns:\n",
        "        cleaned_df: Cleaned DataFrame\n",
        "        validation_report: Dictionary with validation results\n",
        "    \"\"\"\n",
        "    print(f\"Cleaning and validating data version {version}...\")\n",
        "\n",
        "    # Create a copy to avoid modifying the original\n",
        "    df_cleaned = df.copy()\n",
        "\n",
        "    # Track cleaning operations\n",
        "    cleaning_ops = []\n",
        "    validation_issues = []\n",
        "\n",
        "    # Check for and handle missing values\n",
        "    missing_values = df_cleaned.isnull().sum()\n",
        "    if missing_values.sum() > 0:\n",
        "        cleaning_ops.append(f\"Found {missing_values.sum()} missing values\")\n",
        "        for col in missing_values[missing_values > 0].index:\n",
        "            cleaning_ops.append(f\"Column {col} has {missing_values[col]} missing values\")\n",
        "\n",
        "            # Handle missing values based on data type\n",
        "            if df_cleaned[col].dtype == 'object':\n",
        "                # For categorical, fill with mode\n",
        "                df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].mode()[0])\n",
        "                cleaning_ops.append(f\"Filled missing values in {col} with mode: {df_cleaned[col].mode()[0]}\")\n",
        "            else:\n",
        "                # For numerical, fill with median\n",
        "                df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
        "                cleaning_ops.append(f\"Filled missing values in {col} with median: {df_cleaned[col].median()}\")\n",
        "\n",
        "    # Handle TotalCharges - convert to numeric if string\n",
        "    if df_cleaned['total_charges'].dtype == 'object':\n",
        "        cleaning_ops.append(\"Converting total_charges to numeric\")\n",
        "        df_cleaned['total_charges'] = pd.to_numeric(df_cleaned['total_charges'], errors='coerce')\n",
        "        # Fill any new missing values\n",
        "        df_cleaned['total_charges'] = df_cleaned['total_charges'].fillna(df_cleaned['total_charges'].median())\n",
        "\n",
        "    # Data validation checks\n",
        "\n",
        "    # 1. Check for negative values in numerical columns that should be positive\n",
        "    for col in ['tenure', 'monthly_charges', 'total_charges']:\n",
        "        neg_values = (df_cleaned[col] < 0).sum()\n",
        "        if neg_values > 0:\n",
        "            validation_issues.append(f\"Found {neg_values} negative values in {col}\")\n",
        "            # Replace with absolute value\n",
        "            df_cleaned[col] = df_cleaned[col].abs()\n",
        "            cleaning_ops.append(f\"Converted {neg_values} negative values to positive in {col}\")\n",
        "\n",
        "    # 2. Check for logical consistency\n",
        "    if 'tenure' in df_cleaned.columns and 'total_charges' in df_cleaned.columns:\n",
        "        inconsistent = ((df_cleaned['tenure'] > 0) & (df_cleaned['total_charges'] <= 0)).sum()\n",
        "        if inconsistent > 0:\n",
        "            validation_issues.append(f\"Found {inconsistent} rows with tenure > 0 but total_charges <= 0\")\n",
        "            # Fix by setting total_charges to at least monthly_charges\n",
        "            mask = (df_cleaned['tenure'] > 0) & (df_cleaned['total_charges'] <= 0)\n",
        "            df_cleaned.loc[mask, 'total_charges'] = df_cleaned.loc[mask, 'monthly_charges']\n",
        "            cleaning_ops.append(f\"Fixed {inconsistent} rows with inconsistent tenure and total_charges\")\n",
        "\n",
        "    # 3. Check categorical variable validity\n",
        "    for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
        "        if col == 'customer_id':  # Skip ID column\n",
        "            continue\n",
        "\n",
        "        # Count unique values\n",
        "        unique_values = df_cleaned[col].unique()\n",
        "        cleaning_ops.append(f\"Column {col} has {len(unique_values)} unique values: {unique_values}\")\n",
        "\n",
        "        # If binary Yes/No column has other values\n",
        "        if set(df_cleaned[col].unique()) - set(['Yes', 'No', 'No internet service', 'No phone service']):\n",
        "            unexpected = set(df_cleaned[col].unique()) - set(['Yes', 'No', 'No internet service', 'No phone service'])\n",
        "            validation_issues.append(f\"Column {col} has unexpected values: {unexpected}\")\n",
        "\n",
        "    # Create validation report\n",
        "    validation_report = {\n",
        "        \"data_version\": version,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows_before\": len(df),\n",
        "        \"num_rows_after\": len(df_cleaned),\n",
        "        \"cleaning_operations\": cleaning_ops,\n",
        "        \"validation_issues\": validation_issues,\n",
        "        \"columns\": list(df_cleaned.columns),\n",
        "        \"dtypes\": {col: str(df_cleaned[col].dtype) for col in df_cleaned.columns}\n",
        "    }\n",
        "\n",
        "    # Save validation report\n",
        "    validation_dir = Path(\"data/validation_reports\")\n",
        "    validation_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    validation_path = validation_dir / f\"validation_report_v{version}.json\"\n",
        "    with open(validation_path, 'w') as f:\n",
        "        json.dump(validation_report, f, indent=2)\n",
        "\n",
        "    print(f\"Data cleaning and validation complete. Report saved to {validation_path}\")\n",
        "\n",
        "    return df_cleaned, validation_report\n",
        "\n",
        "# Clean and validate our data\n",
        "cleaned_data, validation_report = clean_and_validate_data(raw_data, initial_version)\n",
        "\n",
        "# Display validation results summary\n",
        "print(\"\\nValidation Summary:\")\n",
        "print(f\"- Cleaning operations: {len(validation_report['cleaning_operations'])}\")\n",
        "print(f\"- Validation issues: {len(validation_report['validation_issues'])}\")\n",
        "if validation_report['validation_issues']:\n",
        "    for issue in validation_report['validation_issues']:\n",
        "        print(f\"  - {issue}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8V8-yVQxkOd",
        "outputId": "deda0287-70ae-4f76-db81-0434c32ac886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning and validating data version 20250512_172103...\n",
            "Data cleaning and validation complete. Report saved to data/validation_reports/validation_report_v20250512_172103.json\n",
            "\n",
            "Validation Summary:\n",
            "- Cleaning operations: 15\n",
            "- Validation issues: 4\n",
            "  - Column gender has unexpected values: {'Male', 'Female'}\n",
            "  - Column internet_service has unexpected values: {'DSL', 'Fiber optic'}\n",
            "  - Column contract has unexpected values: {'One year', 'Two year', 'Month-to-month'}\n",
            "  - Column payment_method has unexpected values: {'Electronic check', 'Bank transfer', 'Mailed check', 'Credit card'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Feature Engineering and Storage"
      ],
      "metadata": {
        "id": "GVkqe6uUxnue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df, version):\n",
        "    \"\"\"\n",
        "    Apply feature engineering transformations\n",
        "\n",
        "    Args:\n",
        "        df: Cleaned DataFrame\n",
        "        version: Version string for tracking\n",
        "\n",
        "    Returns:\n",
        "        features_df: DataFrame with engineered features\n",
        "        feature_metadata: Dictionary with feature metadata\n",
        "    \"\"\"\n",
        "    print(f\"Engineering features for data version {version}...\")\n",
        "\n",
        "    # Create a copy to avoid modifying the original\n",
        "    features_df = df.copy()\n",
        "\n",
        "    # Track feature engineering operations\n",
        "    feature_ops = []\n",
        "\n",
        "    # 1. Convert binary categorical variables to 0/1\n",
        "    binary_columns = ['partner', 'dependents', 'phone_service', 'paperless_billing']\n",
        "    for col in binary_columns:\n",
        "        if col in features_df.columns:\n",
        "            features_df[col] = features_df[col].map({'Yes': 1, 'No': 0})\n",
        "            feature_ops.append(f\"Converted {col} to binary 0/1\")\n",
        "\n",
        "    # 2. Create tenure-related features\n",
        "    if 'tenure' in features_df.columns:\n",
        "        # Tenure in years\n",
        "        features_df['tenure_years'] = features_df['tenure'] / 12\n",
        "        feature_ops.append(\"Created tenure_years feature\")\n",
        "\n",
        "        # Tenure bins\n",
        "        tenure_bins = [0, 12, 24, 36, 48, 60, 72]\n",
        "        tenure_labels = ['0-1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5+ years']\n",
        "        features_df['tenure_group'] = pd.cut(features_df['tenure'], bins=tenure_bins, labels=tenure_labels, right=False)\n",
        "        feature_ops.append(\"Created tenure_group feature with 6 bins\")\n",
        "\n",
        "    # 3. Create price-related features\n",
        "    if 'monthly_charges' in features_df.columns and 'tenure' in features_df.columns:\n",
        "        # Average charge per month of tenure\n",
        "        mask = features_df['tenure'] > 0  # Avoid division by zero\n",
        "        features_df['avg_monthly_charges'] = 0\n",
        "        features_df.loc[mask, 'avg_monthly_charges'] = features_df.loc[mask, 'total_charges'] / features_df.loc[mask, 'tenure']\n",
        "        feature_ops.append(\"Created avg_monthly_charges feature\")\n",
        "\n",
        "        # Monthly charges bin\n",
        "        charge_bins = [0, 35, 70, 105, float('inf')]\n",
        "        charge_labels = ['Low', 'Medium', 'High', 'Very High']\n",
        "        features_df['monthly_charges_category'] = pd.cut(features_df['monthly_charges'], bins=charge_bins, labels=charge_labels)\n",
        "        feature_ops.append(\"Created monthly_charges_category feature with 4 bins\")\n",
        "\n",
        "    # 4. Services count feature\n",
        "    service_columns = ['phone_service', 'multiple_lines', 'internet_service', 'online_security',\n",
        "                       'online_backup', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
        "\n",
        "    # Initialize services count\n",
        "    features_df['services_count'] = 0\n",
        "\n",
        "    # Count 'Yes' values\n",
        "    for col in service_columns:\n",
        "        if col in features_df.columns:\n",
        "            features_df['services_count'] += (features_df[col] == 'Yes').astype(int)\n",
        "\n",
        "    feature_ops.append(\"Created services_count feature\")\n",
        "\n",
        "    # 5. Contract type as ordinal\n",
        "    if 'contract' in features_df.columns:\n",
        "        contract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
        "        features_df['contract_type_code'] = features_df['contract'].map(contract_map)\n",
        "        feature_ops.append(\"Created contract_type_code feature\")\n",
        "\n",
        "    # 6. Target encoding for churn prediction\n",
        "    features_df['churn_binary'] = features_df['churn'].map({'Yes': 1, 'No': 0})\n",
        "    feature_ops.append(\"Created churn_binary feature for target\")\n",
        "\n",
        "    # Create feature metadata\n",
        "    feature_metadata = {\n",
        "        \"data_version\": version,\n",
        "        \"feature_version\": f\"{version}_feat\",\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows\": len(features_df),\n",
        "        \"num_features\": len(features_df.columns),\n",
        "        \"feature_engineering_ops\": feature_ops,\n",
        "        \"numerical_features\": list(features_df.select_dtypes(include=['int64', 'float64']).columns),\n",
        "        \"categorical_features\": list(features_df.select_dtypes(include=['object']).columns),\n",
        "        \"binary_features\": [col for col in features_df.columns if features_df[col].nunique() == 2],\n",
        "        \"target_feature\": \"churn_binary\"\n",
        "    }\n",
        "\n",
        "    # Save engineered features\n",
        "    features_dir = Path(\"data/features\")\n",
        "    features_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    features_path = features_dir / f\"telco_features_v{version}.csv\"\n",
        "    features_df.to_csv(features_path, index=False)\n",
        "\n",
        "    # Save feature metadata\n",
        "    metadata_path = features_dir / f\"telco_features_v{version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(feature_metadata, f, indent=2)\n",
        "\n",
        "    print(f\"Feature engineering complete. Features saved to {features_path}\")\n",
        "    logging.info(f\"Feature engineering completed for version {version} at {datetime.datetime.now()}\")\n",
        "\n",
        "    return features_df, feature_metadata\n",
        "\n",
        "# Engineer features\n",
        "features_df, feature_metadata = engineer_features(cleaned_data, initial_version)\n",
        "\n",
        "# Display feature summary\n",
        "print(\"\\nFeature Engineering Summary:\")\n",
        "print(f\"- Original features: {len(raw_data.columns)}\")\n",
        "print(f\"- Engineered features: {len(features_df.columns)}\")\n",
        "print(f\"- New features added: {len(features_df.columns) - len(raw_data.columns)}\")\n",
        "\n",
        "# Display sample of engineered features\n",
        "features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYjuAijDxkTa",
        "outputId": "5ac77925-5522-4633-9fb3-78b378470f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engineering features for data version 20250512_172103...\n",
            "Feature engineering complete. Features saved to data/features/telco_features_v20250512_172103.csv\n",
            "\n",
            "Feature Engineering Summary:\n",
            "- Original features: 20\n",
            "- Engineered features: 27\n",
            "- New features added: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-71cee673866d>:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[8.25314225e+02 4.66699957e+01 4.35869662e+01 2.96909301e+02\n",
            " 8.48814780e+02 1.36938389e+02 1.10943446e+02 5.17629125e+01\n",
            " 5.70463733e+01 8.41303614e+01 1.20460558e+01 1.14457683e+02\n",
            " 1.01104262e+02 8.70262056e+01 1.30602476e+01 2.38914956e+02\n",
            " 2.70803064e+02 1.02516846e+02 4.63917025e+02 2.49873981e+02\n",
            " 2.03965064e+02 4.17602759e+02 6.44385998e+01 2.22358440e+01\n",
            " 1.80014994e+02 3.43760298e+01 3.14326101e+02 6.61805600e+01\n",
            " 8.49066538e+01 1.40251790e+02 7.63303226e+01 2.66563425e+02\n",
            " 1.49680606e+01 2.24232317e+03 6.58049809e+01 1.56820644e+02\n",
            " 3.40020337e+02 7.07533128e+02 6.61154918e+00 5.88138021e+01\n",
            " 5.13699511e+01 3.83920897e+00 3.00652727e+01 7.80332896e+01\n",
            " 6.01750777e+01 1.79179444e+02 1.18562718e+02 9.30114595e+01\n",
            " 1.19169246e+02 5.33772740e+01 8.81026888e+01 3.74656846e+01\n",
            " 1.34437002e+02 6.20168181e+01 4.27105391e+02 8.80690727e+01\n",
            " 7.13486086e+01 4.65187119e+01 4.39615368e+02 6.23159973e+03\n",
            " 1.87744375e+02 3.34915232e+01 2.52596840e+01 9.37778097e+01\n",
            " 1.24791469e+02 5.02368096e+01 1.09242920e+02 9.91139527e+01\n",
            " 7.93038323e+01 1.21198685e+02 7.72800487e+02 5.81508090e+01\n",
            " 3.57086098e+00 7.22688764e+01 7.76020468e+01 1.45365858e+02\n",
            " 8.74259206e+02 6.58599143e+01 2.74085646e+02 6.17179115e+01\n",
            " 8.99871559e+01 1.98485153e+02 4.39090302e+02 1.83899320e+01\n",
            " 8.51819026e+01 9.94696969e+01 7.00843363e+01 2.55310706e+02\n",
            " 8.19864499e+01 7.29498154e+01 1.20543165e+02 1.95568331e+03\n",
            " 6.78740772e+01 8.91267605e+01 1.36992079e+02 7.05241154e+02\n",
            " 4.46831088e+01 3.50995467e+01 6.62953518e+00 5.05625705e+01\n",
            " 1.43248794e+02 3.54104744e+02 2.49925527e+01 1.53528952e+02\n",
            " 4.06898207e+02 6.67648374e+02 8.11920818e+02 2.52488002e+02\n",
            " 1.92961152e+01 5.25122829e+01 2.38925610e+00 1.06618673e+02\n",
            " 3.52632810e+02 1.37272932e+02 1.98399724e+02 1.39845460e+02\n",
            " 2.76223465e+01 2.49092871e+01 4.04771690e+01 3.02459125e+02\n",
            " 2.85475221e+03 1.02213526e+03 4.32958001e+02 1.43730723e+03\n",
            " 2.58238308e+02 1.60947926e+01 2.35766053e+02 1.14241225e+02\n",
            " 7.74533202e+01 6.47226651e+01 2.07783060e+03 6.96785770e+01\n",
            " 2.88360502e+02 1.96268632e+02 1.29004262e+02 6.07486792e+02\n",
            " 5.67439645e+02 1.03577770e+02 4.75260610e+02 2.73133823e+01\n",
            " 1.74749426e+02 1.38032367e+02 4.46849376e+01 2.31564738e+02\n",
            " 3.71920120e+02 2.07775704e+02 7.06762963e+01 1.16344144e+01\n",
            " 1.08904486e+02 2.84562950e+02 2.12081882e+03 2.84872307e+01\n",
            " 4.42008682e+01 1.56357926e+02 6.41782855e+01 1.64114420e+02\n",
            " 1.93365836e+03 7.73688766e+01 8.91306918e+02 1.06978425e+02\n",
            " 7.70889512e+02 1.16125419e+02 8.89257691e+01 6.96216255e+02\n",
            " 3.69762535e+01 2.42961583e+01 3.42849213e+03 1.63468269e+02\n",
            " 3.56191497e+02 2.78104998e+02 8.58466039e+00 1.26801796e+02\n",
            " 9.00652923e+01 9.89074772e+01 1.93011226e+02 5.79165677e+01\n",
            " 8.99741447e+01 1.23890343e+02 2.03860624e+01 1.16627296e+02\n",
            " 2.22193902e+02 1.61730761e+02 1.32489451e+02 5.96470590e+01\n",
            " 6.03141101e+01 7.77905097e+01 5.54232824e+02 1.19297403e+01\n",
            " 1.89146276e+02 2.83220596e+02 9.12758532e+01 9.54081692e+00\n",
            " 1.28592787e+02 1.74934837e+02 5.04125621e+01 1.91861880e+02\n",
            " 3.62676675e+01 1.92254250e+02 1.25610118e+01 1.20388348e+02\n",
            " 4.63459940e+01 2.46051930e+02 5.54315837e+01 2.01733338e+02\n",
            " 9.03881762e+01 1.50996800e+02 3.84516530e+01 3.78688842e+01\n",
            " 3.28596078e+02 1.30564310e+01 1.31891135e+02 1.83550917e+01\n",
            " 5.14783715e+02 1.84389273e+02 1.29906621e+02 1.63476027e+02\n",
            " 1.24546580e+02 8.20869005e+01 1.91387097e+01 5.70668131e+01\n",
            " 1.12530477e+02 3.65476905e+02 8.92951838e+01 8.66277895e+01\n",
            " 1.44387964e+02 1.86282112e+02 1.32520229e+02 1.40613106e+02\n",
            " 1.73156709e+02 1.47461813e+02 5.80781437e+00 2.49782247e+02\n",
            " 3.61585372e+01 1.42638192e+02 3.44323300e+03 1.72230790e+01\n",
            " 5.22482446e+01 1.48587244e+02 1.11655887e+02 3.24539409e+01\n",
            " 9.29468058e+01 2.66657587e+02 5.79589232e+01 2.31103658e+01\n",
            " 1.62869925e+02 3.45491146e+01 1.11539043e+02 9.77226587e+01\n",
            " 1.19459277e+02 2.41251551e+02 8.65327713e+02 4.81746769e+01\n",
            " 5.46944454e+01 1.22032432e+02 2.70871816e+02 3.10986875e+01\n",
            " 1.24913107e+02 4.16255784e+01 4.53547207e+00 3.88375810e+00\n",
            " 7.16613045e+02 5.32723298e+03 6.39307367e+01 4.86682744e+01\n",
            " 1.85466795e+02 8.97254511e+01 1.18990840e+01 2.56552386e+02\n",
            " 1.68901477e+02 2.35218186e+02 1.45502928e+02 9.83367780e+01\n",
            " 3.80603899e+01 3.69344866e+01 1.03117254e+02 1.46470956e+02\n",
            " 1.73063479e+02 8.55898413e+01 1.04670253e+02 2.13698541e+02\n",
            " 4.31490360e+01 5.29626495e+02 5.87230109e+01 8.51722361e+01\n",
            " 1.11601485e+02 2.01490801e+02 2.91163239e+01 1.01251855e+02\n",
            " 1.35748831e+02 3.08960775e+01 7.08148399e+01 1.64735964e+02\n",
            " 1.46305546e+02 2.98891641e+02 2.37887208e+02 7.13767985e+01\n",
            " 3.57450252e+02 2.95979410e+02 7.43520836e+01 1.24263462e+02\n",
            " 2.93244537e+02 1.70653658e+02 1.40834218e+02 9.73140144e+02\n",
            " 4.57240249e+01 2.55618175e+01 1.47587203e+01 1.46603440e+02\n",
            " 3.32068382e+02 1.24075133e+02 8.05788800e+01 7.62412041e+01\n",
            " 2.06328219e+02 7.21131243e+01 4.14030381e+01 2.00567278e+02\n",
            " 1.12387803e+03 8.88208073e+01 2.84766930e+02 7.18490239e+01\n",
            " 1.08127336e+02 9.54163791e+02 9.94925549e+01 7.33650368e+01\n",
            " 1.18662244e+02 9.22816771e+01 1.80196399e+02 4.18526342e+02\n",
            " 8.58873873e+01 8.83028888e+01 9.88799892e+01 1.60124862e+02\n",
            " 1.75332394e+02 1.16871979e+02 1.54171139e+02 1.19917390e+02\n",
            " 1.22246006e+02 4.63320120e+02 1.81638757e+02 2.97472881e+02\n",
            " 1.13643569e+01 1.51339487e+02 6.23386538e+01 6.12554620e+01\n",
            " 8.63223809e+01 1.60017240e+02 1.05733661e+02 1.38873021e+02\n",
            " 5.55778568e+00 1.41002848e+02 5.96956165e+00 6.76823868e+01\n",
            " 1.00925733e+02 1.68692038e+02 1.40129613e+02 1.22679661e+02\n",
            " 5.55671644e+01 6.16730733e+02 9.88094358e+01 4.63798502e+02\n",
            " 3.10864317e+02 7.40209920e+02 1.27286952e+02 6.84126957e+01\n",
            " 1.07230125e+01 1.75149052e+02 4.66190416e+01 1.99721416e+01\n",
            " 4.70625494e+00 1.04882888e+02 8.78584969e+01 2.01190052e+02\n",
            " 1.79700173e+02 4.17098776e+01 6.90727979e+02 3.12643552e+02\n",
            " 3.15473349e+01 1.98944832e+02 1.31833304e+02 1.67272236e+01\n",
            " 1.50084134e+02 3.83737051e+02 5.59821157e+00 1.22323415e+01\n",
            " 1.52532019e+01 7.84135400e+01 2.29076835e+02 1.59464706e+02\n",
            " 5.67837795e+01 5.21543957e+02 7.52319010e+01 1.21012166e+01\n",
            " 2.47179418e+03 6.92865232e+01 1.18748300e+02 3.48208600e+01\n",
            " 2.27490735e+01 7.30155506e+02 6.13042109e+02 5.40676571e+01\n",
            " 8.19685855e+01 1.84536905e+02 2.88784383e+03 4.63338163e+01\n",
            " 2.78805507e+02 4.52403151e+03 9.88670704e+01 2.60435737e+03\n",
            " 5.08476693e+02 1.63511875e+02 4.16103731e+02 6.81312074e+01\n",
            " 3.47027546e+02 7.60202594e+01 8.79919020e+01 1.22731968e+02\n",
            " 1.33582415e+02 1.29766114e+02 4.69401337e+01 2.92184042e+02\n",
            " 2.79832684e+02 1.28748356e+02 1.59448213e+02 3.41555576e+01\n",
            " 3.16786726e+02 8.12341842e+01 1.41711316e+02 1.50875448e+02\n",
            " 1.17472682e+02 3.37488685e+01 1.17289509e+01 5.97562447e+01\n",
            " 1.48359476e+02 1.06442147e+02 1.12619889e+02 1.58428193e+02\n",
            " 1.40815059e+02 8.92623963e+01 9.66782103e+01 7.80878203e+01\n",
            " 6.44981150e+01 1.64851651e+02 4.34728443e+00 1.81482636e+02\n",
            " 2.91336107e+02 8.56110295e+01 1.10265003e+02 1.24093263e+02\n",
            " 2.30654504e+02 6.60105823e+01 4.43235207e+02 8.15393737e+01\n",
            " 1.26368470e+02 2.51202475e+01 3.98194732e+01 1.12654186e+02\n",
            " 1.20360392e+02 4.15220901e+02 3.42188833e+02 2.69342786e+02\n",
            " 3.06421989e+01 3.64395912e+02 7.63877674e+00 1.28547718e+02\n",
            " 3.80733000e+02 5.91542618e+01 1.86837686e+02 1.08709758e+02\n",
            " 4.06152160e+00 7.02155781e+02 9.10871082e+01 7.19940832e+01\n",
            " 1.21329488e+02 3.98083468e+01 2.51669520e+02 5.06369076e+02\n",
            " 1.08887901e+02 7.95533828e+01 7.21497164e+01 4.59574105e+01\n",
            " 1.01438001e+02 1.39051398e+02 8.99952485e+02 1.72730269e+02\n",
            " 2.25874746e+01 3.88687216e+01 6.25076574e+01 1.55838502e+01\n",
            " 1.38006645e+02 1.15444981e+03 1.30253552e+02 3.98456326e+02\n",
            " 2.59626581e+02 1.09284127e+02 1.34492417e+02 1.90684667e+02\n",
            " 1.52141772e+02 6.86427788e+01 8.68364468e+01 4.26658980e+02\n",
            " 2.28038713e+02 8.12462561e+01 1.17462995e+02 4.95157196e+02\n",
            " 3.88681190e+01 8.01676738e+01 3.43947322e+01 1.43242059e+02\n",
            " 1.02088047e+02 1.09359081e+02 5.25241970e+01 9.63629551e+01\n",
            " 2.22603317e+01 1.09746446e+03 1.63376581e+02 8.65813838e+01\n",
            " 7.91135047e+01 1.67444637e+02 9.47238901e+01 7.39080357e+01\n",
            " 4.89101643e+02 9.05548887e+01 1.18261881e+02 2.71106808e+02\n",
            " 1.58651134e+02 2.95993707e+01 6.26362810e+01 7.61397452e+01\n",
            " 2.48350540e+02 2.95718424e+02 1.24271102e+01 9.58441551e+02\n",
            " 7.64841409e+01 8.78648474e+02 3.36042282e+02 9.97830976e+01\n",
            " 1.99231869e+02 9.81684386e+00 3.27140404e+02 1.15892422e+02\n",
            " 1.66588479e+02 7.31875518e+01 3.13302548e+02 2.82537707e+02\n",
            " 7.54789881e+02 5.52445357e+02 6.50388951e+01 3.36220454e+02\n",
            " 1.22914480e+02 2.16362693e+01 4.59917146e+02 2.28303717e+01\n",
            " 2.58169117e+02 2.37773101e+02 2.80880262e+02 7.98660588e+01\n",
            " 4.52469634e+01 2.78932486e+01 1.29751663e+02 4.53433047e+01\n",
            " 5.67928136e+01 7.17576185e+01 4.43507280e+02 1.47982456e+02\n",
            " 4.56196056e+01 5.90537432e+01 1.31394081e+02 8.94962848e+01\n",
            " 1.25459914e+02 2.39553476e+03 1.20395987e+03 7.92712214e+01\n",
            " 1.62220531e+02 4.17633053e+00 6.99318394e+01 1.01081845e+02\n",
            " 1.26090631e+02 3.64087654e+01 6.73166501e+01 7.48072082e+01\n",
            " 6.14280850e+01 8.59000766e+01 5.97482840e+02 1.17960327e+02\n",
            " 2.85881182e+01 2.48939568e+02 1.04261605e+02 3.05753555e+01\n",
            " 1.22839622e+01 8.58628595e+01 1.10969273e+02 2.91787679e+01\n",
            " 3.92101714e+01 1.16252939e+02 7.49768020e+01 1.63807193e+02\n",
            " 2.65854882e+02 6.39302115e+01 3.70536897e+01 2.66543210e+02\n",
            " 2.94761265e+00 1.53256352e+02 4.93486853e+01 4.21308120e+02\n",
            " 4.00603936e+02 1.43151161e+02 8.12321836e+01 1.63537431e+02\n",
            " 4.35286784e+02 6.78070339e+01 9.17591310e+01 1.24127449e+01\n",
            " 7.85310465e+00 1.03298023e+02 3.82022850e+02 4.97504001e+01\n",
            " 2.93293645e+02 2.37371486e+02 1.10825508e+03 1.72342768e+01\n",
            " 1.43982840e+01 2.24665932e+02 1.88317096e+01 9.18867452e+01\n",
            " 2.89371370e+01 1.19308348e+02 1.24852194e+02 8.38328966e+01\n",
            " 2.53916148e+03 2.60834485e+02 8.81536377e+01 2.42830223e+03\n",
            " 2.84168193e+02 4.93866173e+01 1.72317991e+02 1.47363018e+02\n",
            " 1.06242567e+02 3.22003144e+01 3.12608508e+01 1.16415227e+02\n",
            " 6.61156037e+01 2.24778330e+02 3.04744107e+01 4.47446814e+02\n",
            " 5.39477084e+00 1.02900416e+02 1.85884862e+01 5.91988041e+02\n",
            " 1.06640070e+02 4.66965025e+01 1.38483701e+02 6.76311811e+01\n",
            " 2.28491134e+01 9.83934196e+02 6.08857381e+01 1.24942129e+02\n",
            " 2.77327833e+01 8.22689169e+01 1.09152704e+02 1.85544801e+02\n",
            " 2.62678212e+02 1.45689237e+02 1.03724951e+02 7.50379451e+01\n",
            " 3.84173620e+02 6.15925242e+01 7.47524778e+00 4.04212031e+01\n",
            " 2.00886210e+02 2.13806704e+02 2.13661125e+01 4.42398536e+01\n",
            " 2.38210708e+02 9.89192148e+01 5.28806538e+02 8.69940231e+01\n",
            " 6.58103671e+01 1.19447067e+02 1.59854928e+02 6.54305523e+01\n",
            " 4.50708156e+02 6.97022675e+01 2.90847375e+02 5.50179412e+01\n",
            " 3.20941157e+02 3.55733530e+02 6.93323545e+01 1.03321731e+02\n",
            " 1.17376286e+03 1.26697334e+02 5.22283108e+02 5.43636306e+02\n",
            " 1.26301418e+02 5.75644233e+01 3.48930421e+01 6.18019006e+01\n",
            " 2.42736312e+02 2.87062631e+02 1.49734362e+02 4.75587382e+01\n",
            " 5.57619890e+02 1.12680648e+01 1.31170122e+03 1.16472766e+02\n",
            " 7.70777813e+01 2.96210888e+00 5.14772090e+01 1.94628235e+02\n",
            " 4.93542661e+02 9.88145513e+01 1.16982427e+02 7.66586517e+02\n",
            " 2.12887453e+02 8.03101373e+01 1.02543171e+02 1.88576580e+01\n",
            " 2.62518541e+02 1.41229180e+02 2.85617658e+02 1.40262020e+02\n",
            " 6.90290085e+01 2.93786552e+01 9.38147867e+01 1.13813008e+02\n",
            " 2.03079159e+02 1.83347451e+01 1.21142802e+02 2.10882116e+01\n",
            " 1.49199238e+01 6.26989002e+01 2.79168190e+02 1.61126091e+02\n",
            " 1.39457994e+02 3.04353958e+02 3.57412955e+02 1.76946149e+02\n",
            " 9.36920116e+01 7.54104929e+02 2.67981195e+02 9.95143308e+01\n",
            " 6.48665430e+01 3.71529024e+01 2.71116101e+02 1.46637474e+01\n",
            " 1.07078181e+02 3.95886593e+01 3.16016655e+02 1.66753553e+02\n",
            " 1.39584554e+02 1.63955906e+02 8.93803278e+01 2.36302132e+02\n",
            " 1.06433509e+02 5.94227530e+02 5.25651973e+02 8.13473484e+01\n",
            " 4.40556648e+03 1.24585876e+02 4.50867739e+02 1.06088736e+02\n",
            " 1.25848232e+02 1.30520438e+02 7.67158748e+01 7.26863988e+00\n",
            " 8.63501667e+02 2.10971651e+02 8.35477919e+02 8.49343181e+00\n",
            " 1.91535362e+02 3.94454319e+03 3.31659055e+01 4.99590710e+01\n",
            " 5.87554560e+01 3.62509809e+02 2.58066180e+02 3.73173624e+01\n",
            " 1.39883683e+01 7.89748955e+01 1.37865641e+02 4.50788890e+02\n",
            " 6.31689416e+00 2.40386241e+01 1.04195106e+02 1.97525353e+02\n",
            " 1.32210435e+02 1.30899538e+01 3.91806014e+01 1.53627422e+02\n",
            " 7.82511380e+01 4.71119062e+02 4.28621691e+01 2.13824479e+02\n",
            " 5.83623794e+03 1.98797340e+02 7.38698576e+02 1.43147026e+02\n",
            " 1.32252991e+02 2.25268745e+03 2.91025668e+02 1.27975347e+02\n",
            " 6.19167117e+01 1.22308767e+02 1.16683268e+02 1.45542230e+02\n",
            " 1.63002226e+02 1.27601654e+02 3.78131823e+01 1.25335491e+02\n",
            " 4.21130587e+02 9.59477019e+01 7.75705677e+01 2.00533572e+01\n",
            " 6.24795641e+01 5.46047923e+01 1.37840474e+02 5.51305447e+01\n",
            " 2.14773413e+02 1.51173514e+02 5.58647927e+02 7.32320265e+02\n",
            " 2.80843060e+02 2.21206549e+02 2.53168817e+01 4.88180319e+01\n",
            " 4.58043854e+02 7.71703373e+00 4.38734391e+02 4.56871895e+02\n",
            " 7.41532777e+01 9.91047328e+02 1.01176665e+02 9.89556455e+01\n",
            " 1.73481774e+02 8.03332174e+01 1.55706019e+02 9.51422498e+01\n",
            " 8.04133413e+01 2.73975737e+01 2.31747100e+01 1.64501792e+02\n",
            " 2.25043469e+02 2.26412925e+01 2.24095626e+03 5.61065116e+02\n",
            " 1.38768880e+03 1.41346811e+02 1.55322410e+01 5.15690699e+02\n",
            " 3.53616548e+01 1.18680540e+02 3.25065033e+02 4.53713029e+02\n",
            " 7.06954521e+01 6.84775235e+01 1.01685070e+02 2.67151739e+02\n",
            " 4.41640933e+01 7.22171948e+02 8.86836725e+01 3.65992506e+02\n",
            " 6.63232316e+01 5.80672046e+01 1.12923871e+02 1.64104067e+02\n",
            " 1.19220352e+02 3.17560840e+01 1.26536396e+02 1.27778281e+02\n",
            " 1.03115430e+02 8.29607799e+01 8.14646602e+01 1.50029365e+02\n",
            " 2.19700271e+02 2.36906866e+01 2.72153700e+02 8.42785523e+02\n",
            " 4.12589207e+01 1.31531541e+02 1.09781122e+02 1.32369001e+02\n",
            " 5.89429334e+01 5.04006305e+00 2.86723402e+02 1.48633871e+01\n",
            " 3.02978502e+02 5.06887461e+01 5.30117736e+01 1.57513033e+02\n",
            " 6.39083260e+01 1.02848736e+02 2.12712214e+01 1.15834679e+02\n",
            " 6.12305353e+02 2.73535520e+03 1.30141427e+03 1.37267982e+02\n",
            " 4.83902657e+01 2.23964279e+02 1.17333354e+02 5.15247523e+02\n",
            " 1.97916934e+02 4.88722374e+01 1.12999347e+01 4.19805879e+02\n",
            " 8.15199189e+01 8.15990482e+01 1.31056381e+02 4.37406564e+01\n",
            " 4.18127893e+01 1.14673622e+02 6.39620247e+02 2.45196500e+02\n",
            " 6.29335801e+01 3.33160116e+01 2.11368045e+02 6.28365156e+02\n",
            " 2.23604607e+03 2.71594449e+02 1.11457443e+02 1.92663053e+02\n",
            " 1.50729114e+02 4.42521419e+01 4.30330513e+01 5.19723312e+01\n",
            " 2.62263503e+02 1.03401693e+03 3.10624069e+01 4.12250953e+01\n",
            " 2.04252216e+02 5.12987054e+00 1.46690209e+02 3.29852831e+02\n",
            " 1.10043016e+01 2.10018288e+02 4.45620151e+01 1.08757472e+02\n",
            " 5.39292438e+01 1.50005643e+01 7.60596364e+00 1.87573689e+01\n",
            " 9.34928746e+00 1.29966151e+02 1.87427286e+02 1.08032597e+02\n",
            " 5.15926423e+01 6.19889934e+02 1.65794075e+02 6.39316021e+02\n",
            " 8.86123848e+02 4.95324418e+01 1.19644757e+02 1.49949280e+02\n",
            " 1.25981572e+02 4.66456715e+01 1.19557946e+02 3.46677718e+02\n",
            " 1.04010105e+02 3.65350661e+02 1.31149257e+02 2.02576745e+01\n",
            " 5.54654827e+01 4.90072406e+01 3.60380131e+00 5.15373312e+01\n",
            " 1.87412140e+02 3.60162726e+01 1.64719439e+02 1.22906559e+02\n",
            " 1.22715787e+02 1.90181100e+03 1.24845707e+02 1.89855932e+02\n",
            " 1.17168772e+02 1.72025321e+02 1.19239258e+02 7.46200846e+01\n",
            " 6.38161171e+02 1.14105314e+02 5.81436739e+01 2.31836800e+02\n",
            " 2.67245993e+02 3.07561090e+02 4.52871408e+00 3.94282112e+01\n",
            " 2.69860435e+01 2.77211496e+01 2.90134675e+02 1.00373585e+01\n",
            " 4.59106406e+02 1.27279894e+02]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  features_df.loc[mask, 'avg_monthly_charges'] = features_df.loc[mask, 'total_charges'] / features_df.loc[mask, 'tenure']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  customer_id  gender  senior_citizen  partner  dependents  tenure  \\\n",
              "0  CUST-00000    Male               1        1           0       6   \n",
              "1  CUST-00001  Female               0        0           0      34   \n",
              "2  CUST-00002    Male               0        0           0      54   \n",
              "3  CUST-00003    Male               0        0           0      13   \n",
              "4  CUST-00004    Male               0        0           1       9   \n",
              "\n",
              "   phone_service    multiple_lines internet_service      online_security  ...  \\\n",
              "0              0               Yes               No                  Yes  ...   \n",
              "1              0  No phone service      Fiber optic  No internet service  ...   \n",
              "2              1  No phone service               No                  Yes  ...   \n",
              "3              0  No phone service      Fiber optic                  Yes  ...   \n",
              "4              0  No phone service               No                  Yes  ...   \n",
              "\n",
              "  monthly_charges total_charges churn tenure_years tenure_group  \\\n",
              "0       26.875095   4951.885351    No     0.500000     0-1 year   \n",
              "1       70.739409   1586.779855    No     2.833333    2-3 years   \n",
              "2       52.891978   2353.696176    No     4.500000    4-5 years   \n",
              "3       70.831169   3859.820909    No     1.083333    1-2 years   \n",
              "4       22.397545   7639.333018   Yes     0.750000     0-1 year   \n",
              "\n",
              "   avg_monthly_charges monthly_charges_category  services_count  \\\n",
              "0           825.314225                      Low               5   \n",
              "1            46.669996                     High               1   \n",
              "2            43.586966                   Medium               3   \n",
              "3           296.909301                     High               2   \n",
              "4           848.814780                      Low               2   \n",
              "\n",
              "   contract_type_code churn_binary  \n",
              "0                   2            0  \n",
              "1                   1            0  \n",
              "2                   0            0  \n",
              "3                   1            0  \n",
              "4                   0            1  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f9f82a1-51a4-4e3c-a829-5052a68aba32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>senior_citizen</th>\n",
              "      <th>partner</th>\n",
              "      <th>dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>phone_service</th>\n",
              "      <th>multiple_lines</th>\n",
              "      <th>internet_service</th>\n",
              "      <th>online_security</th>\n",
              "      <th>...</th>\n",
              "      <th>monthly_charges</th>\n",
              "      <th>total_charges</th>\n",
              "      <th>churn</th>\n",
              "      <th>tenure_years</th>\n",
              "      <th>tenure_group</th>\n",
              "      <th>avg_monthly_charges</th>\n",
              "      <th>monthly_charges_category</th>\n",
              "      <th>services_count</th>\n",
              "      <th>contract_type_code</th>\n",
              "      <th>churn_binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUST-00000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>26.875095</td>\n",
              "      <td>4951.885351</td>\n",
              "      <td>No</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0-1 year</td>\n",
              "      <td>825.314225</td>\n",
              "      <td>Low</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CUST-00001</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>...</td>\n",
              "      <td>70.739409</td>\n",
              "      <td>1586.779855</td>\n",
              "      <td>No</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>2-3 years</td>\n",
              "      <td>46.669996</td>\n",
              "      <td>High</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUST-00002</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>52.891978</td>\n",
              "      <td>2353.696176</td>\n",
              "      <td>No</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4-5 years</td>\n",
              "      <td>43.586966</td>\n",
              "      <td>Medium</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CUST-00003</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>70.831169</td>\n",
              "      <td>3859.820909</td>\n",
              "      <td>No</td>\n",
              "      <td>1.083333</td>\n",
              "      <td>1-2 years</td>\n",
              "      <td>296.909301</td>\n",
              "      <td>High</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CUST-00004</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>22.397545</td>\n",
              "      <td>7639.333018</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0-1 year</td>\n",
              "      <td>848.814780</td>\n",
              "      <td>Low</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f9f82a1-51a4-4e3c-a829-5052a68aba32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f9f82a1-51a4-4e3c-a829-5052a68aba32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f9f82a1-51a4-4e3c-a829-5052a68aba32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa27c009-17d2-45b8-9058-769445bdb9fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa27c009-17d2-45b8-9058-769445bdb9fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa27c009-17d2-45b8-9058-769445bdb9fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features_df"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5 Feature Store Setup"
      ],
      "metadata": {
        "id": "5KZjaa4cxuqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_feature_store():\n",
        "    \"\"\"\n",
        "    Set up a SQLite feature store for versioned feature management\n",
        "\n",
        "    Returns:\n",
        "        conn: SQLite connection\n",
        "    \"\"\"\n",
        "    # Create feature store directory\n",
        "    feature_store_dir = Path(\"feature_store\")\n",
        "    feature_store_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Connect to SQLite database\n",
        "    conn = sqlite3.connect('feature_store/feature_store.db')\n",
        "\n",
        "    # Create features table\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS features (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        feature_name TEXT NOT NULL,\n",
        "        feature_version TEXT NOT NULL,\n",
        "        data_version TEXT NOT NULL,\n",
        "        feature_type TEXT NOT NULL,\n",
        "        created_at TEXT NOT NULL,\n",
        "        description TEXT,\n",
        "        stats TEXT,\n",
        "        UNIQUE(feature_name, feature_version)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_values table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_values (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        entity_id TEXT NOT NULL,\n",
        "        feature_id INTEGER NOT NULL,\n",
        "        value TEXT NOT NULL,\n",
        "        timestamp TEXT NOT NULL,\n",
        "        FOREIGN KEY (feature_id) REFERENCES features(id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_sets table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_sets (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        name TEXT NOT NULL,\n",
        "        version TEXT NOT NULL,\n",
        "        created_at TEXT NOT NULL,\n",
        "        description TEXT,\n",
        "        UNIQUE(name, version)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_set_features table (many-to-many relationship)\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_set_features (\n",
        "        feature_set_id INTEGER NOT NULL,\n",
        "        feature_id INTEGER NOT NULL,\n",
        "        PRIMARY KEY (feature_set_id, feature_id),\n",
        "        FOREIGN KEY (feature_set_id) REFERENCES feature_sets(id),\n",
        "        FOREIGN KEY (feature_id) REFERENCES features(id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"Feature store database initialized\")\n",
        "\n",
        "    return conn\n",
        "\n",
        "def register_features_in_store(conn, features_df, feature_metadata):\n",
        "    \"\"\"\n",
        "    Register features in the feature store\n",
        "\n",
        "    Args:\n",
        "        conn: SQLite connection\n",
        "        features_df: DataFrame with features\n",
        "        feature_metadata: Feature metadata dictionary\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create a feature set\n",
        "    feature_set_name = \"telco_churn_features\"\n",
        "    feature_set_version = feature_metadata['feature_version']\n",
        "    created_at = datetime.datetime.now().isoformat()\n",
        "    description = f\"Telco churn prediction features version {feature_set_version}\"\n",
        "\n",
        "    cursor.execute('''\n",
        "    INSERT OR REPLACE INTO feature_sets (name, version, created_at, description)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "    ''', (feature_set_name, feature_set_version, created_at, description))\n",
        "\n",
        "    feature_set_id = cursor.lastrowid\n",
        "\n",
        "    # Register each feature\n",
        "    for feature_name in features_df.columns:\n",
        "        if feature_name == 'customer_id':\n",
        "            continue  # Skip entity ID column\n",
        "\n",
        "        # Determine feature type\n",
        "        if feature_name in feature_metadata['numerical_features']:\n",
        "            feature_type = 'NUMERIC'\n",
        "        elif feature_name in feature_metadata['binary_features']:\n",
        "            feature_type = 'BINARY'\n",
        "        else:\n",
        "            feature_type = 'CATEGORICAL'\n",
        "\n",
        "        # Calculate basic stats\n",
        "        if feature_type == 'NUMERIC':\n",
        "            stats = {\n",
        "                'min': float(features_df[feature_name].min()),\n",
        "                'max': float(features_df[feature_name].max()),\n",
        "                'mean': float(features_df[feature_name].mean()),\n",
        "                'median': float(features_df[feature_name].median()),\n",
        "                'std': float(features_df[feature_name].std())\n",
        "            }\n",
        "        else:\n",
        "            value_counts = features_df[feature_name].value_counts().to_dict()\n",
        "            stats = {\n",
        "                'unique_values': len(value_counts),\n",
        "                'value_counts': {str(k): int(v) for k, v in value_counts.items()}\n",
        "            }\n",
        "\n",
        "        stats_json = json.dumps(stats)\n",
        "\n",
        "        # Insert feature metadata\n",
        "        cursor.execute('''\n",
        "        INSERT OR REPLACE INTO features\n",
        "        (feature_name, feature_version, data_version, feature_type, created_at, description, stats)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        ''', (\n",
        "            feature_name,\n",
        "            feature_set_version,\n",
        "            feature_metadata['data_version'],\n",
        "            feature_type,\n",
        "            created_at,\n",
        "            f\"Feature {feature_name} for telco churn prediction\",\n",
        "            stats_json\n",
        "        ))\n",
        "\n",
        "        feature_id = cursor.lastrowid\n",
        "\n",
        "        # Link feature to feature set\n",
        "        cursor.execute('''\n",
        "        INSERT OR REPLACE INTO feature_set_features (feature_set_id, feature_id)\n",
        "        VALUES (?, ?)\n",
        "        ''', (feature_set_id, feature_id))\n",
        "\n",
        "        # For demo purposes, only store a sample of feature values\n",
        "        if feature_name in ['tenure', 'monthly_charges', 'churn_binary', 'services_count']:\n",
        "            # Store feature values for each entity (customer)\n",
        "            for _, row in features_df.sample(min(100, len(features_df))).iterrows():\n",
        "                entity_id = row['customer_id']\n",
        "                value = str(row[feature_name])\n",
        "\n",
        "                cursor.execute('''\n",
        "                INSERT INTO feature_values (entity_id, feature_id, value, timestamp)\n",
        "                VALUES (?, ?, ?, ?)\n",
        "                ''', (entity_id, feature_id, value, created_at))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Registered {len(features_df.columns) - 1} features in feature store under set '{feature_set_name}' version '{feature_set_version}'\")\n",
        "\n",
        "# Set up feature store\n",
        "conn = setup_feature_store()\n",
        "\n",
        "# Register features\n",
        "register_features_in_store(conn, features_df, feature_metadata)\n",
        "\n",
        "# Query to verify feature registration\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT COUNT(*) FROM features\")\n",
        "feature_count = cursor.fetchone()[0]\n",
        "cursor.execute(\"SELECT COUNT(*) FROM feature_sets\")\n",
        "feature_set_count = cursor.fetchone()[0]\n",
        "cursor.execute(\"SELECT COUNT(*) FROM feature_values\")\n",
        "value_count = cursor.fetchone()[0]\n",
        "\n",
        "print(f\"\\nFeature Store Summary:\")\n",
        "print(f\"- Registered features: {feature_count}\")\n",
        "print(f\"- Feature sets: {feature_set_count}\")\n",
        "print(f\"- Sample feature values stored: {value_count}\")\n",
        "\n",
        "# Check a few registered features\n",
        "cursor.execute(\"SELECT feature_name, feature_type, stats FROM features LIMIT 5\")\n",
        "for row in cursor.fetchall():\n",
        "    name, type_, stats = row\n",
        "    print(f\"- Feature: {name}, Type: {type_}, Stats: {stats[:60]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7toX98hSxxXv",
        "outputId": "b84dfc33-7f1a-4158-ffc4-d1bc034d4d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature store database initialized\n",
            "Registered 26 features in feature store under set 'telco_churn_features' version '20250512_172103_feat'\n",
            "\n",
            "Feature Store Summary:\n",
            "- Registered features: 52\n",
            "- Feature sets: 2\n",
            "- Sample feature values stored: 800\n",
            "- Feature: gender, Type: BINARY, Stats: {\"unique_values\": 2, \"value_counts\": {\"Female\": 510, \"Male\":...\n",
            "- Feature: senior_citizen, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.474, \"median\": 0.0, \"std\"...\n",
            "- Feature: partner, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.501, \"median\": 1.0, \"std\"...\n",
            "- Feature: dependents, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.476, \"median\": 0.0, \"std\"...\n",
            "- Feature: tenure, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 71.0, \"mean\": 35.672, \"median\": 36.0, \"s...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Experimentation & Training"
      ],
      "metadata": {
        "id": "y62fXY-hxz4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Set Up MLflow for Experiment Tracking"
      ],
      "metadata": {
        "id": "59pT12Xmx3Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_mlflow():\n",
        "    \"\"\"\n",
        "    Set up MLflow for experiment tracking\n",
        "    \"\"\"\n",
        "    # Create MLflow directory\n",
        "    mlflow_dir = Path(\"mlruns\")\n",
        "    mlflow_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Set tracking URI to local directory\n",
        "    mlflow.set_tracking_uri(f\"file:{os.path.abspath(mlflow_dir)}\")\n",
        "\n",
        "    # Create experiment if it doesn't exist\n",
        "    experiment_name = \"telco_churn_prediction\"\n",
        "\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"Created new MLflow experiment '{experiment_name}' with ID {experiment_id}\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"Using existing MLflow experiment '{experiment_name}' with ID {experiment_id}\")\n",
        "\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    return experiment_id\n",
        "\n",
        "# Set up MLflow\n",
        "experiment_id = setup_mlflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnQEpFyyyDGb",
        "outputId": "78711d80-8c16-41e6-c823-6e96d8618e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing MLflow experiment 'telco_churn_prediction' with ID 409164801491470435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Create Data Splits"
      ],
      "metadata": {
        "id": "TDr6JoZcyExh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_splits(features_df, test_size=0.2, val_size=0.25, random_state=42):\n",
        "    \"\"\"\n",
        "    Create reproducible train/validation/test splits\n",
        "\n",
        "    Args:\n",
        "        features_df: DataFrame with features\n",
        "        test_size: Proportion of data to use for test set\n",
        "        val_size: Proportion of training data to use for validation\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        splits: Dictionary with X_train, X_val, X_test, y_train, y_val, y_test\n",
        "    \"\"\"\n",
        "\n",
        "    # Make a copy to avoid modifying the original\n",
        "    df = features_df.copy()\n",
        "\n",
        "    # Define features and target\n",
        "    X = df.drop(['churn', 'churn_binary'], axis=1)\n",
        "    y = df['churn_binary']\n",
        "\n",
        "    # First split: training+validation vs test\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Second split: training vs validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=val_size, random_state=random_state, stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Create splits dictionary\n",
        "    splits = {\n",
        "        'X_train': X_train,\n",
        "        'X_val': X_val,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_val': y_val,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "    # Log split sizes\n",
        "    print(f\"Split sizes:\")\n",
        "    print(f\"- Training: {len(X_train)} samples ({len(X_train) / len(df):.1%})\")\n",
        "    print(f\"- Validation: {len(X_val)} samples ({len(X_val) / len(df):.1%})\")\n",
        "    print(f\"- Test: {len(X_test)} samples ({len(X_test) / len(df):.1%})\")\n",
        "\n",
        "    splits_dir = Path(\"data/splits\")\n",
        "    splits_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Save split indices for reproducibility\n",
        "    split_indices = {\n",
        "        'train_indices': X_train.index.tolist(),\n",
        "        'val_indices': X_val.index.tolist(),\n",
        "        'test_indices': X_test.index.tolist(),\n",
        "        'random_state': random_state,\n",
        "        'test_size': test_size,\n",
        "        'val_size': val_size,\n",
        "        'timestamp': datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    with open(splits_dir / f\"split_indices_{initial_version}.json\", 'w') as f:\n",
        "        json.dump(split_indices, f, indent=2)\n",
        "\n",
        "    return splits\n",
        "\n",
        "# Create train/validation/test splits\n",
        "data_splits = create_data_splits(features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsHvB7qlyGYA",
        "outputId": "425a78ad-9dde-4508-bc62-f232e98ce318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes:\n",
            "- Training: 600 samples (60.0%)\n",
            "- Validation: 200 samples (20.0%)\n",
            "- Test: 200 samples (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Create Feature Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "-GYvGnJ-yJzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessing_pipeline(X_train):\n",
        "    \"\"\"\n",
        "    Create a scikit-learn preprocessing pipeline\n",
        "\n",
        "    Args:\n",
        "        X_train: Training features DataFrame\n",
        "\n",
        "    Returns:\n",
        "        preprocessor: ColumnTransformer preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Identify column types\n",
        "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    # Remove customer_id from features\n",
        "    if 'customer_id' in categorical_cols:\n",
        "        categorical_cols.remove('customer_id')\n",
        "    if 'customer_id' in numerical_cols:\n",
        "        numerical_cols.remove('customer_id')\n",
        "\n",
        "    # Create preprocessing steps for each column type\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # The following line was incorrectly indented\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Changed 'sparse' to 'sparse_output'\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ],\n",
        "        remainder='drop'  # Drop any columns not specified (like customer_id)\n",
        "    )\n",
        "\n",
        "    print(f\"Created preprocessing pipeline with:\")\n",
        "    print(f\"- {len(numerical_cols)} numerical features: {numerical_cols[:5]}\")\n",
        "    print(f\"- {len(categorical_cols)} categorical features: {categorical_cols[:5]}\")\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = create_preprocessing_pipeline(data_splits['X_train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nji5yhoyMDh",
        "outputId": "f158a3ff-0cb8-4ca5-f718-c14f773258c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created preprocessing pipeline with:\n",
            "- 12 numerical features: ['senior_citizen', 'partner', 'dependents', 'tenure', 'phone_service']\n",
            "- 12 categorical features: ['gender', 'multiple_lines', 'internet_service', 'online_security', 'online_backup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Train Models with Experiment Tracking"
      ],
      "metadata": {
        "id": "fB9HVNh2yNmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(splits, preprocessor, model_params, run_name=None):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model with experiment tracking\n",
        "\n",
        "    Args:\n",
        "        splits: Dictionary with data splits\n",
        "        preprocessor: Preprocessing pipeline\n",
        "        model_params: Parameters for RandomForestClassifier\n",
        "        run_name: Name for MLflow run\n",
        "\n",
        "    Returns:\n",
        "        model_pipeline: Trained model pipeline\n",
        "        metrics: Evaluation metrics\n",
        "    \"\"\"\n",
        "    # Extract splits\n",
        "    X_train = splits['X_train']\n",
        "    X_val = splits['X_val']\n",
        "    X_test = splits['X_test']\n",
        "    y_train = splits['y_train']\n",
        "    y_val = splits['y_val']\n",
        "    y_test = splits['y_test']\n",
        "\n",
        "    # Create and train model pipeline\n",
        "    model = RandomForestClassifier(**model_params)\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(run_name=run_name) as run:\n",
        "        run_id = run.info.run_id\n",
        "        print(f\"Started MLflow run '{run_name}' with ID {run_id}\")\n",
        "\n",
        "        # Log data versions and features\n",
        "        mlflow.log_param(\"data_version\", initial_version)\n",
        "        mlflow.log_param(\"n_samples_train\", len(X_train))\n",
        "        mlflow.log_param(\"n_features\", X_train.shape[1])\n",
        "\n",
        "        # Log feature names\n",
        "        feature_names = list(X_train.columns)\n",
        "        mlflow.log_param(\"feature_count\", len(feature_names))\n",
        "\n",
        "        # Log model parameters\n",
        "        for param, value in model_params.items():\n",
        "            mlflow.log_param(param, value)\n",
        "\n",
        "        # Train the model and time it\n",
        "        start_time = datetime.datetime.now()\n",
        "        model_pipeline.fit(X_train, y_train)\n",
        "        train_time = (datetime.datetime.now() - start_time).total_seconds()\n",
        "        mlflow.log_metric(\"training_time_seconds\", train_time)\n",
        "\n",
        "        # Evaluate on training set\n",
        "        y_train_pred = model_pipeline.predict(X_train)\n",
        "        y_train_prob = model_pipeline.predict_proba(X_train)[:, 1]\n",
        "\n",
        "        train_metrics = {\n",
        "            \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
        "            \"train_precision\": precision_score(y_train, y_train_pred),\n",
        "            \"train_recall\": recall_score(y_train, y_train_pred),\n",
        "            \"train_f1\": f1_score(y_train, y_train_pred),\n",
        "            \"train_roc_auc\": roc_auc_score(y_train, y_train_prob)\n",
        "        }\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        y_val_pred = model_pipeline.predict(X_val)\n",
        "        y_val_prob = model_pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        val_metrics = {\n",
        "            \"val_accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "            \"val_precision\": precision_score(y_val, y_val_pred),\n",
        "            \"val_recall\": recall_score(y_val, y_val_pred),\n",
        "            \"val_f1\": f1_score(y_val, y_val_pred),\n",
        "            \"val_roc_auc\": roc_auc_score(y_val, y_val_prob)\n",
        "        }\n",
        "\n",
        "        # Evaluate on test set\n",
        "        y_test_pred = model_pipeline.predict(X_test)\n",
        "        y_test_prob = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        test_metrics = {\n",
        "            \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "            \"test_precision\": precision_score(y_test, y_test_pred),\n",
        "            \"test_recall\": recall_score(y_test, y_test_pred),\n",
        "            \"test_f1\": f1_score(y_test, y_test_pred),\n",
        "            \"test_roc_auc\": roc_auc_score(y_test, y_test_prob)\n",
        "        }\n",
        "\n",
        "        # Combine all metrics\n",
        "        metrics = {**train_metrics, **val_metrics, **test_metrics}\n",
        "\n",
        "        # Log metrics to MLflow\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            mlflow.log_metric(metric_name, metric_value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model_pipeline, \"model\")\n",
        "\n",
        "\n",
        "        # Log feature importances\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            # Get column names after preprocessing\n",
        "            preprocessor_output_feature_names = []\n",
        "            for name, trans, cols in preprocessor.transformers_:\n",
        "                if hasattr(trans, 'get_feature_names_out'):\n",
        "                    preprocessor_output_feature_names.extend(trans.get_feature_names_out(cols))\n",
        "                else:\n",
        "                    preprocessor_output_feature_names.extend(cols)\n",
        "\n",
        "            # Ensure feature names and importances have the same length\n",
        "            # This is done by selecting the feature names corresponding to the\n",
        "            # features used by the model (based on the length of feature_importances_)\n",
        "            preprocessor_output_feature_names = preprocessor_output_feature_names[:len(model.feature_importances_)]\n",
        "\n",
        "            # Match feature importances with names\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': preprocessor_output_feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Match feature importances with names\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': preprocessor_output_feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Save feature importances\n",
        "            importance_path = f\"feature_importances_{run_id}.csv\"\n",
        "            importance_df.to_csv(importance_path, index=False)\n",
        "            mlflow.log_artifact(importance_path)\n",
        "\n",
        "            # Create and log feature importance plot\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            top_features = importance_df.head(15)\n",
        "            sns.barplot(x='importance', y='feature', data=top_features)\n",
        "            plt.title('Top 15 Feature Importances')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plot_path = f\"feature_importance_plot_{run_id}.png\"\n",
        "            plt.savefig(plot_path)\n",
        "            mlflow.log_artifact(plot_path)\n",
        "            plt.close()\n",
        "\n",
        "            # Clean up local files\n",
        "            os.remove(importance_path)\n",
        "            os.remove(plot_path)\n",
        "\n",
        "        # Create and log confusion matrix\n",
        "        cm = np.zeros((2, 2))\n",
        "        cm[0, 0] = np.sum((y_val == 0) & (y_val_pred == 0))\n",
        "        cm[0, 1] = np.sum((y_val == 0) & (y_val_pred == 1))\n",
        "        cm[1, 0] = np.sum((y_val == 1) & (y_val_pred == 0))\n",
        "        cm[1, 1] = np.sum((y_val == 1) & (y_val_pred == 1))\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n",
        "                    xticklabels=['No Churn', 'Churn'],\n",
        "                    yticklabels=['No Churn', 'Churn'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Confusion Matrix (Validation Set)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        cm_path = f\"confusion_matrix_{run_id}.png\"\n",
        "        plt.savefig(cm_path)\n",
        "        mlflow.log_artifact(cm_path)\n",
        "        plt.close()\n",
        "\n",
        "        # Clean up local file\n",
        "        os.remove(cm_path)\n",
        "\n",
        "        print(f\"Model training and evaluation complete. MLflow run ID: {run_id}\")\n",
        "        print(f\"Validation metrics: accuracy={val_metrics['val_accuracy']:.4f}, f1={val_metrics['val_f1']:.4f}, roc_auc={val_metrics['val_roc_auc']:.4f}\")\n",
        "\n",
        "    return model_pipeline, metrics, run_id\n",
        "\n",
        "# Train multiple model variants\n",
        "models = []\n",
        "\n",
        "# Model 1: Default RandomForest\n",
        "model_params_1 = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': None,\n",
        "    'min_samples_split': 2,\n",
        "    'min_samples_leaf': 1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_1, metrics_1, run_id_1 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_1,\n",
        "    run_name=\"RandomForest-Default\"\n",
        ")\n",
        "models.append((\"RandomForest-Default\", model_1, metrics_1, run_id_1))\n",
        "\n",
        "# Model 2: Tuned RandomForest\n",
        "model_params_2 = {\n",
        "    'n_estimators': 200,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_2, metrics_2, run_id_2 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_2,\n",
        "    run_name=\"RandomForest-Tuned\"\n",
        ")\n",
        "models.append((\"RandomForest-Tuned\", model_2, metrics_2, run_id_2))\n",
        "\n",
        "# Model 3: RandomForest with feature reduction focus\n",
        "model_params_3 = {\n",
        "    'n_estimators': 150,\n",
        "    'max_depth': 8,\n",
        "    'min_samples_split': 10,\n",
        "    'min_samples_leaf': 4,\n",
        "    'max_features': 'sqrt',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_3, metrics_3, run_id_3 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_3,\n",
        "    run_name=\"RandomForest-FeatureReduction\"\n",
        ")\n",
        "models.append((\"RandomForest-FeatureReduction\", model_3, metrics_3, run_id_3))\n",
        "\n",
        "# Compare models\n",
        "comparison_df = pd.DataFrame([\n",
        "    {\n",
        "        'model_name': model_name,\n",
        "        'val_accuracy': metrics['val_accuracy'],\n",
        "        'val_precision': metrics['val_precision'],\n",
        "        'val_recall': metrics['val_recall'],\n",
        "        'val_f1': metrics['val_f1'],\n",
        "        'val_roc_auc': metrics['val_roc_auc'],\n",
        "        'run_id': run_id\n",
        "    }\n",
        "    for model_name, _, metrics, run_id in models\n",
        "])\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "comparison_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "WVskZlDOyPzH",
        "outputId": "3aa5bb89-59cb-44dd-f507-244c1039f8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started MLflow run 'RandomForest-Default' with ID 4bce6674e96248deaa3eabf58da39748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: 4bce6674e96248deaa3eabf58da39748\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6231\n",
            "Started MLflow run 'RandomForest-Tuned' with ID 7c320ab775db4de1a352fd8060601f20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: 7c320ab775db4de1a352fd8060601f20\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6356\n",
            "Started MLflow run 'RandomForest-FeatureReduction' with ID a7cfc0187a3b41e7bb015c8d0925ec12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: a7cfc0187a3b41e7bb015c8d0925ec12\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6423\n",
            "\n",
            "Model Comparison:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      model_name  val_accuracy  val_precision  val_recall  \\\n",
              "0           RandomForest-Default         0.665       0.555556    0.214286   \n",
              "1             RandomForest-Tuned         0.665       0.555556    0.214286   \n",
              "2  RandomForest-FeatureReduction         0.665       0.555556    0.214286   \n",
              "\n",
              "     val_f1  val_roc_auc                            run_id  \n",
              "0  0.309278     0.623077  4bce6674e96248deaa3eabf58da39748  \n",
              "1  0.309278     0.635604  7c320ab775db4de1a352fd8060601f20  \n",
              "2  0.309278     0.642308  a7cfc0187a3b41e7bb015c8d0925ec12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_f1</th>\n",
              "      <th>val_roc_auc</th>\n",
              "      <th>run_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest-Default</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.623077</td>\n",
              "      <td>4bce6674e96248deaa3eabf58da39748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest-Tuned</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.635604</td>\n",
              "      <td>7c320ab775db4de1a352fd8060601f20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest-FeatureReduction</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.642308</td>\n",
              "      <td>a7cfc0187a3b41e7bb015c8d0925ec12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f16b574d-76df-45ef-abe9-e1a706d09903\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f16b574d-76df-45ef-abe9-e1a706d09903')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f16b574d-76df-45ef-abe9-e1a706d09903 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_687fac13-b2fa-405f-a82f-9780b420b66f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_687fac13-b2fa-405f-a82f-9780b420b66f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RandomForest-Default\",\n          \"RandomForest-Tuned\",\n          \"RandomForest-FeatureReduction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.665,\n        \"max\": 0.665,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5555555555555556,\n        \"max\": 0.5555555555555556,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5555555555555556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.21428571428571427,\n        \"max\": 0.21428571428571427,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.21428571428571427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.30927835051546393,\n        \"max\": 0.30927835051546393,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.30927835051546393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009761269041694935,\n        \"min\": 0.6230769230769231,\n        \"max\": 0.6423076923076924,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6230769230769231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"4bce6674e96248deaa3eabf58da39748\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Select Best Model and Register in Model Registry"
      ],
      "metadata": {
        "id": "JP5ZERYjyRIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def register_best_model(models):\n",
        "    \"\"\"\n",
        "    Select the best model based on validation metrics and register in model registry\n",
        "\n",
        "    Args:\n",
        "        models: List of (name, model, metrics, run_id) tuples\n",
        "\n",
        "    Returns:\n",
        "        best_model: Best model object\n",
        "        best_run_id: MLflow run ID of best model\n",
        "    \"\"\"\n",
        "    # Create a sorted list based on validation F1 score\n",
        "    sorted_models = sorted(models, key=lambda x: x[2]['val_f1'], reverse=True)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model_name, best_model, best_metrics, best_run_id = sorted_models[0]\n",
        "\n",
        "    print(f\"Best model: {best_model_name}\")\n",
        "    print(f\"Validation F1 score: {best_metrics['val_f1']:.4f}\")\n",
        "    print(f\"Validation ROC AUC: {best_metrics['val_roc_auc']:.4f}\")\n",
        "\n",
        "    # Register the model in MLflow model registry\n",
        "    model_uri = f\"runs:/{best_run_id}/model\"\n",
        "    registered_model_name = \"telco_churn_predictor\"\n",
        "\n",
        "    registered_model = mlflow.register_model(model_uri, registered_model_name)\n",
        "    print(f\"Registered model '{registered_model_name}' version {registered_model.version}\")\n",
        "\n",
        "    # Create model directory\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Save the model locally\n",
        "    model_path = models_dir / f\"{registered_model_name}_v{registered_model.version}.pkl\"\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "\n",
        "    # Save model metadata\n",
        "    model_metadata = {\n",
        "        \"model_name\": registered_model_name,\n",
        "        \"model_version\": registered_model.version,\n",
        "        \"run_id\": best_run_id,\n",
        "        \"data_version\": initial_version,\n",
        "        \"metrics\": best_metrics,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"description\": f\"Telco churn prediction model version {registered_model.version}\"\n",
        "    }\n",
        "\n",
        "    metadata_path = models_dir / f\"{registered_model_name}_v{registered_model.version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "    return best_model, best_run_id, registered_model.version\n",
        "\n",
        "# Register best model\n",
        "best_model, best_run_id, model_version = register_best_model(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGYJqTb6yXk-",
        "outputId": "51516df1-36e0-47b3-dadb-5795ccb004f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForest-Default\n",
            "Validation F1 score: 0.3093\n",
            "Validation ROC AUC: 0.6231\n",
            "Registered model 'telco_churn_predictor' version 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Registered model 'telco_churn_predictor' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'telco_churn_predictor'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Automated Validation (CI)"
      ],
      "metadata": {
        "id": "JecA3eMgybfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Create Validation Test Suite"
      ],
      "metadata": {
        "id": "wJX8teUNyZdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_validation_test_suite():\n",
        "    \"\"\"\n",
        "    Create a validation test suite for the ML pipeline\n",
        "\n",
        "    Returns:\n",
        "        test_suite: Dictionary of test functions\n",
        "    \"\"\"\n",
        "    # Dictionary to store test functions\n",
        "    test_suite = {}\n",
        "\n",
        "    # Test 1: Feature pipeline validation\n",
        "    def test_feature_pipeline(X_sample, preprocessor):\n",
        "        \"\"\"Test that the feature pipeline correctly transforms data\"\"\"\n",
        "        try:\n",
        "            # Transform a sample\n",
        "            X_transformed = preprocessor.transform(X_sample)\n",
        "\n",
        "            # Check output shape and type\n",
        "            assert X_transformed is not None, \"Preprocessor output is None\"\n",
        "            assert X_transformed.shape[0] == X_sample.shape[0], \"Output has wrong number of samples\"\n",
        "            assert not np.isnan(X_transformed).any(), \"Output contains NaN values\"\n",
        "            assert not np.isinf(X_transformed).any(), \"Output contains infinite values\"\n",
        "\n",
        "            return True, \"Feature pipeline validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Feature pipeline validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_feature_pipeline\"] = test_feature_pipeline\n",
        "\n",
        "    # Test 2: Model prediction validation\n",
        "    def test_model_predictions(model, X_sample):\n",
        "        \"\"\"Test that the model produces valid predictions\"\"\"\n",
        "        try:\n",
        "            # Generate predictions\n",
        "            predictions = model.predict(X_sample)\n",
        "            probabilities = model.predict_proba(X_sample)\n",
        "\n",
        "            # Check predictions\n",
        "            assert predictions is not None, \"Predictions are None\"\n",
        "            assert predictions.shape[0] == X_sample.shape[0], \"Wrong number of predictions\"\n",
        "            assert set(np.unique(predictions)).issubset({0, 1}), \"Predictions are not binary\"\n",
        "            assert probabilities.shape == (X_sample.shape[0], 2), \"Probability shape is incorrect\"\n",
        "            assert np.allclose(np.sum(probabilities, axis=1), 1.0), \"Probabilities don't sum to 1\"\n",
        "            assert np.all(probabilities >= 0) and np.all(probabilities <= 1), \"Probabilities outside [0,1]\"\n",
        "\n",
        "            return True, \"Model prediction validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Model prediction validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_model_predictions\"] = test_model_predictions\n",
        "\n",
        "    # Test 3: Feature importance validation\n",
        "    def test_feature_importance(model):\n",
        "        \"\"\"Test that feature importances are available and valid\"\"\"\n",
        "        try:\n",
        "            # Get the classifier from the pipeline\n",
        "            classifier = model.named_steps['classifier']\n",
        "\n",
        "            # Check feature importances\n",
        "            assert hasattr(classifier, 'feature_importances_'), \"Model has no feature_importances_ attribute\"\n",
        "            importances = classifier.feature_importances_\n",
        "            assert importances is not None, \"Feature importances are None\"\n",
        "            assert len(importances) > 0, \"No feature importances available\"\n",
        "            assert np.all(importances >= 0), \"Negative feature importances found\"\n",
        "            assert np.isclose(np.sum(importances), 1.0), \"Feature importances don't sum to 1\"\n",
        "\n",
        "            return True, \"Feature importance validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Feature importance validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_feature_importance\"] = test_feature_importance\n",
        "\n",
        "    # Test 4: Model serialization validation\n",
        "    def test_model_serialization(model):\n",
        "        \"\"\"Test that the model can be serialized and deserialized\"\"\"\n",
        "        try:\n",
        "            # Serialize model\n",
        "            serialized = pickle.dumps(model)\n",
        "\n",
        "            # Deserialize model\n",
        "            deserialized_model = pickle.loads(serialized)\n",
        "\n",
        "            # Check if model works after deserialization\n",
        "            assert deserialized_model is not None, \"Deserialized model is None\"\n",
        "            assert hasattr(deserialized_model, 'predict'), \"Deserialized model has no predict method\"\n",
        "            assert hasattr(deserialized_model, 'predict_proba'), \"Deserialized model has no predict_proba method\"\n",
        "\n",
        "            return True, \"Model serialization validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Model serialization validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_model_serialization\"] = test_model_serialization\n",
        "\n",
        "    # Test 5: Lightweight retraining validation\n",
        "    def test_lightweight_retraining(model, X_sample, y_sample):\n",
        "        \"\"\"Test that the model can be retrained with new data\"\"\"\n",
        "        try:\n",
        "            # Clone the model to avoid modifying the original\n",
        "            model_copy = pickle.loads(pickle.dumps(model))\n",
        "\n",
        "            # Fit on a small sample\n",
        "            model_copy.fit(X_sample, y_sample)\n",
        "\n",
        "            # Check predictions\n",
        "            predictions = model_copy.predict(X_sample)\n",
        "            assert predictions is not None, \"Predictions after retraining are None\"\n",
        "            assert predictions.shape[0] == X_sample.shape[0], \"Wrong number of predictions after retraining\"\n",
        "\n",
        "            return True, \"Lightweight retraining validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Lightweight retraining validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_lightweight_retraining\"] = test_lightweight_retraining\n",
        "\n",
        "    return test_suite\n",
        "\n",
        "# Create validation test suite\n",
        "test_suite = create_validation_test_suite()"
      ],
      "metadata": {
        "id": "PHGBv5Xcyd-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Run Validation Tests"
      ],
      "metadata": {
        "id": "6CYbjJxeyhMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation_tests(test_suite, model, preprocessor, data_splits):\n",
        "    \"\"\"\n",
        "    Run all validation tests and report results\n",
        "\n",
        "    Args:\n",
        "        test_suite: Dictionary of test functions\n",
        "        model: Model to validate\n",
        "        preprocessor: Preprocessor pipeline\n",
        "        data_splits: Data splits dictionary\n",
        "\n",
        "    Returns:\n",
        "        results: Dictionary of test results\n",
        "    \"\"\"\n",
        "    print(f\"Running validation tests for model...\")\n",
        "\n",
        "    # Create test dataset (small sample)\n",
        "    X_sample = data_splits['X_val'].sample(min(100, len(data_splits['X_val'])), random_state=42)\n",
        "    y_sample = data_splits['y_val'].loc[X_sample.index]\n",
        "\n",
        "    # Run all tests\n",
        "    results = {}\n",
        "\n",
        "    # Test 1: Feature pipeline validation\n",
        "    success, message = test_suite[\"test_feature_pipeline\"](X_sample, preprocessor)\n",
        "    results[\"Feature Pipeline\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Feature Pipeline Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 2: Model prediction validation\n",
        "    success, message = test_suite[\"test_model_predictions\"](model, X_sample)\n",
        "    results[\"Model Predictions\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Model Predictions Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 3: Feature importance validation\n",
        "    success, message = test_suite[\"test_feature_importance\"](model)\n",
        "    results[\"Feature Importance\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Feature Importance Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 4: Model serialization validation\n",
        "    success, message = test_suite[\"test_model_serialization\"](model)\n",
        "    results[\"Model Serialization\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Model Serialization Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 5: Lightweight retraining validation\n",
        "    success, message = test_suite[\"test_lightweight_retraining\"](model, X_sample, y_sample)\n",
        "    results[\"Lightweight Retraining\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Lightweight Retraining Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Calculate overall success rate\n",
        "    success_count = sum(1 for test in results.values() if test[\"success\"])\n",
        "    success_rate = success_count / len(results)\n",
        "    print(f\"\\nValidation summary: {success_count}/{len(results)} tests passed ({success_rate:.0%})\")\n",
        "\n",
        "    # Save test results\n",
        "    validation_dir = Path(\"validation\")\n",
        "    validation_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    results_path = validation_dir / f\"validation_results_{timestamp}.json\"\n",
        "\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"model_version\": model_version,\n",
        "            \"data_version\": initial_version,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"tests\": {name: {\"success\": result[\"success\"], \"message\": result[\"message\"]}\n",
        "                      for name, result in results.items()}\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"Test results saved to {results_path}\")\n",
        "\n",
        "    if success_rate == 1.0:\n",
        "        print(\"All validation tests passed! Model is ready for deployment.\")\n",
        "    else:\n",
        "        print(\"Some validation tests failed. Review issues before deployment.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run validation tests\n",
        "validation_results = run_validation_tests(test_suite, best_model, preprocessor, data_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNPSP5PMyiKB",
        "outputId": "6614040a-128c-4ab6-961b-2a22682eefe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running validation tests for model...\n",
            "- Feature Pipeline Test:  Feature pipeline validation passed\n",
            "- Model Predictions Test:  Model prediction validation passed\n",
            "- Feature Importance Test:  Feature importance validation passed\n",
            "- Model Serialization Test:  Model serialization validation passed\n",
            "- Lightweight Retraining Test:  Lightweight retraining validation passed\n",
            "\n",
            "Validation summary: 5/5 tests passed (100%)\n",
            "Test results saved to validation/validation_results_20250512_172144.json\n",
            "All validation tests passed! Model is ready for deployment.\n"
          ]
        }
      ]
    }
  ]
}