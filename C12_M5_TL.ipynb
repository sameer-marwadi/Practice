{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Environment Setup"
      ],
      "metadata": {
        "id": "1xYX7QszxC9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As necessary, install the required Python packages"
      ],
      "metadata": {
        "id": "IOQaubgDxEhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHstEYgv3jk",
        "outputId": "fa33f586-7436-4ade-88c1-e714a3126e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.22.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.22.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.52.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.2.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn mlflow flask scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core data and ML libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pickle\n",
        "import os\n",
        "import datetime\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import logging\n",
        "import uuid\n",
        "\n",
        "# For model registry and experiment tracking\n",
        "import mlflow\n",
        "\n",
        "# For model serving\n",
        "import flask\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# For drift detection and monitoring\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "674U5eQlxPXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Intake & Feature Management"
      ],
      "metadata": {
        "id": "yCYEFto3xSY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Data Collection"
      ],
      "metadata": {
        "id": "9lr4cl1nxTbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download and load the dataset\n",
        "def get_raw_data():\n",
        "    \"\"\"\n",
        "    Downloads the telco churn dataset or loads it if already exists\n",
        "    Returns the raw dataframe\n",
        "    \"\"\"\n",
        "    # In a real scenario, this might be pulling from a database or API\n",
        "    # For this example, we'll use a local CSV file or download it if it doesn't exist\n",
        "\n",
        "    # Create data directory if it doesn't exist\n",
        "    data_dir = Path(\"data\")\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    raw_data_path = data_dir / \"telco_churn_raw.csv\"\n",
        "\n",
        "    # Check if we already have the file\n",
        "    if not raw_data_path.exists():\n",
        "        # If not, we'll create a simple synthetic dataset\n",
        "        print(\"Creating synthetic telco churn dataset...\")\n",
        "\n",
        "        # Create synthetic data\n",
        "        np.random.seed(42)\n",
        "        n_samples = 1000\n",
        "\n",
        "        # Generate synthetic features\n",
        "        data = {\n",
        "            'customer_id': [f'CUST-{i:05d}' for i in range(n_samples)],\n",
        "            'gender': np.random.choice(['Male', 'Female'], size=n_samples),\n",
        "            'senior_citizen': np.random.choice([0, 1], size=n_samples),\n",
        "            'partner': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'dependents': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'tenure': np.random.randint(0, 72, size=n_samples),\n",
        "            'phone_service': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'multiple_lines': np.random.choice(['Yes', 'No', 'No phone service'], size=n_samples),\n",
        "            'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], size=n_samples),\n",
        "            'online_security': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'online_backup': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'streaming_tv': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'streaming_movies': np.random.choice(['Yes', 'No', 'No internet service'], size=n_samples),\n",
        "            'contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], size=n_samples),\n",
        "            'paperless_billing': np.random.choice(['Yes', 'No'], size=n_samples),\n",
        "            'payment_method': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], size=n_samples),\n",
        "            'monthly_charges': np.random.uniform(20, 120, size=n_samples),\n",
        "            'total_charges': np.random.uniform(100, 8000, size=n_samples),\n",
        "        }\n",
        "\n",
        "        # Churn is more likely for month-to-month contracts and high monthly charges\n",
        "        probabilities = []\n",
        "        for i in range(n_samples):\n",
        "            prob = 0.2  # Base probability\n",
        "            if data['contract'][i] == 'Month-to-month':\n",
        "                prob += 0.2\n",
        "            if data['monthly_charges'][i] > 80:\n",
        "                prob += 0.15\n",
        "            if data['tenure'][i] < 12:\n",
        "                prob += 0.15\n",
        "            probabilities.append(min(prob, 0.9))\n",
        "\n",
        "        data['churn'] = np.random.binomial(1, probabilities)\n",
        "        data['churn'] = ['Yes' if x == 1 else 'No' for x in data['churn']]\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(raw_data_path, index=False)\n",
        "        print(f\"Dataset saved to {raw_data_path}\")\n",
        "    else:\n",
        "        print(f\"Loading dataset from {raw_data_path}\")\n",
        "        df = pd.DataFrame(pd.read_csv(raw_data_path))\n",
        "\n",
        "    # Record data intake in our log\n",
        "    logging.basicConfig(filename='mlops_pipeline.log', level=logging.INFO)\n",
        "    logging.info(f\"Data ingested at {datetime.datetime.now()}: {len(df)} records\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the raw data\n",
        "raw_data = get_raw_data()\n",
        "\n",
        "# Display first few rows\n",
        "print(f\"Loaded {len(raw_data)} rows\")\n",
        "raw_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "w9w6gwKtxVrf",
        "outputId": "57041b08-e4bf-4901-ed39-dadfc1382952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from data/telco_churn_raw.csv\n",
            "Loaded 1000 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  customer_id  gender  senior_citizen partner dependents  tenure  \\\n",
              "0  CUST-00000    Male               1     Yes         No       6   \n",
              "1  CUST-00001  Female               0      No         No      34   \n",
              "2  CUST-00002    Male               0      No         No      54   \n",
              "3  CUST-00003    Male               0      No         No      13   \n",
              "4  CUST-00004    Male               0      No        Yes       9   \n",
              "\n",
              "  phone_service    multiple_lines internet_service      online_security  \\\n",
              "0            No               Yes               No                  Yes   \n",
              "1            No  No phone service      Fiber optic  No internet service   \n",
              "2           Yes  No phone service               No                  Yes   \n",
              "3            No  No phone service      Fiber optic                  Yes   \n",
              "4            No  No phone service               No                  Yes   \n",
              "\n",
              "         online_backup         tech_support streaming_tv     streaming_movies  \\\n",
              "0                  Yes  No internet service          Yes                  Yes   \n",
              "1                  Yes                   No           No                   No   \n",
              "2                  Yes  No internet service           No                  Yes   \n",
              "3                   No                  Yes           No  No internet service   \n",
              "4  No internet service  No internet service          Yes                   No   \n",
              "\n",
              "         contract paperless_billing    payment_method  monthly_charges  \\\n",
              "0        Two year                No     Bank transfer        26.875095   \n",
              "1        One year               Yes       Credit card        70.739409   \n",
              "2  Month-to-month                No       Credit card        52.891978   \n",
              "3        One year               Yes  Electronic check        70.831169   \n",
              "4  Month-to-month               Yes       Credit card        22.397545   \n",
              "\n",
              "   total_charges churn  \n",
              "0    4951.885351    No  \n",
              "1    1586.779855    No  \n",
              "2    2353.696176    No  \n",
              "3    3859.820909    No  \n",
              "4    7639.333018   Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>senior_citizen</th>\n",
              "      <th>partner</th>\n",
              "      <th>dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>phone_service</th>\n",
              "      <th>multiple_lines</th>\n",
              "      <th>internet_service</th>\n",
              "      <th>online_security</th>\n",
              "      <th>online_backup</th>\n",
              "      <th>tech_support</th>\n",
              "      <th>streaming_tv</th>\n",
              "      <th>streaming_movies</th>\n",
              "      <th>contract</th>\n",
              "      <th>paperless_billing</th>\n",
              "      <th>payment_method</th>\n",
              "      <th>monthly_charges</th>\n",
              "      <th>total_charges</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUST-00000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer</td>\n",
              "      <td>26.875095</td>\n",
              "      <td>4951.885351</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CUST-00001</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>70.739409</td>\n",
              "      <td>1586.779855</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUST-00002</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>54</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>52.891978</td>\n",
              "      <td>2353.696176</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CUST-00003</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>13</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.831169</td>\n",
              "      <td>3859.820909</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CUST-00004</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>22.397545</td>\n",
              "      <td>7639.333018</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc16684a-fbc1-4f25-b679-4dd7ff80f85f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6f1f5cd-5072-4de3-b0cc-4eb3a8bdf122 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_data",
              "summary": "{\n  \"name\": \"raw_data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"CUST-00521\",\n          \"CUST-00737\",\n          \"CUST-00740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senior_citizen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partner\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dependents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 71,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          9,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_lines\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No phone service\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"internet_service\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"No\",\n          \"Fiber optic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"online_security\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No internet service\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"online_backup\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tech_support\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"No internet service\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"streaming_tv\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"streaming_movies\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Two year\",\n          \"One year\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paperless_billing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payment_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Credit card\",\n          \"Mailed check\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"monthly_charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.8709966659831,\n        \"min\": 20.02408745178665,\n        \"max\": 119.95051897085165,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          40.146149579316045,\n          113.7987865459497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2270.0411316649793,\n        \"min\": 119.39123290636934,\n        \"max\": 7997.418321412529,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          3955.675234530337,\n          3385.7406101684564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"churn\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Data Versioning"
      ],
      "metadata": {
        "id": "q9Mr1p4bxZPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_versioned_dataset(df, version=None):\n",
        "    \"\"\"\n",
        "    Create a versioned snapshot of the dataset\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to version\n",
        "        version: Version string (if None, a timestamp will be used)\n",
        "\n",
        "    Returns:\n",
        "        version: The version string used\n",
        "        path: Path to the saved versioned data\n",
        "    \"\"\"\n",
        "    # Create versioned data directory\n",
        "    versioned_data_dir = Path(\"data/versioned\")\n",
        "    versioned_data_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Generate version if not provided\n",
        "    if version is None:\n",
        "        version = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save versioned data\n",
        "    versioned_path = versioned_data_dir / f\"telco_data_v{version}.csv\"\n",
        "    df.to_csv(versioned_path, index=False)\n",
        "\n",
        "    # Save version metadata\n",
        "    metadata = {\n",
        "        \"version\": version,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows\": len(df),\n",
        "        \"num_features\": len(df.columns),\n",
        "        \"feature_names\": list(df.columns),\n",
        "        \"description\": f\"Telco churn data version {version}\"\n",
        "    }\n",
        "\n",
        "    metadata_path = versioned_data_dir / f\"telco_data_v{version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    print(f\"Created versioned dataset {version} at {versioned_path}\")\n",
        "    logging.info(f\"Created versioned dataset {version} with {len(df)} records at {datetime.datetime.now()}\")\n",
        "\n",
        "    return version, versioned_path\n",
        "\n",
        "# Create a versioned snapshot of our raw data\n",
        "initial_version, versioned_raw_path = create_versioned_dataset(raw_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7MVkufMxjSa",
        "outputId": "e2e84e34-7597-490a-853c-79d42ab9455d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created versioned dataset 20250512_172103 at data/versioned/telco_data_v20250512_172103.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Data Cleaning and Validation"
      ],
      "metadata": {
        "id": "bz9vWnRpxgwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_validate_data(df, version):\n",
        "    \"\"\"\n",
        "    Clean and validate the data\n",
        "\n",
        "    Args:\n",
        "        df: Raw DataFrame\n",
        "        version: Version string for tracking\n",
        "\n",
        "    Returns:\n",
        "        cleaned_df: Cleaned DataFrame\n",
        "        validation_report: Dictionary with validation results\n",
        "    \"\"\"\n",
        "    print(f\"Cleaning and validating data version {version}...\")\n",
        "\n",
        "    # Create a copy to avoid modifying the original\n",
        "    df_cleaned = df.copy()\n",
        "\n",
        "    # Track cleaning operations\n",
        "    cleaning_ops = []\n",
        "    validation_issues = []\n",
        "\n",
        "    # Check for and handle missing values\n",
        "    missing_values = df_cleaned.isnull().sum()\n",
        "    if missing_values.sum() > 0:\n",
        "        cleaning_ops.append(f\"Found {missing_values.sum()} missing values\")\n",
        "        for col in missing_values[missing_values > 0].index:\n",
        "            cleaning_ops.append(f\"Column {col} has {missing_values[col]} missing values\")\n",
        "\n",
        "            # Handle missing values based on data type\n",
        "            if df_cleaned[col].dtype == 'object':\n",
        "                # For categorical, fill with mode\n",
        "                df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].mode()[0])\n",
        "                cleaning_ops.append(f\"Filled missing values in {col} with mode: {df_cleaned[col].mode()[0]}\")\n",
        "            else:\n",
        "                # For numerical, fill with median\n",
        "                df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
        "                cleaning_ops.append(f\"Filled missing values in {col} with median: {df_cleaned[col].median()}\")\n",
        "\n",
        "    # Handle TotalCharges - convert to numeric if string\n",
        "    if df_cleaned['total_charges'].dtype == 'object':\n",
        "        cleaning_ops.append(\"Converting total_charges to numeric\")\n",
        "        df_cleaned['total_charges'] = pd.to_numeric(df_cleaned['total_charges'], errors='coerce')\n",
        "        # Fill any new missing values\n",
        "        df_cleaned['total_charges'] = df_cleaned['total_charges'].fillna(df_cleaned['total_charges'].median())\n",
        "\n",
        "    # Data validation checks\n",
        "\n",
        "    # 1. Check for negative values in numerical columns that should be positive\n",
        "    for col in ['tenure', 'monthly_charges', 'total_charges']:\n",
        "        neg_values = (df_cleaned[col] < 0).sum()\n",
        "        if neg_values > 0:\n",
        "            validation_issues.append(f\"Found {neg_values} negative values in {col}\")\n",
        "            # Replace with absolute value\n",
        "            df_cleaned[col] = df_cleaned[col].abs()\n",
        "            cleaning_ops.append(f\"Converted {neg_values} negative values to positive in {col}\")\n",
        "\n",
        "    # 2. Check for logical consistency\n",
        "    if 'tenure' in df_cleaned.columns and 'total_charges' in df_cleaned.columns:\n",
        "        inconsistent = ((df_cleaned['tenure'] > 0) & (df_cleaned['total_charges'] <= 0)).sum()\n",
        "        if inconsistent > 0:\n",
        "            validation_issues.append(f\"Found {inconsistent} rows with tenure > 0 but total_charges <= 0\")\n",
        "            # Fix by setting total_charges to at least monthly_charges\n",
        "            mask = (df_cleaned['tenure'] > 0) & (df_cleaned['total_charges'] <= 0)\n",
        "            df_cleaned.loc[mask, 'total_charges'] = df_cleaned.loc[mask, 'monthly_charges']\n",
        "            cleaning_ops.append(f\"Fixed {inconsistent} rows with inconsistent tenure and total_charges\")\n",
        "\n",
        "    # 3. Check categorical variable validity\n",
        "    for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
        "        if col == 'customer_id':  # Skip ID column\n",
        "            continue\n",
        "\n",
        "        # Count unique values\n",
        "        unique_values = df_cleaned[col].unique()\n",
        "        cleaning_ops.append(f\"Column {col} has {len(unique_values)} unique values: {unique_values}\")\n",
        "\n",
        "        # If binary Yes/No column has other values\n",
        "        if set(df_cleaned[col].unique()) - set(['Yes', 'No', 'No internet service', 'No phone service']):\n",
        "            unexpected = set(df_cleaned[col].unique()) - set(['Yes', 'No', 'No internet service', 'No phone service'])\n",
        "            validation_issues.append(f\"Column {col} has unexpected values: {unexpected}\")\n",
        "\n",
        "    # Create validation report\n",
        "    validation_report = {\n",
        "        \"data_version\": version,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows_before\": len(df),\n",
        "        \"num_rows_after\": len(df_cleaned),\n",
        "        \"cleaning_operations\": cleaning_ops,\n",
        "        \"validation_issues\": validation_issues,\n",
        "        \"columns\": list(df_cleaned.columns),\n",
        "        \"dtypes\": {col: str(df_cleaned[col].dtype) for col in df_cleaned.columns}\n",
        "    }\n",
        "\n",
        "    # Save validation report\n",
        "    validation_dir = Path(\"data/validation_reports\")\n",
        "    validation_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    validation_path = validation_dir / f\"validation_report_v{version}.json\"\n",
        "    with open(validation_path, 'w') as f:\n",
        "        json.dump(validation_report, f, indent=2)\n",
        "\n",
        "    print(f\"Data cleaning and validation complete. Report saved to {validation_path}\")\n",
        "\n",
        "    return df_cleaned, validation_report\n",
        "\n",
        "# Clean and validate our data\n",
        "cleaned_data, validation_report = clean_and_validate_data(raw_data, initial_version)\n",
        "\n",
        "# Display validation results summary\n",
        "print(\"\\nValidation Summary:\")\n",
        "print(f\"- Cleaning operations: {len(validation_report['cleaning_operations'])}\")\n",
        "print(f\"- Validation issues: {len(validation_report['validation_issues'])}\")\n",
        "if validation_report['validation_issues']:\n",
        "    for issue in validation_report['validation_issues']:\n",
        "        print(f\"  - {issue}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8V8-yVQxkOd",
        "outputId": "deda0287-70ae-4f76-db81-0434c32ac886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning and validating data version 20250512_172103...\n",
            "Data cleaning and validation complete. Report saved to data/validation_reports/validation_report_v20250512_172103.json\n",
            "\n",
            "Validation Summary:\n",
            "- Cleaning operations: 15\n",
            "- Validation issues: 4\n",
            "  - Column gender has unexpected values: {'Male', 'Female'}\n",
            "  - Column internet_service has unexpected values: {'DSL', 'Fiber optic'}\n",
            "  - Column contract has unexpected values: {'One year', 'Two year', 'Month-to-month'}\n",
            "  - Column payment_method has unexpected values: {'Electronic check', 'Bank transfer', 'Mailed check', 'Credit card'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Feature Engineering and Storage"
      ],
      "metadata": {
        "id": "GVkqe6uUxnue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df, version):\n",
        "    \"\"\"\n",
        "    Apply feature engineering transformations\n",
        "\n",
        "    Args:\n",
        "        df: Cleaned DataFrame\n",
        "        version: Version string for tracking\n",
        "\n",
        "    Returns:\n",
        "        features_df: DataFrame with engineered features\n",
        "        feature_metadata: Dictionary with feature metadata\n",
        "    \"\"\"\n",
        "    print(f\"Engineering features for data version {version}...\")\n",
        "\n",
        "    # Create a copy to avoid modifying the original\n",
        "    features_df = df.copy()\n",
        "\n",
        "    # Track feature engineering operations\n",
        "    feature_ops = []\n",
        "\n",
        "    # 1. Convert binary categorical variables to 0/1\n",
        "    binary_columns = ['partner', 'dependents', 'phone_service', 'paperless_billing']\n",
        "    for col in binary_columns:\n",
        "        if col in features_df.columns:\n",
        "            features_df[col] = features_df[col].map({'Yes': 1, 'No': 0})\n",
        "            feature_ops.append(f\"Converted {col} to binary 0/1\")\n",
        "\n",
        "    # 2. Create tenure-related features\n",
        "    if 'tenure' in features_df.columns:\n",
        "        # Tenure in years\n",
        "        features_df['tenure_years'] = features_df['tenure'] / 12\n",
        "        feature_ops.append(\"Created tenure_years feature\")\n",
        "\n",
        "        # Tenure bins\n",
        "        tenure_bins = [0, 12, 24, 36, 48, 60, 72]\n",
        "        tenure_labels = ['0-1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5+ years']\n",
        "        features_df['tenure_group'] = pd.cut(features_df['tenure'], bins=tenure_bins, labels=tenure_labels, right=False)\n",
        "        feature_ops.append(\"Created tenure_group feature with 6 bins\")\n",
        "\n",
        "    # 3. Create price-related features\n",
        "    if 'monthly_charges' in features_df.columns and 'tenure' in features_df.columns:\n",
        "        # Average charge per month of tenure\n",
        "        mask = features_df['tenure'] > 0  # Avoid division by zero\n",
        "        features_df['avg_monthly_charges'] = 0\n",
        "        features_df.loc[mask, 'avg_monthly_charges'] = features_df.loc[mask, 'total_charges'] / features_df.loc[mask, 'tenure']\n",
        "        feature_ops.append(\"Created avg_monthly_charges feature\")\n",
        "\n",
        "        # Monthly charges bin\n",
        "        charge_bins = [0, 35, 70, 105, float('inf')]\n",
        "        charge_labels = ['Low', 'Medium', 'High', 'Very High']\n",
        "        features_df['monthly_charges_category'] = pd.cut(features_df['monthly_charges'], bins=charge_bins, labels=charge_labels)\n",
        "        feature_ops.append(\"Created monthly_charges_category feature with 4 bins\")\n",
        "\n",
        "    # 4. Services count feature\n",
        "    service_columns = ['phone_service', 'multiple_lines', 'internet_service', 'online_security',\n",
        "                       'online_backup', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
        "\n",
        "    # Initialize services count\n",
        "    features_df['services_count'] = 0\n",
        "\n",
        "    # Count 'Yes' values\n",
        "    for col in service_columns:\n",
        "        if col in features_df.columns:\n",
        "            features_df['services_count'] += (features_df[col] == 'Yes').astype(int)\n",
        "\n",
        "    feature_ops.append(\"Created services_count feature\")\n",
        "\n",
        "    # 5. Contract type as ordinal\n",
        "    if 'contract' in features_df.columns:\n",
        "        contract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
        "        features_df['contract_type_code'] = features_df['contract'].map(contract_map)\n",
        "        feature_ops.append(\"Created contract_type_code feature\")\n",
        "\n",
        "    # 6. Target encoding for churn prediction\n",
        "    features_df['churn_binary'] = features_df['churn'].map({'Yes': 1, 'No': 0})\n",
        "    feature_ops.append(\"Created churn_binary feature for target\")\n",
        "\n",
        "    # Create feature metadata\n",
        "    feature_metadata = {\n",
        "        \"data_version\": version,\n",
        "        \"feature_version\": f\"{version}_feat\",\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"num_rows\": len(features_df),\n",
        "        \"num_features\": len(features_df.columns),\n",
        "        \"feature_engineering_ops\": feature_ops,\n",
        "        \"numerical_features\": list(features_df.select_dtypes(include=['int64', 'float64']).columns),\n",
        "        \"categorical_features\": list(features_df.select_dtypes(include=['object']).columns),\n",
        "        \"binary_features\": [col for col in features_df.columns if features_df[col].nunique() == 2],\n",
        "        \"target_feature\": \"churn_binary\"\n",
        "    }\n",
        "\n",
        "    # Save engineered features\n",
        "    features_dir = Path(\"data/features\")\n",
        "    features_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    features_path = features_dir / f\"telco_features_v{version}.csv\"\n",
        "    features_df.to_csv(features_path, index=False)\n",
        "\n",
        "    # Save feature metadata\n",
        "    metadata_path = features_dir / f\"telco_features_v{version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(feature_metadata, f, indent=2)\n",
        "\n",
        "    print(f\"Feature engineering complete. Features saved to {features_path}\")\n",
        "    logging.info(f\"Feature engineering completed for version {version} at {datetime.datetime.now()}\")\n",
        "\n",
        "    return features_df, feature_metadata\n",
        "\n",
        "# Engineer features\n",
        "features_df, feature_metadata = engineer_features(cleaned_data, initial_version)\n",
        "\n",
        "# Display feature summary\n",
        "print(\"\\nFeature Engineering Summary:\")\n",
        "print(f\"- Original features: {len(raw_data.columns)}\")\n",
        "print(f\"- Engineered features: {len(features_df.columns)}\")\n",
        "print(f\"- New features added: {len(features_df.columns) - len(raw_data.columns)}\")\n",
        "\n",
        "# Display sample of engineered features\n",
        "features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYjuAijDxkTa",
        "outputId": "5ac77925-5522-4633-9fb3-78b378470f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engineering features for data version 20250512_172103...\n",
            "Feature engineering complete. Features saved to data/features/telco_features_v20250512_172103.csv\n",
            "\n",
            "Feature Engineering Summary:\n",
            "- Original features: 20\n",
            "- Engineered features: 27\n",
            "- New features added: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-71cee673866d>:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[8.25314225e+02 4.66699957e+01 4.35869662e+01 2.96909301e+02\n",
            " 8.48814780e+02 1.36938389e+02 1.10943446e+02 5.17629125e+01\n",
            " 5.70463733e+01 8.41303614e+01 1.20460558e+01 1.14457683e+02\n",
            " 1.01104262e+02 8.70262056e+01 1.30602476e+01 2.38914956e+02\n",
            " 2.70803064e+02 1.02516846e+02 4.63917025e+02 2.49873981e+02\n",
            " 2.03965064e+02 4.17602759e+02 6.44385998e+01 2.22358440e+01\n",
            " 1.80014994e+02 3.43760298e+01 3.14326101e+02 6.61805600e+01\n",
            " 8.49066538e+01 1.40251790e+02 7.63303226e+01 2.66563425e+02\n",
            " 1.49680606e+01 2.24232317e+03 6.58049809e+01 1.56820644e+02\n",
            " 3.40020337e+02 7.07533128e+02 6.61154918e+00 5.88138021e+01\n",
            " 5.13699511e+01 3.83920897e+00 3.00652727e+01 7.80332896e+01\n",
            " 6.01750777e+01 1.79179444e+02 1.18562718e+02 9.30114595e+01\n",
            " 1.19169246e+02 5.33772740e+01 8.81026888e+01 3.74656846e+01\n",
            " 1.34437002e+02 6.20168181e+01 4.27105391e+02 8.80690727e+01\n",
            " 7.13486086e+01 4.65187119e+01 4.39615368e+02 6.23159973e+03\n",
            " 1.87744375e+02 3.34915232e+01 2.52596840e+01 9.37778097e+01\n",
            " 1.24791469e+02 5.02368096e+01 1.09242920e+02 9.91139527e+01\n",
            " 7.93038323e+01 1.21198685e+02 7.72800487e+02 5.81508090e+01\n",
            " 3.57086098e+00 7.22688764e+01 7.76020468e+01 1.45365858e+02\n",
            " 8.74259206e+02 6.58599143e+01 2.74085646e+02 6.17179115e+01\n",
            " 8.99871559e+01 1.98485153e+02 4.39090302e+02 1.83899320e+01\n",
            " 8.51819026e+01 9.94696969e+01 7.00843363e+01 2.55310706e+02\n",
            " 8.19864499e+01 7.29498154e+01 1.20543165e+02 1.95568331e+03\n",
            " 6.78740772e+01 8.91267605e+01 1.36992079e+02 7.05241154e+02\n",
            " 4.46831088e+01 3.50995467e+01 6.62953518e+00 5.05625705e+01\n",
            " 1.43248794e+02 3.54104744e+02 2.49925527e+01 1.53528952e+02\n",
            " 4.06898207e+02 6.67648374e+02 8.11920818e+02 2.52488002e+02\n",
            " 1.92961152e+01 5.25122829e+01 2.38925610e+00 1.06618673e+02\n",
            " 3.52632810e+02 1.37272932e+02 1.98399724e+02 1.39845460e+02\n",
            " 2.76223465e+01 2.49092871e+01 4.04771690e+01 3.02459125e+02\n",
            " 2.85475221e+03 1.02213526e+03 4.32958001e+02 1.43730723e+03\n",
            " 2.58238308e+02 1.60947926e+01 2.35766053e+02 1.14241225e+02\n",
            " 7.74533202e+01 6.47226651e+01 2.07783060e+03 6.96785770e+01\n",
            " 2.88360502e+02 1.96268632e+02 1.29004262e+02 6.07486792e+02\n",
            " 5.67439645e+02 1.03577770e+02 4.75260610e+02 2.73133823e+01\n",
            " 1.74749426e+02 1.38032367e+02 4.46849376e+01 2.31564738e+02\n",
            " 3.71920120e+02 2.07775704e+02 7.06762963e+01 1.16344144e+01\n",
            " 1.08904486e+02 2.84562950e+02 2.12081882e+03 2.84872307e+01\n",
            " 4.42008682e+01 1.56357926e+02 6.41782855e+01 1.64114420e+02\n",
            " 1.93365836e+03 7.73688766e+01 8.91306918e+02 1.06978425e+02\n",
            " 7.70889512e+02 1.16125419e+02 8.89257691e+01 6.96216255e+02\n",
            " 3.69762535e+01 2.42961583e+01 3.42849213e+03 1.63468269e+02\n",
            " 3.56191497e+02 2.78104998e+02 8.58466039e+00 1.26801796e+02\n",
            " 9.00652923e+01 9.89074772e+01 1.93011226e+02 5.79165677e+01\n",
            " 8.99741447e+01 1.23890343e+02 2.03860624e+01 1.16627296e+02\n",
            " 2.22193902e+02 1.61730761e+02 1.32489451e+02 5.96470590e+01\n",
            " 6.03141101e+01 7.77905097e+01 5.54232824e+02 1.19297403e+01\n",
            " 1.89146276e+02 2.83220596e+02 9.12758532e+01 9.54081692e+00\n",
            " 1.28592787e+02 1.74934837e+02 5.04125621e+01 1.91861880e+02\n",
            " 3.62676675e+01 1.92254250e+02 1.25610118e+01 1.20388348e+02\n",
            " 4.63459940e+01 2.46051930e+02 5.54315837e+01 2.01733338e+02\n",
            " 9.03881762e+01 1.50996800e+02 3.84516530e+01 3.78688842e+01\n",
            " 3.28596078e+02 1.30564310e+01 1.31891135e+02 1.83550917e+01\n",
            " 5.14783715e+02 1.84389273e+02 1.29906621e+02 1.63476027e+02\n",
            " 1.24546580e+02 8.20869005e+01 1.91387097e+01 5.70668131e+01\n",
            " 1.12530477e+02 3.65476905e+02 8.92951838e+01 8.66277895e+01\n",
            " 1.44387964e+02 1.86282112e+02 1.32520229e+02 1.40613106e+02\n",
            " 1.73156709e+02 1.47461813e+02 5.80781437e+00 2.49782247e+02\n",
            " 3.61585372e+01 1.42638192e+02 3.44323300e+03 1.72230790e+01\n",
            " 5.22482446e+01 1.48587244e+02 1.11655887e+02 3.24539409e+01\n",
            " 9.29468058e+01 2.66657587e+02 5.79589232e+01 2.31103658e+01\n",
            " 1.62869925e+02 3.45491146e+01 1.11539043e+02 9.77226587e+01\n",
            " 1.19459277e+02 2.41251551e+02 8.65327713e+02 4.81746769e+01\n",
            " 5.46944454e+01 1.22032432e+02 2.70871816e+02 3.10986875e+01\n",
            " 1.24913107e+02 4.16255784e+01 4.53547207e+00 3.88375810e+00\n",
            " 7.16613045e+02 5.32723298e+03 6.39307367e+01 4.86682744e+01\n",
            " 1.85466795e+02 8.97254511e+01 1.18990840e+01 2.56552386e+02\n",
            " 1.68901477e+02 2.35218186e+02 1.45502928e+02 9.83367780e+01\n",
            " 3.80603899e+01 3.69344866e+01 1.03117254e+02 1.46470956e+02\n",
            " 1.73063479e+02 8.55898413e+01 1.04670253e+02 2.13698541e+02\n",
            " 4.31490360e+01 5.29626495e+02 5.87230109e+01 8.51722361e+01\n",
            " 1.11601485e+02 2.01490801e+02 2.91163239e+01 1.01251855e+02\n",
            " 1.35748831e+02 3.08960775e+01 7.08148399e+01 1.64735964e+02\n",
            " 1.46305546e+02 2.98891641e+02 2.37887208e+02 7.13767985e+01\n",
            " 3.57450252e+02 2.95979410e+02 7.43520836e+01 1.24263462e+02\n",
            " 2.93244537e+02 1.70653658e+02 1.40834218e+02 9.73140144e+02\n",
            " 4.57240249e+01 2.55618175e+01 1.47587203e+01 1.46603440e+02\n",
            " 3.32068382e+02 1.24075133e+02 8.05788800e+01 7.62412041e+01\n",
            " 2.06328219e+02 7.21131243e+01 4.14030381e+01 2.00567278e+02\n",
            " 1.12387803e+03 8.88208073e+01 2.84766930e+02 7.18490239e+01\n",
            " 1.08127336e+02 9.54163791e+02 9.94925549e+01 7.33650368e+01\n",
            " 1.18662244e+02 9.22816771e+01 1.80196399e+02 4.18526342e+02\n",
            " 8.58873873e+01 8.83028888e+01 9.88799892e+01 1.60124862e+02\n",
            " 1.75332394e+02 1.16871979e+02 1.54171139e+02 1.19917390e+02\n",
            " 1.22246006e+02 4.63320120e+02 1.81638757e+02 2.97472881e+02\n",
            " 1.13643569e+01 1.51339487e+02 6.23386538e+01 6.12554620e+01\n",
            " 8.63223809e+01 1.60017240e+02 1.05733661e+02 1.38873021e+02\n",
            " 5.55778568e+00 1.41002848e+02 5.96956165e+00 6.76823868e+01\n",
            " 1.00925733e+02 1.68692038e+02 1.40129613e+02 1.22679661e+02\n",
            " 5.55671644e+01 6.16730733e+02 9.88094358e+01 4.63798502e+02\n",
            " 3.10864317e+02 7.40209920e+02 1.27286952e+02 6.84126957e+01\n",
            " 1.07230125e+01 1.75149052e+02 4.66190416e+01 1.99721416e+01\n",
            " 4.70625494e+00 1.04882888e+02 8.78584969e+01 2.01190052e+02\n",
            " 1.79700173e+02 4.17098776e+01 6.90727979e+02 3.12643552e+02\n",
            " 3.15473349e+01 1.98944832e+02 1.31833304e+02 1.67272236e+01\n",
            " 1.50084134e+02 3.83737051e+02 5.59821157e+00 1.22323415e+01\n",
            " 1.52532019e+01 7.84135400e+01 2.29076835e+02 1.59464706e+02\n",
            " 5.67837795e+01 5.21543957e+02 7.52319010e+01 1.21012166e+01\n",
            " 2.47179418e+03 6.92865232e+01 1.18748300e+02 3.48208600e+01\n",
            " 2.27490735e+01 7.30155506e+02 6.13042109e+02 5.40676571e+01\n",
            " 8.19685855e+01 1.84536905e+02 2.88784383e+03 4.63338163e+01\n",
            " 2.78805507e+02 4.52403151e+03 9.88670704e+01 2.60435737e+03\n",
            " 5.08476693e+02 1.63511875e+02 4.16103731e+02 6.81312074e+01\n",
            " 3.47027546e+02 7.60202594e+01 8.79919020e+01 1.22731968e+02\n",
            " 1.33582415e+02 1.29766114e+02 4.69401337e+01 2.92184042e+02\n",
            " 2.79832684e+02 1.28748356e+02 1.59448213e+02 3.41555576e+01\n",
            " 3.16786726e+02 8.12341842e+01 1.41711316e+02 1.50875448e+02\n",
            " 1.17472682e+02 3.37488685e+01 1.17289509e+01 5.97562447e+01\n",
            " 1.48359476e+02 1.06442147e+02 1.12619889e+02 1.58428193e+02\n",
            " 1.40815059e+02 8.92623963e+01 9.66782103e+01 7.80878203e+01\n",
            " 6.44981150e+01 1.64851651e+02 4.34728443e+00 1.81482636e+02\n",
            " 2.91336107e+02 8.56110295e+01 1.10265003e+02 1.24093263e+02\n",
            " 2.30654504e+02 6.60105823e+01 4.43235207e+02 8.15393737e+01\n",
            " 1.26368470e+02 2.51202475e+01 3.98194732e+01 1.12654186e+02\n",
            " 1.20360392e+02 4.15220901e+02 3.42188833e+02 2.69342786e+02\n",
            " 3.06421989e+01 3.64395912e+02 7.63877674e+00 1.28547718e+02\n",
            " 3.80733000e+02 5.91542618e+01 1.86837686e+02 1.08709758e+02\n",
            " 4.06152160e+00 7.02155781e+02 9.10871082e+01 7.19940832e+01\n",
            " 1.21329488e+02 3.98083468e+01 2.51669520e+02 5.06369076e+02\n",
            " 1.08887901e+02 7.95533828e+01 7.21497164e+01 4.59574105e+01\n",
            " 1.01438001e+02 1.39051398e+02 8.99952485e+02 1.72730269e+02\n",
            " 2.25874746e+01 3.88687216e+01 6.25076574e+01 1.55838502e+01\n",
            " 1.38006645e+02 1.15444981e+03 1.30253552e+02 3.98456326e+02\n",
            " 2.59626581e+02 1.09284127e+02 1.34492417e+02 1.90684667e+02\n",
            " 1.52141772e+02 6.86427788e+01 8.68364468e+01 4.26658980e+02\n",
            " 2.28038713e+02 8.12462561e+01 1.17462995e+02 4.95157196e+02\n",
            " 3.88681190e+01 8.01676738e+01 3.43947322e+01 1.43242059e+02\n",
            " 1.02088047e+02 1.09359081e+02 5.25241970e+01 9.63629551e+01\n",
            " 2.22603317e+01 1.09746446e+03 1.63376581e+02 8.65813838e+01\n",
            " 7.91135047e+01 1.67444637e+02 9.47238901e+01 7.39080357e+01\n",
            " 4.89101643e+02 9.05548887e+01 1.18261881e+02 2.71106808e+02\n",
            " 1.58651134e+02 2.95993707e+01 6.26362810e+01 7.61397452e+01\n",
            " 2.48350540e+02 2.95718424e+02 1.24271102e+01 9.58441551e+02\n",
            " 7.64841409e+01 8.78648474e+02 3.36042282e+02 9.97830976e+01\n",
            " 1.99231869e+02 9.81684386e+00 3.27140404e+02 1.15892422e+02\n",
            " 1.66588479e+02 7.31875518e+01 3.13302548e+02 2.82537707e+02\n",
            " 7.54789881e+02 5.52445357e+02 6.50388951e+01 3.36220454e+02\n",
            " 1.22914480e+02 2.16362693e+01 4.59917146e+02 2.28303717e+01\n",
            " 2.58169117e+02 2.37773101e+02 2.80880262e+02 7.98660588e+01\n",
            " 4.52469634e+01 2.78932486e+01 1.29751663e+02 4.53433047e+01\n",
            " 5.67928136e+01 7.17576185e+01 4.43507280e+02 1.47982456e+02\n",
            " 4.56196056e+01 5.90537432e+01 1.31394081e+02 8.94962848e+01\n",
            " 1.25459914e+02 2.39553476e+03 1.20395987e+03 7.92712214e+01\n",
            " 1.62220531e+02 4.17633053e+00 6.99318394e+01 1.01081845e+02\n",
            " 1.26090631e+02 3.64087654e+01 6.73166501e+01 7.48072082e+01\n",
            " 6.14280850e+01 8.59000766e+01 5.97482840e+02 1.17960327e+02\n",
            " 2.85881182e+01 2.48939568e+02 1.04261605e+02 3.05753555e+01\n",
            " 1.22839622e+01 8.58628595e+01 1.10969273e+02 2.91787679e+01\n",
            " 3.92101714e+01 1.16252939e+02 7.49768020e+01 1.63807193e+02\n",
            " 2.65854882e+02 6.39302115e+01 3.70536897e+01 2.66543210e+02\n",
            " 2.94761265e+00 1.53256352e+02 4.93486853e+01 4.21308120e+02\n",
            " 4.00603936e+02 1.43151161e+02 8.12321836e+01 1.63537431e+02\n",
            " 4.35286784e+02 6.78070339e+01 9.17591310e+01 1.24127449e+01\n",
            " 7.85310465e+00 1.03298023e+02 3.82022850e+02 4.97504001e+01\n",
            " 2.93293645e+02 2.37371486e+02 1.10825508e+03 1.72342768e+01\n",
            " 1.43982840e+01 2.24665932e+02 1.88317096e+01 9.18867452e+01\n",
            " 2.89371370e+01 1.19308348e+02 1.24852194e+02 8.38328966e+01\n",
            " 2.53916148e+03 2.60834485e+02 8.81536377e+01 2.42830223e+03\n",
            " 2.84168193e+02 4.93866173e+01 1.72317991e+02 1.47363018e+02\n",
            " 1.06242567e+02 3.22003144e+01 3.12608508e+01 1.16415227e+02\n",
            " 6.61156037e+01 2.24778330e+02 3.04744107e+01 4.47446814e+02\n",
            " 5.39477084e+00 1.02900416e+02 1.85884862e+01 5.91988041e+02\n",
            " 1.06640070e+02 4.66965025e+01 1.38483701e+02 6.76311811e+01\n",
            " 2.28491134e+01 9.83934196e+02 6.08857381e+01 1.24942129e+02\n",
            " 2.77327833e+01 8.22689169e+01 1.09152704e+02 1.85544801e+02\n",
            " 2.62678212e+02 1.45689237e+02 1.03724951e+02 7.50379451e+01\n",
            " 3.84173620e+02 6.15925242e+01 7.47524778e+00 4.04212031e+01\n",
            " 2.00886210e+02 2.13806704e+02 2.13661125e+01 4.42398536e+01\n",
            " 2.38210708e+02 9.89192148e+01 5.28806538e+02 8.69940231e+01\n",
            " 6.58103671e+01 1.19447067e+02 1.59854928e+02 6.54305523e+01\n",
            " 4.50708156e+02 6.97022675e+01 2.90847375e+02 5.50179412e+01\n",
            " 3.20941157e+02 3.55733530e+02 6.93323545e+01 1.03321731e+02\n",
            " 1.17376286e+03 1.26697334e+02 5.22283108e+02 5.43636306e+02\n",
            " 1.26301418e+02 5.75644233e+01 3.48930421e+01 6.18019006e+01\n",
            " 2.42736312e+02 2.87062631e+02 1.49734362e+02 4.75587382e+01\n",
            " 5.57619890e+02 1.12680648e+01 1.31170122e+03 1.16472766e+02\n",
            " 7.70777813e+01 2.96210888e+00 5.14772090e+01 1.94628235e+02\n",
            " 4.93542661e+02 9.88145513e+01 1.16982427e+02 7.66586517e+02\n",
            " 2.12887453e+02 8.03101373e+01 1.02543171e+02 1.88576580e+01\n",
            " 2.62518541e+02 1.41229180e+02 2.85617658e+02 1.40262020e+02\n",
            " 6.90290085e+01 2.93786552e+01 9.38147867e+01 1.13813008e+02\n",
            " 2.03079159e+02 1.83347451e+01 1.21142802e+02 2.10882116e+01\n",
            " 1.49199238e+01 6.26989002e+01 2.79168190e+02 1.61126091e+02\n",
            " 1.39457994e+02 3.04353958e+02 3.57412955e+02 1.76946149e+02\n",
            " 9.36920116e+01 7.54104929e+02 2.67981195e+02 9.95143308e+01\n",
            " 6.48665430e+01 3.71529024e+01 2.71116101e+02 1.46637474e+01\n",
            " 1.07078181e+02 3.95886593e+01 3.16016655e+02 1.66753553e+02\n",
            " 1.39584554e+02 1.63955906e+02 8.93803278e+01 2.36302132e+02\n",
            " 1.06433509e+02 5.94227530e+02 5.25651973e+02 8.13473484e+01\n",
            " 4.40556648e+03 1.24585876e+02 4.50867739e+02 1.06088736e+02\n",
            " 1.25848232e+02 1.30520438e+02 7.67158748e+01 7.26863988e+00\n",
            " 8.63501667e+02 2.10971651e+02 8.35477919e+02 8.49343181e+00\n",
            " 1.91535362e+02 3.94454319e+03 3.31659055e+01 4.99590710e+01\n",
            " 5.87554560e+01 3.62509809e+02 2.58066180e+02 3.73173624e+01\n",
            " 1.39883683e+01 7.89748955e+01 1.37865641e+02 4.50788890e+02\n",
            " 6.31689416e+00 2.40386241e+01 1.04195106e+02 1.97525353e+02\n",
            " 1.32210435e+02 1.30899538e+01 3.91806014e+01 1.53627422e+02\n",
            " 7.82511380e+01 4.71119062e+02 4.28621691e+01 2.13824479e+02\n",
            " 5.83623794e+03 1.98797340e+02 7.38698576e+02 1.43147026e+02\n",
            " 1.32252991e+02 2.25268745e+03 2.91025668e+02 1.27975347e+02\n",
            " 6.19167117e+01 1.22308767e+02 1.16683268e+02 1.45542230e+02\n",
            " 1.63002226e+02 1.27601654e+02 3.78131823e+01 1.25335491e+02\n",
            " 4.21130587e+02 9.59477019e+01 7.75705677e+01 2.00533572e+01\n",
            " 6.24795641e+01 5.46047923e+01 1.37840474e+02 5.51305447e+01\n",
            " 2.14773413e+02 1.51173514e+02 5.58647927e+02 7.32320265e+02\n",
            " 2.80843060e+02 2.21206549e+02 2.53168817e+01 4.88180319e+01\n",
            " 4.58043854e+02 7.71703373e+00 4.38734391e+02 4.56871895e+02\n",
            " 7.41532777e+01 9.91047328e+02 1.01176665e+02 9.89556455e+01\n",
            " 1.73481774e+02 8.03332174e+01 1.55706019e+02 9.51422498e+01\n",
            " 8.04133413e+01 2.73975737e+01 2.31747100e+01 1.64501792e+02\n",
            " 2.25043469e+02 2.26412925e+01 2.24095626e+03 5.61065116e+02\n",
            " 1.38768880e+03 1.41346811e+02 1.55322410e+01 5.15690699e+02\n",
            " 3.53616548e+01 1.18680540e+02 3.25065033e+02 4.53713029e+02\n",
            " 7.06954521e+01 6.84775235e+01 1.01685070e+02 2.67151739e+02\n",
            " 4.41640933e+01 7.22171948e+02 8.86836725e+01 3.65992506e+02\n",
            " 6.63232316e+01 5.80672046e+01 1.12923871e+02 1.64104067e+02\n",
            " 1.19220352e+02 3.17560840e+01 1.26536396e+02 1.27778281e+02\n",
            " 1.03115430e+02 8.29607799e+01 8.14646602e+01 1.50029365e+02\n",
            " 2.19700271e+02 2.36906866e+01 2.72153700e+02 8.42785523e+02\n",
            " 4.12589207e+01 1.31531541e+02 1.09781122e+02 1.32369001e+02\n",
            " 5.89429334e+01 5.04006305e+00 2.86723402e+02 1.48633871e+01\n",
            " 3.02978502e+02 5.06887461e+01 5.30117736e+01 1.57513033e+02\n",
            " 6.39083260e+01 1.02848736e+02 2.12712214e+01 1.15834679e+02\n",
            " 6.12305353e+02 2.73535520e+03 1.30141427e+03 1.37267982e+02\n",
            " 4.83902657e+01 2.23964279e+02 1.17333354e+02 5.15247523e+02\n",
            " 1.97916934e+02 4.88722374e+01 1.12999347e+01 4.19805879e+02\n",
            " 8.15199189e+01 8.15990482e+01 1.31056381e+02 4.37406564e+01\n",
            " 4.18127893e+01 1.14673622e+02 6.39620247e+02 2.45196500e+02\n",
            " 6.29335801e+01 3.33160116e+01 2.11368045e+02 6.28365156e+02\n",
            " 2.23604607e+03 2.71594449e+02 1.11457443e+02 1.92663053e+02\n",
            " 1.50729114e+02 4.42521419e+01 4.30330513e+01 5.19723312e+01\n",
            " 2.62263503e+02 1.03401693e+03 3.10624069e+01 4.12250953e+01\n",
            " 2.04252216e+02 5.12987054e+00 1.46690209e+02 3.29852831e+02\n",
            " 1.10043016e+01 2.10018288e+02 4.45620151e+01 1.08757472e+02\n",
            " 5.39292438e+01 1.50005643e+01 7.60596364e+00 1.87573689e+01\n",
            " 9.34928746e+00 1.29966151e+02 1.87427286e+02 1.08032597e+02\n",
            " 5.15926423e+01 6.19889934e+02 1.65794075e+02 6.39316021e+02\n",
            " 8.86123848e+02 4.95324418e+01 1.19644757e+02 1.49949280e+02\n",
            " 1.25981572e+02 4.66456715e+01 1.19557946e+02 3.46677718e+02\n",
            " 1.04010105e+02 3.65350661e+02 1.31149257e+02 2.02576745e+01\n",
            " 5.54654827e+01 4.90072406e+01 3.60380131e+00 5.15373312e+01\n",
            " 1.87412140e+02 3.60162726e+01 1.64719439e+02 1.22906559e+02\n",
            " 1.22715787e+02 1.90181100e+03 1.24845707e+02 1.89855932e+02\n",
            " 1.17168772e+02 1.72025321e+02 1.19239258e+02 7.46200846e+01\n",
            " 6.38161171e+02 1.14105314e+02 5.81436739e+01 2.31836800e+02\n",
            " 2.67245993e+02 3.07561090e+02 4.52871408e+00 3.94282112e+01\n",
            " 2.69860435e+01 2.77211496e+01 2.90134675e+02 1.00373585e+01\n",
            " 4.59106406e+02 1.27279894e+02]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  features_df.loc[mask, 'avg_monthly_charges'] = features_df.loc[mask, 'total_charges'] / features_df.loc[mask, 'tenure']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  customer_id  gender  senior_citizen  partner  dependents  tenure  \\\n",
              "0  CUST-00000    Male               1        1           0       6   \n",
              "1  CUST-00001  Female               0        0           0      34   \n",
              "2  CUST-00002    Male               0        0           0      54   \n",
              "3  CUST-00003    Male               0        0           0      13   \n",
              "4  CUST-00004    Male               0        0           1       9   \n",
              "\n",
              "   phone_service    multiple_lines internet_service      online_security  ...  \\\n",
              "0              0               Yes               No                  Yes  ...   \n",
              "1              0  No phone service      Fiber optic  No internet service  ...   \n",
              "2              1  No phone service               No                  Yes  ...   \n",
              "3              0  No phone service      Fiber optic                  Yes  ...   \n",
              "4              0  No phone service               No                  Yes  ...   \n",
              "\n",
              "  monthly_charges total_charges churn tenure_years tenure_group  \\\n",
              "0       26.875095   4951.885351    No     0.500000     0-1 year   \n",
              "1       70.739409   1586.779855    No     2.833333    2-3 years   \n",
              "2       52.891978   2353.696176    No     4.500000    4-5 years   \n",
              "3       70.831169   3859.820909    No     1.083333    1-2 years   \n",
              "4       22.397545   7639.333018   Yes     0.750000     0-1 year   \n",
              "\n",
              "   avg_monthly_charges monthly_charges_category  services_count  \\\n",
              "0           825.314225                      Low               5   \n",
              "1            46.669996                     High               1   \n",
              "2            43.586966                   Medium               3   \n",
              "3           296.909301                     High               2   \n",
              "4           848.814780                      Low               2   \n",
              "\n",
              "   contract_type_code churn_binary  \n",
              "0                   2            0  \n",
              "1                   1            0  \n",
              "2                   0            0  \n",
              "3                   1            0  \n",
              "4                   0            1  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f9f82a1-51a4-4e3c-a829-5052a68aba32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>senior_citizen</th>\n",
              "      <th>partner</th>\n",
              "      <th>dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>phone_service</th>\n",
              "      <th>multiple_lines</th>\n",
              "      <th>internet_service</th>\n",
              "      <th>online_security</th>\n",
              "      <th>...</th>\n",
              "      <th>monthly_charges</th>\n",
              "      <th>total_charges</th>\n",
              "      <th>churn</th>\n",
              "      <th>tenure_years</th>\n",
              "      <th>tenure_group</th>\n",
              "      <th>avg_monthly_charges</th>\n",
              "      <th>monthly_charges_category</th>\n",
              "      <th>services_count</th>\n",
              "      <th>contract_type_code</th>\n",
              "      <th>churn_binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUST-00000</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>26.875095</td>\n",
              "      <td>4951.885351</td>\n",
              "      <td>No</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0-1 year</td>\n",
              "      <td>825.314225</td>\n",
              "      <td>Low</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CUST-00001</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>...</td>\n",
              "      <td>70.739409</td>\n",
              "      <td>1586.779855</td>\n",
              "      <td>No</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>2-3 years</td>\n",
              "      <td>46.669996</td>\n",
              "      <td>High</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUST-00002</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>52.891978</td>\n",
              "      <td>2353.696176</td>\n",
              "      <td>No</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4-5 years</td>\n",
              "      <td>43.586966</td>\n",
              "      <td>Medium</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CUST-00003</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>70.831169</td>\n",
              "      <td>3859.820909</td>\n",
              "      <td>No</td>\n",
              "      <td>1.083333</td>\n",
              "      <td>1-2 years</td>\n",
              "      <td>296.909301</td>\n",
              "      <td>High</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CUST-00004</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>22.397545</td>\n",
              "      <td>7639.333018</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0-1 year</td>\n",
              "      <td>848.814780</td>\n",
              "      <td>Low</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f9f82a1-51a4-4e3c-a829-5052a68aba32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f9f82a1-51a4-4e3c-a829-5052a68aba32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f9f82a1-51a4-4e3c-a829-5052a68aba32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa27c009-17d2-45b8-9058-769445bdb9fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa27c009-17d2-45b8-9058-769445bdb9fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa27c009-17d2-45b8-9058-769445bdb9fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features_df"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5 Feature Store Setup"
      ],
      "metadata": {
        "id": "5KZjaa4cxuqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_feature_store():\n",
        "    \"\"\"\n",
        "    Set up a SQLite feature store for versioned feature management\n",
        "\n",
        "    Returns:\n",
        "        conn: SQLite connection\n",
        "    \"\"\"\n",
        "    # Create feature store directory\n",
        "    feature_store_dir = Path(\"feature_store\")\n",
        "    feature_store_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Connect to SQLite database\n",
        "    conn = sqlite3.connect('feature_store/feature_store.db')\n",
        "\n",
        "    # Create features table\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS features (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        feature_name TEXT NOT NULL,\n",
        "        feature_version TEXT NOT NULL,\n",
        "        data_version TEXT NOT NULL,\n",
        "        feature_type TEXT NOT NULL,\n",
        "        created_at TEXT NOT NULL,\n",
        "        description TEXT,\n",
        "        stats TEXT,\n",
        "        UNIQUE(feature_name, feature_version)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_values table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_values (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        entity_id TEXT NOT NULL,\n",
        "        feature_id INTEGER NOT NULL,\n",
        "        value TEXT NOT NULL,\n",
        "        timestamp TEXT NOT NULL,\n",
        "        FOREIGN KEY (feature_id) REFERENCES features(id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_sets table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_sets (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        name TEXT NOT NULL,\n",
        "        version TEXT NOT NULL,\n",
        "        created_at TEXT NOT NULL,\n",
        "        description TEXT,\n",
        "        UNIQUE(name, version)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # Create feature_set_features table (many-to-many relationship)\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS feature_set_features (\n",
        "        feature_set_id INTEGER NOT NULL,\n",
        "        feature_id INTEGER NOT NULL,\n",
        "        PRIMARY KEY (feature_set_id, feature_id),\n",
        "        FOREIGN KEY (feature_set_id) REFERENCES feature_sets(id),\n",
        "        FOREIGN KEY (feature_id) REFERENCES features(id)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"Feature store database initialized\")\n",
        "\n",
        "    return conn\n",
        "\n",
        "def register_features_in_store(conn, features_df, feature_metadata):\n",
        "    \"\"\"\n",
        "    Register features in the feature store\n",
        "\n",
        "    Args:\n",
        "        conn: SQLite connection\n",
        "        features_df: DataFrame with features\n",
        "        feature_metadata: Feature metadata dictionary\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create a feature set\n",
        "    feature_set_name = \"telco_churn_features\"\n",
        "    feature_set_version = feature_metadata['feature_version']\n",
        "    created_at = datetime.datetime.now().isoformat()\n",
        "    description = f\"Telco churn prediction features version {feature_set_version}\"\n",
        "\n",
        "    cursor.execute('''\n",
        "    INSERT OR REPLACE INTO feature_sets (name, version, created_at, description)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "    ''', (feature_set_name, feature_set_version, created_at, description))\n",
        "\n",
        "    feature_set_id = cursor.lastrowid\n",
        "\n",
        "    # Register each feature\n",
        "    for feature_name in features_df.columns:\n",
        "        if feature_name == 'customer_id':\n",
        "            continue  # Skip entity ID column\n",
        "\n",
        "        # Determine feature type\n",
        "        if feature_name in feature_metadata['numerical_features']:\n",
        "            feature_type = 'NUMERIC'\n",
        "        elif feature_name in feature_metadata['binary_features']:\n",
        "            feature_type = 'BINARY'\n",
        "        else:\n",
        "            feature_type = 'CATEGORICAL'\n",
        "\n",
        "        # Calculate basic stats\n",
        "        if feature_type == 'NUMERIC':\n",
        "            stats = {\n",
        "                'min': float(features_df[feature_name].min()),\n",
        "                'max': float(features_df[feature_name].max()),\n",
        "                'mean': float(features_df[feature_name].mean()),\n",
        "                'median': float(features_df[feature_name].median()),\n",
        "                'std': float(features_df[feature_name].std())\n",
        "            }\n",
        "        else:\n",
        "            value_counts = features_df[feature_name].value_counts().to_dict()\n",
        "            stats = {\n",
        "                'unique_values': len(value_counts),\n",
        "                'value_counts': {str(k): int(v) for k, v in value_counts.items()}\n",
        "            }\n",
        "\n",
        "        stats_json = json.dumps(stats)\n",
        "\n",
        "        # Insert feature metadata\n",
        "        cursor.execute('''\n",
        "        INSERT OR REPLACE INTO features\n",
        "        (feature_name, feature_version, data_version, feature_type, created_at, description, stats)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        ''', (\n",
        "            feature_name,\n",
        "            feature_set_version,\n",
        "            feature_metadata['data_version'],\n",
        "            feature_type,\n",
        "            created_at,\n",
        "            f\"Feature {feature_name} for telco churn prediction\",\n",
        "            stats_json\n",
        "        ))\n",
        "\n",
        "        feature_id = cursor.lastrowid\n",
        "\n",
        "        # Link feature to feature set\n",
        "        cursor.execute('''\n",
        "        INSERT OR REPLACE INTO feature_set_features (feature_set_id, feature_id)\n",
        "        VALUES (?, ?)\n",
        "        ''', (feature_set_id, feature_id))\n",
        "\n",
        "        # For demo purposes, only store a sample of feature values\n",
        "        if feature_name in ['tenure', 'monthly_charges', 'churn_binary', 'services_count']:\n",
        "            # Store feature values for each entity (customer)\n",
        "            for _, row in features_df.sample(min(100, len(features_df))).iterrows():\n",
        "                entity_id = row['customer_id']\n",
        "                value = str(row[feature_name])\n",
        "\n",
        "                cursor.execute('''\n",
        "                INSERT INTO feature_values (entity_id, feature_id, value, timestamp)\n",
        "                VALUES (?, ?, ?, ?)\n",
        "                ''', (entity_id, feature_id, value, created_at))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Registered {len(features_df.columns) - 1} features in feature store under set '{feature_set_name}' version '{feature_set_version}'\")\n",
        "\n",
        "# Set up feature store\n",
        "conn = setup_feature_store()\n",
        "\n",
        "# Register features\n",
        "register_features_in_store(conn, features_df, feature_metadata)\n",
        "\n",
        "# Query to verify feature registration\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT COUNT(*) FROM features\")\n",
        "feature_count = cursor.fetchone()[0]\n",
        "cursor.execute(\"SELECT COUNT(*) FROM feature_sets\")\n",
        "feature_set_count = cursor.fetchone()[0]\n",
        "cursor.execute(\"SELECT COUNT(*) FROM feature_values\")\n",
        "value_count = cursor.fetchone()[0]\n",
        "\n",
        "print(f\"\\nFeature Store Summary:\")\n",
        "print(f\"- Registered features: {feature_count}\")\n",
        "print(f\"- Feature sets: {feature_set_count}\")\n",
        "print(f\"- Sample feature values stored: {value_count}\")\n",
        "\n",
        "# Check a few registered features\n",
        "cursor.execute(\"SELECT feature_name, feature_type, stats FROM features LIMIT 5\")\n",
        "for row in cursor.fetchall():\n",
        "    name, type_, stats = row\n",
        "    print(f\"- Feature: {name}, Type: {type_}, Stats: {stats[:60]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7toX98hSxxXv",
        "outputId": "b84dfc33-7f1a-4158-ffc4-d1bc034d4d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature store database initialized\n",
            "Registered 26 features in feature store under set 'telco_churn_features' version '20250512_172103_feat'\n",
            "\n",
            "Feature Store Summary:\n",
            "- Registered features: 52\n",
            "- Feature sets: 2\n",
            "- Sample feature values stored: 800\n",
            "- Feature: gender, Type: BINARY, Stats: {\"unique_values\": 2, \"value_counts\": {\"Female\": 510, \"Male\":...\n",
            "- Feature: senior_citizen, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.474, \"median\": 0.0, \"std\"...\n",
            "- Feature: partner, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.501, \"median\": 1.0, \"std\"...\n",
            "- Feature: dependents, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 1.0, \"mean\": 0.476, \"median\": 0.0, \"std\"...\n",
            "- Feature: tenure, Type: NUMERIC, Stats: {\"min\": 0.0, \"max\": 71.0, \"mean\": 35.672, \"median\": 36.0, \"s...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Experimentation & Training"
      ],
      "metadata": {
        "id": "y62fXY-hxz4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Set Up MLflow for Experiment Tracking"
      ],
      "metadata": {
        "id": "59pT12Xmx3Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_mlflow():\n",
        "    \"\"\"\n",
        "    Set up MLflow for experiment tracking\n",
        "    \"\"\"\n",
        "    # Create MLflow directory\n",
        "    mlflow_dir = Path(\"mlruns\")\n",
        "    mlflow_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Set tracking URI to local directory\n",
        "    mlflow.set_tracking_uri(f\"file:{os.path.abspath(mlflow_dir)}\")\n",
        "\n",
        "    # Create experiment if it doesn't exist\n",
        "    experiment_name = \"telco_churn_prediction\"\n",
        "\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        experiment_id = mlflow.create_experiment(experiment_name)\n",
        "        print(f\"Created new MLflow experiment '{experiment_name}' with ID {experiment_id}\")\n",
        "    else:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        print(f\"Using existing MLflow experiment '{experiment_name}' with ID {experiment_id}\")\n",
        "\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "    return experiment_id\n",
        "\n",
        "# Set up MLflow\n",
        "experiment_id = setup_mlflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnQEpFyyyDGb",
        "outputId": "78711d80-8c16-41e6-c823-6e96d8618e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing MLflow experiment 'telco_churn_prediction' with ID 409164801491470435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Create Data Splits"
      ],
      "metadata": {
        "id": "TDr6JoZcyExh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_splits(features_df, test_size=0.2, val_size=0.25, random_state=42):\n",
        "    \"\"\"\n",
        "    Create reproducible train/validation/test splits\n",
        "\n",
        "    Args:\n",
        "        features_df: DataFrame with features\n",
        "        test_size: Proportion of data to use for test set\n",
        "        val_size: Proportion of training data to use for validation\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        splits: Dictionary with X_train, X_val, X_test, y_train, y_val, y_test\n",
        "    \"\"\"\n",
        "\n",
        "    # Make a copy to avoid modifying the original\n",
        "    df = features_df.copy()\n",
        "\n",
        "    # Define features and target\n",
        "    X = df.drop(['churn', 'churn_binary'], axis=1)\n",
        "    y = df['churn_binary']\n",
        "\n",
        "    # First split: training+validation vs test\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Second split: training vs validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=val_size, random_state=random_state, stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Create splits dictionary\n",
        "    splits = {\n",
        "        'X_train': X_train,\n",
        "        'X_val': X_val,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_val': y_val,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "    # Log split sizes\n",
        "    print(f\"Split sizes:\")\n",
        "    print(f\"- Training: {len(X_train)} samples ({len(X_train) / len(df):.1%})\")\n",
        "    print(f\"- Validation: {len(X_val)} samples ({len(X_val) / len(df):.1%})\")\n",
        "    print(f\"- Test: {len(X_test)} samples ({len(X_test) / len(df):.1%})\")\n",
        "\n",
        "    splits_dir = Path(\"data/splits\")\n",
        "    splits_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Save split indices for reproducibility\n",
        "    split_indices = {\n",
        "        'train_indices': X_train.index.tolist(),\n",
        "        'val_indices': X_val.index.tolist(),\n",
        "        'test_indices': X_test.index.tolist(),\n",
        "        'random_state': random_state,\n",
        "        'test_size': test_size,\n",
        "        'val_size': val_size,\n",
        "        'timestamp': datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    with open(splits_dir / f\"split_indices_{initial_version}.json\", 'w') as f:\n",
        "        json.dump(split_indices, f, indent=2)\n",
        "\n",
        "    return splits\n",
        "\n",
        "# Create train/validation/test splits\n",
        "data_splits = create_data_splits(features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsHvB7qlyGYA",
        "outputId": "425a78ad-9dde-4508-bc62-f232e98ce318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes:\n",
            "- Training: 600 samples (60.0%)\n",
            "- Validation: 200 samples (20.0%)\n",
            "- Test: 200 samples (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Create Feature Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "-GYvGnJ-yJzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessing_pipeline(X_train):\n",
        "    \"\"\"\n",
        "    Create a scikit-learn preprocessing pipeline\n",
        "\n",
        "    Args:\n",
        "        X_train: Training features DataFrame\n",
        "\n",
        "    Returns:\n",
        "        preprocessor: ColumnTransformer preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Identify column types\n",
        "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    # Remove customer_id from features\n",
        "    if 'customer_id' in categorical_cols:\n",
        "        categorical_cols.remove('customer_id')\n",
        "    if 'customer_id' in numerical_cols:\n",
        "        numerical_cols.remove('customer_id')\n",
        "\n",
        "    # Create preprocessing steps for each column type\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # The following line was incorrectly indented\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Changed 'sparse' to 'sparse_output'\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessing steps\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ],\n",
        "        remainder='drop'  # Drop any columns not specified (like customer_id)\n",
        "    )\n",
        "\n",
        "    print(f\"Created preprocessing pipeline with:\")\n",
        "    print(f\"- {len(numerical_cols)} numerical features: {numerical_cols[:5]}\")\n",
        "    print(f\"- {len(categorical_cols)} categorical features: {categorical_cols[:5]}\")\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = create_preprocessing_pipeline(data_splits['X_train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nji5yhoyMDh",
        "outputId": "f158a3ff-0cb8-4ca5-f718-c14f773258c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created preprocessing pipeline with:\n",
            "- 12 numerical features: ['senior_citizen', 'partner', 'dependents', 'tenure', 'phone_service']\n",
            "- 12 categorical features: ['gender', 'multiple_lines', 'internet_service', 'online_security', 'online_backup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 Train Models with Experiment Tracking"
      ],
      "metadata": {
        "id": "fB9HVNh2yNmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(splits, preprocessor, model_params, run_name=None):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model with experiment tracking\n",
        "\n",
        "    Args:\n",
        "        splits: Dictionary with data splits\n",
        "        preprocessor: Preprocessing pipeline\n",
        "        model_params: Parameters for RandomForestClassifier\n",
        "        run_name: Name for MLflow run\n",
        "\n",
        "    Returns:\n",
        "        model_pipeline: Trained model pipeline\n",
        "        metrics: Evaluation metrics\n",
        "    \"\"\"\n",
        "    # Extract splits\n",
        "    X_train = splits['X_train']\n",
        "    X_val = splits['X_val']\n",
        "    X_test = splits['X_test']\n",
        "    y_train = splits['y_train']\n",
        "    y_val = splits['y_val']\n",
        "    y_test = splits['y_test']\n",
        "\n",
        "    # Create and train model pipeline\n",
        "    model = RandomForestClassifier(**model_params)\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(run_name=run_name) as run:\n",
        "        run_id = run.info.run_id\n",
        "        print(f\"Started MLflow run '{run_name}' with ID {run_id}\")\n",
        "\n",
        "        # Log data versions and features\n",
        "        mlflow.log_param(\"data_version\", initial_version)\n",
        "        mlflow.log_param(\"n_samples_train\", len(X_train))\n",
        "        mlflow.log_param(\"n_features\", X_train.shape[1])\n",
        "\n",
        "        # Log feature names\n",
        "        feature_names = list(X_train.columns)\n",
        "        mlflow.log_param(\"feature_count\", len(feature_names))\n",
        "\n",
        "        # Log model parameters\n",
        "        for param, value in model_params.items():\n",
        "            mlflow.log_param(param, value)\n",
        "\n",
        "        # Train the model and time it\n",
        "        start_time = datetime.datetime.now()\n",
        "        model_pipeline.fit(X_train, y_train)\n",
        "        train_time = (datetime.datetime.now() - start_time).total_seconds()\n",
        "        mlflow.log_metric(\"training_time_seconds\", train_time)\n",
        "\n",
        "        # Evaluate on training set\n",
        "        y_train_pred = model_pipeline.predict(X_train)\n",
        "        y_train_prob = model_pipeline.predict_proba(X_train)[:, 1]\n",
        "\n",
        "        train_metrics = {\n",
        "            \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
        "            \"train_precision\": precision_score(y_train, y_train_pred),\n",
        "            \"train_recall\": recall_score(y_train, y_train_pred),\n",
        "            \"train_f1\": f1_score(y_train, y_train_pred),\n",
        "            \"train_roc_auc\": roc_auc_score(y_train, y_train_prob)\n",
        "        }\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        y_val_pred = model_pipeline.predict(X_val)\n",
        "        y_val_prob = model_pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        val_metrics = {\n",
        "            \"val_accuracy\": accuracy_score(y_val, y_val_pred),\n",
        "            \"val_precision\": precision_score(y_val, y_val_pred),\n",
        "            \"val_recall\": recall_score(y_val, y_val_pred),\n",
        "            \"val_f1\": f1_score(y_val, y_val_pred),\n",
        "            \"val_roc_auc\": roc_auc_score(y_val, y_val_prob)\n",
        "        }\n",
        "\n",
        "        # Evaluate on test set\n",
        "        y_test_pred = model_pipeline.predict(X_test)\n",
        "        y_test_prob = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        test_metrics = {\n",
        "            \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "            \"test_precision\": precision_score(y_test, y_test_pred),\n",
        "            \"test_recall\": recall_score(y_test, y_test_pred),\n",
        "            \"test_f1\": f1_score(y_test, y_test_pred),\n",
        "            \"test_roc_auc\": roc_auc_score(y_test, y_test_prob)\n",
        "        }\n",
        "\n",
        "        # Combine all metrics\n",
        "        metrics = {**train_metrics, **val_metrics, **test_metrics}\n",
        "\n",
        "        # Log metrics to MLflow\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            mlflow.log_metric(metric_name, metric_value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model_pipeline, \"model\")\n",
        "\n",
        "\n",
        "        # Log feature importances\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            # Get column names after preprocessing\n",
        "            preprocessor_output_feature_names = []\n",
        "            for name, trans, cols in preprocessor.transformers_:\n",
        "                if hasattr(trans, 'get_feature_names_out'):\n",
        "                    preprocessor_output_feature_names.extend(trans.get_feature_names_out(cols))\n",
        "                else:\n",
        "                    preprocessor_output_feature_names.extend(cols)\n",
        "\n",
        "            # Ensure feature names and importances have the same length\n",
        "            # This is done by selecting the feature names corresponding to the\n",
        "            # features used by the model (based on the length of feature_importances_)\n",
        "            preprocessor_output_feature_names = preprocessor_output_feature_names[:len(model.feature_importances_)]\n",
        "\n",
        "            # Match feature importances with names\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': preprocessor_output_feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Match feature importances with names\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': preprocessor_output_feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Save feature importances\n",
        "            importance_path = f\"feature_importances_{run_id}.csv\"\n",
        "            importance_df.to_csv(importance_path, index=False)\n",
        "            mlflow.log_artifact(importance_path)\n",
        "\n",
        "            # Create and log feature importance plot\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            top_features = importance_df.head(15)\n",
        "            sns.barplot(x='importance', y='feature', data=top_features)\n",
        "            plt.title('Top 15 Feature Importances')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plot_path = f\"feature_importance_plot_{run_id}.png\"\n",
        "            plt.savefig(plot_path)\n",
        "            mlflow.log_artifact(plot_path)\n",
        "            plt.close()\n",
        "\n",
        "            # Clean up local files\n",
        "            os.remove(importance_path)\n",
        "            os.remove(plot_path)\n",
        "\n",
        "        # Create and log confusion matrix\n",
        "        cm = np.zeros((2, 2))\n",
        "        cm[0, 0] = np.sum((y_val == 0) & (y_val_pred == 0))\n",
        "        cm[0, 1] = np.sum((y_val == 0) & (y_val_pred == 1))\n",
        "        cm[1, 0] = np.sum((y_val == 1) & (y_val_pred == 0))\n",
        "        cm[1, 1] = np.sum((y_val == 1) & (y_val_pred == 1))\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n",
        "                    xticklabels=['No Churn', 'Churn'],\n",
        "                    yticklabels=['No Churn', 'Churn'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Confusion Matrix (Validation Set)')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        cm_path = f\"confusion_matrix_{run_id}.png\"\n",
        "        plt.savefig(cm_path)\n",
        "        mlflow.log_artifact(cm_path)\n",
        "        plt.close()\n",
        "\n",
        "        # Clean up local file\n",
        "        os.remove(cm_path)\n",
        "\n",
        "        print(f\"Model training and evaluation complete. MLflow run ID: {run_id}\")\n",
        "        print(f\"Validation metrics: accuracy={val_metrics['val_accuracy']:.4f}, f1={val_metrics['val_f1']:.4f}, roc_auc={val_metrics['val_roc_auc']:.4f}\")\n",
        "\n",
        "    return model_pipeline, metrics, run_id\n",
        "\n",
        "# Train multiple model variants\n",
        "models = []\n",
        "\n",
        "# Model 1: Default RandomForest\n",
        "model_params_1 = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': None,\n",
        "    'min_samples_split': 2,\n",
        "    'min_samples_leaf': 1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_1, metrics_1, run_id_1 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_1,\n",
        "    run_name=\"RandomForest-Default\"\n",
        ")\n",
        "models.append((\"RandomForest-Default\", model_1, metrics_1, run_id_1))\n",
        "\n",
        "# Model 2: Tuned RandomForest\n",
        "model_params_2 = {\n",
        "    'n_estimators': 200,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_2, metrics_2, run_id_2 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_2,\n",
        "    run_name=\"RandomForest-Tuned\"\n",
        ")\n",
        "models.append((\"RandomForest-Tuned\", model_2, metrics_2, run_id_2))\n",
        "\n",
        "# Model 3: RandomForest with feature reduction focus\n",
        "model_params_3 = {\n",
        "    'n_estimators': 150,\n",
        "    'max_depth': 8,\n",
        "    'min_samples_split': 10,\n",
        "    'min_samples_leaf': 4,\n",
        "    'max_features': 'sqrt',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model_3, metrics_3, run_id_3 = train_and_evaluate_model(\n",
        "    data_splits,\n",
        "    preprocessor,\n",
        "    model_params_3,\n",
        "    run_name=\"RandomForest-FeatureReduction\"\n",
        ")\n",
        "models.append((\"RandomForest-FeatureReduction\", model_3, metrics_3, run_id_3))\n",
        "\n",
        "# Compare models\n",
        "comparison_df = pd.DataFrame([\n",
        "    {\n",
        "        'model_name': model_name,\n",
        "        'val_accuracy': metrics['val_accuracy'],\n",
        "        'val_precision': metrics['val_precision'],\n",
        "        'val_recall': metrics['val_recall'],\n",
        "        'val_f1': metrics['val_f1'],\n",
        "        'val_roc_auc': metrics['val_roc_auc'],\n",
        "        'run_id': run_id\n",
        "    }\n",
        "    for model_name, _, metrics, run_id in models\n",
        "])\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "comparison_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "WVskZlDOyPzH",
        "outputId": "3aa5bb89-59cb-44dd-f507-244c1039f8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started MLflow run 'RandomForest-Default' with ID 4bce6674e96248deaa3eabf58da39748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: 4bce6674e96248deaa3eabf58da39748\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6231\n",
            "Started MLflow run 'RandomForest-Tuned' with ID 7c320ab775db4de1a352fd8060601f20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: 7c320ab775db4de1a352fd8060601f20\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6356\n",
            "Started MLflow run 'RandomForest-FeatureReduction' with ID a7cfc0187a3b41e7bb015c8d0925ec12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/12 17:21:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py:1667: FutureWarning: \n",
            "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
            "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
            "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and evaluation complete. MLflow run ID: a7cfc0187a3b41e7bb015c8d0925ec12\n",
            "Validation metrics: accuracy=0.6650, f1=0.3093, roc_auc=0.6423\n",
            "\n",
            "Model Comparison:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      model_name  val_accuracy  val_precision  val_recall  \\\n",
              "0           RandomForest-Default         0.665       0.555556    0.214286   \n",
              "1             RandomForest-Tuned         0.665       0.555556    0.214286   \n",
              "2  RandomForest-FeatureReduction         0.665       0.555556    0.214286   \n",
              "\n",
              "     val_f1  val_roc_auc                            run_id  \n",
              "0  0.309278     0.623077  4bce6674e96248deaa3eabf58da39748  \n",
              "1  0.309278     0.635604  7c320ab775db4de1a352fd8060601f20  \n",
              "2  0.309278     0.642308  a7cfc0187a3b41e7bb015c8d0925ec12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_f1</th>\n",
              "      <th>val_roc_auc</th>\n",
              "      <th>run_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForest-Default</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.623077</td>\n",
              "      <td>4bce6674e96248deaa3eabf58da39748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest-Tuned</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.635604</td>\n",
              "      <td>7c320ab775db4de1a352fd8060601f20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest-FeatureReduction</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.642308</td>\n",
              "      <td>a7cfc0187a3b41e7bb015c8d0925ec12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc98c09c-0e17-48ea-8fd8-cb1786f7caa3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f16b574d-76df-45ef-abe9-e1a706d09903\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f16b574d-76df-45ef-abe9-e1a706d09903')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f16b574d-76df-45ef-abe9-e1a706d09903 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_687fac13-b2fa-405f-a82f-9780b420b66f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_687fac13-b2fa-405f-a82f-9780b420b66f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RandomForest-Default\",\n          \"RandomForest-Tuned\",\n          \"RandomForest-FeatureReduction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.665,\n        \"max\": 0.665,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5555555555555556,\n        \"max\": 0.5555555555555556,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5555555555555556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.21428571428571427,\n        \"max\": 0.21428571428571427,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.21428571428571427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.30927835051546393,\n        \"max\": 0.30927835051546393,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.30927835051546393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009761269041694935,\n        \"min\": 0.6230769230769231,\n        \"max\": 0.6423076923076924,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6230769230769231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"4bce6674e96248deaa3eabf58da39748\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5 Select Best Model and Register in Model Registry"
      ],
      "metadata": {
        "id": "JP5ZERYjyRIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def register_best_model(models):\n",
        "    \"\"\"\n",
        "    Select the best model based on validation metrics and register in model registry\n",
        "\n",
        "    Args:\n",
        "        models: List of (name, model, metrics, run_id) tuples\n",
        "\n",
        "    Returns:\n",
        "        best_model: Best model object\n",
        "        best_run_id: MLflow run ID of best model\n",
        "    \"\"\"\n",
        "    # Create a sorted list based on validation F1 score\n",
        "    sorted_models = sorted(models, key=lambda x: x[2]['val_f1'], reverse=True)\n",
        "\n",
        "    # Get the best model\n",
        "    best_model_name, best_model, best_metrics, best_run_id = sorted_models[0]\n",
        "\n",
        "    print(f\"Best model: {best_model_name}\")\n",
        "    print(f\"Validation F1 score: {best_metrics['val_f1']:.4f}\")\n",
        "    print(f\"Validation ROC AUC: {best_metrics['val_roc_auc']:.4f}\")\n",
        "\n",
        "    # Register the model in MLflow model registry\n",
        "    model_uri = f\"runs:/{best_run_id}/model\"\n",
        "    registered_model_name = \"telco_churn_predictor\"\n",
        "\n",
        "    registered_model = mlflow.register_model(model_uri, registered_model_name)\n",
        "    print(f\"Registered model '{registered_model_name}' version {registered_model.version}\")\n",
        "\n",
        "    # Create model directory\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Save the model locally\n",
        "    model_path = models_dir / f\"{registered_model_name}_v{registered_model.version}.pkl\"\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "\n",
        "    # Save model metadata\n",
        "    model_metadata = {\n",
        "        \"model_name\": registered_model_name,\n",
        "        \"model_version\": registered_model.version,\n",
        "        \"run_id\": best_run_id,\n",
        "        \"data_version\": initial_version,\n",
        "        \"metrics\": best_metrics,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"description\": f\"Telco churn prediction model version {registered_model.version}\"\n",
        "    }\n",
        "\n",
        "    metadata_path = models_dir / f\"{registered_model_name}_v{registered_model.version}_metadata.json\"\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "    return best_model, best_run_id, registered_model.version\n",
        "\n",
        "# Register best model\n",
        "best_model, best_run_id, model_version = register_best_model(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGYJqTb6yXk-",
        "outputId": "51516df1-36e0-47b3-dadb-5795ccb004f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForest-Default\n",
            "Validation F1 score: 0.3093\n",
            "Validation ROC AUC: 0.6231\n",
            "Registered model 'telco_churn_predictor' version 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Registered model 'telco_churn_predictor' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'telco_churn_predictor'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Automated Validation (CI)"
      ],
      "metadata": {
        "id": "JecA3eMgybfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Create Validation Test Suite"
      ],
      "metadata": {
        "id": "wJX8teUNyZdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_validation_test_suite():\n",
        "    \"\"\"\n",
        "    Create a validation test suite for the ML pipeline\n",
        "\n",
        "    Returns:\n",
        "        test_suite: Dictionary of test functions\n",
        "    \"\"\"\n",
        "    # Dictionary to store test functions\n",
        "    test_suite = {}\n",
        "\n",
        "    # Test 1: Feature pipeline validation\n",
        "    def test_feature_pipeline(X_sample, preprocessor):\n",
        "        \"\"\"Test that the feature pipeline correctly transforms data\"\"\"\n",
        "        try:\n",
        "            # Transform a sample\n",
        "            X_transformed = preprocessor.transform(X_sample)\n",
        "\n",
        "            # Check output shape and type\n",
        "            assert X_transformed is not None, \"Preprocessor output is None\"\n",
        "            assert X_transformed.shape[0] == X_sample.shape[0], \"Output has wrong number of samples\"\n",
        "            assert not np.isnan(X_transformed).any(), \"Output contains NaN values\"\n",
        "            assert not np.isinf(X_transformed).any(), \"Output contains infinite values\"\n",
        "\n",
        "            return True, \"Feature pipeline validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Feature pipeline validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_feature_pipeline\"] = test_feature_pipeline\n",
        "\n",
        "    # Test 2: Model prediction validation\n",
        "    def test_model_predictions(model, X_sample):\n",
        "        \"\"\"Test that the model produces valid predictions\"\"\"\n",
        "        try:\n",
        "            # Generate predictions\n",
        "            predictions = model.predict(X_sample)\n",
        "            probabilities = model.predict_proba(X_sample)\n",
        "\n",
        "            # Check predictions\n",
        "            assert predictions is not None, \"Predictions are None\"\n",
        "            assert predictions.shape[0] == X_sample.shape[0], \"Wrong number of predictions\"\n",
        "            assert set(np.unique(predictions)).issubset({0, 1}), \"Predictions are not binary\"\n",
        "            assert probabilities.shape == (X_sample.shape[0], 2), \"Probability shape is incorrect\"\n",
        "            assert np.allclose(np.sum(probabilities, axis=1), 1.0), \"Probabilities don't sum to 1\"\n",
        "            assert np.all(probabilities >= 0) and np.all(probabilities <= 1), \"Probabilities outside [0,1]\"\n",
        "\n",
        "            return True, \"Model prediction validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Model prediction validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_model_predictions\"] = test_model_predictions\n",
        "\n",
        "    # Test 3: Feature importance validation\n",
        "    def test_feature_importance(model):\n",
        "        \"\"\"Test that feature importances are available and valid\"\"\"\n",
        "        try:\n",
        "            # Get the classifier from the pipeline\n",
        "            classifier = model.named_steps['classifier']\n",
        "\n",
        "            # Check feature importances\n",
        "            assert hasattr(classifier, 'feature_importances_'), \"Model has no feature_importances_ attribute\"\n",
        "            importances = classifier.feature_importances_\n",
        "            assert importances is not None, \"Feature importances are None\"\n",
        "            assert len(importances) > 0, \"No feature importances available\"\n",
        "            assert np.all(importances >= 0), \"Negative feature importances found\"\n",
        "            assert np.isclose(np.sum(importances), 1.0), \"Feature importances don't sum to 1\"\n",
        "\n",
        "            return True, \"Feature importance validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Feature importance validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_feature_importance\"] = test_feature_importance\n",
        "\n",
        "    # Test 4: Model serialization validation\n",
        "    def test_model_serialization(model):\n",
        "        \"\"\"Test that the model can be serialized and deserialized\"\"\"\n",
        "        try:\n",
        "            # Serialize model\n",
        "            serialized = pickle.dumps(model)\n",
        "\n",
        "            # Deserialize model\n",
        "            deserialized_model = pickle.loads(serialized)\n",
        "\n",
        "            # Check if model works after deserialization\n",
        "            assert deserialized_model is not None, \"Deserialized model is None\"\n",
        "            assert hasattr(deserialized_model, 'predict'), \"Deserialized model has no predict method\"\n",
        "            assert hasattr(deserialized_model, 'predict_proba'), \"Deserialized model has no predict_proba method\"\n",
        "\n",
        "            return True, \"Model serialization validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Model serialization validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_model_serialization\"] = test_model_serialization\n",
        "\n",
        "    # Test 5: Lightweight retraining validation\n",
        "    def test_lightweight_retraining(model, X_sample, y_sample):\n",
        "        \"\"\"Test that the model can be retrained with new data\"\"\"\n",
        "        try:\n",
        "            # Clone the model to avoid modifying the original\n",
        "            model_copy = pickle.loads(pickle.dumps(model))\n",
        "\n",
        "            # Fit on a small sample\n",
        "            model_copy.fit(X_sample, y_sample)\n",
        "\n",
        "            # Check predictions\n",
        "            predictions = model_copy.predict(X_sample)\n",
        "            assert predictions is not None, \"Predictions after retraining are None\"\n",
        "            assert predictions.shape[0] == X_sample.shape[0], \"Wrong number of predictions after retraining\"\n",
        "\n",
        "            return True, \"Lightweight retraining validation passed\"\n",
        "        except Exception as e:\n",
        "            return False, f\"Lightweight retraining validation failed: {str(e)}\"\n",
        "\n",
        "    test_suite[\"test_lightweight_retraining\"] = test_lightweight_retraining\n",
        "\n",
        "    return test_suite\n",
        "\n",
        "# Create validation test suite\n",
        "test_suite = create_validation_test_suite()"
      ],
      "metadata": {
        "id": "PHGBv5Xcyd-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Run Validation Tests"
      ],
      "metadata": {
        "id": "6CYbjJxeyhMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation_tests(test_suite, model, preprocessor, data_splits):\n",
        "    \"\"\"\n",
        "    Run all validation tests and report results\n",
        "\n",
        "    Args:\n",
        "        test_suite: Dictionary of test functions\n",
        "        model: Model to validate\n",
        "        preprocessor: Preprocessor pipeline\n",
        "        data_splits: Data splits dictionary\n",
        "\n",
        "    Returns:\n",
        "        results: Dictionary of test results\n",
        "    \"\"\"\n",
        "    print(f\"Running validation tests for model...\")\n",
        "\n",
        "    # Create test dataset (small sample)\n",
        "    X_sample = data_splits['X_val'].sample(min(100, len(data_splits['X_val'])), random_state=42)\n",
        "    y_sample = data_splits['y_val'].loc[X_sample.index]\n",
        "\n",
        "    # Run all tests\n",
        "    results = {}\n",
        "\n",
        "    # Test 1: Feature pipeline validation\n",
        "    success, message = test_suite[\"test_feature_pipeline\"](X_sample, preprocessor)\n",
        "    results[\"Feature Pipeline\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Feature Pipeline Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 2: Model prediction validation\n",
        "    success, message = test_suite[\"test_model_predictions\"](model, X_sample)\n",
        "    results[\"Model Predictions\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Model Predictions Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 3: Feature importance validation\n",
        "    success, message = test_suite[\"test_feature_importance\"](model)\n",
        "    results[\"Feature Importance\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Feature Importance Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 4: Model serialization validation\n",
        "    success, message = test_suite[\"test_model_serialization\"](model)\n",
        "    results[\"Model Serialization\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Model Serialization Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Test 5: Lightweight retraining validation\n",
        "    success, message = test_suite[\"test_lightweight_retraining\"](model, X_sample, y_sample)\n",
        "    results[\"Lightweight Retraining\"] = {\"success\": success, \"message\": message}\n",
        "    print(f\"- Lightweight Retraining Test: {'' if success else ''} {message}\")\n",
        "\n",
        "    # Calculate overall success rate\n",
        "    success_count = sum(1 for test in results.values() if test[\"success\"])\n",
        "    success_rate = success_count / len(results)\n",
        "    print(f\"\\nValidation summary: {success_count}/{len(results)} tests passed ({success_rate:.0%})\")\n",
        "\n",
        "    # Save test results\n",
        "    validation_dir = Path(\"validation\")\n",
        "    validation_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    results_path = validation_dir / f\"validation_results_{timestamp}.json\"\n",
        "\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"model_version\": model_version,\n",
        "            \"data_version\": initial_version,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"tests\": {name: {\"success\": result[\"success\"], \"message\": result[\"message\"]}\n",
        "                      for name, result in results.items()}\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"Test results saved to {results_path}\")\n",
        "\n",
        "    if success_rate == 1.0:\n",
        "        print(\"All validation tests passed! Model is ready for deployment.\")\n",
        "    else:\n",
        "        print(\"Some validation tests failed. Review issues before deployment.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run validation tests\n",
        "validation_results = run_validation_tests(test_suite, best_model, preprocessor, data_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNPSP5PMyiKB",
        "outputId": "6614040a-128c-4ab6-961b-2a22682eefe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running validation tests for model...\n",
            "- Feature Pipeline Test:  Feature pipeline validation passed\n",
            "- Model Predictions Test:  Model prediction validation passed\n",
            "- Feature Importance Test:  Feature importance validation passed\n",
            "- Model Serialization Test:  Model serialization validation passed\n",
            "- Lightweight Retraining Test:  Lightweight retraining validation passed\n",
            "\n",
            "Validation summary: 5/5 tests passed (100%)\n",
            "Test results saved to validation/validation_results_20250512_172144.json\n",
            "All validation tests passed! Model is ready for deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Packaging & Continuous Delivery (CD)"
      ],
      "metadata": {
        "id": "M4okM28Byl4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 Package Model and Pipeline"
      ],
      "metadata": {
        "id": "v-jExA6pymzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import json\n",
        "import datetime\n",
        "import shutil\n",
        "\n",
        "\n",
        "def package_model(\n",
        "    model,\n",
        "    preprocessor,\n",
        "    data_splits,\n",
        "    model_name: str,\n",
        "    version: str,\n",
        "    *,\n",
        "    initial_version: str,\n",
        "    best_run_id: str,\n",
        "    copy_to_root: bool = False,\n",
        "):\n",
        "    \"\"\"Create a selfcontained deployment package for a trained model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Any\n",
        "        Fitted scikitlearn (or compatible) pipeline.\n",
        "    preprocessor : Any\n",
        "        Fitted preprocessing pipeline used before training.\n",
        "    data_splits : dict\n",
        "        Dict with keys like ``'X_test'`` for example input generation.\n",
        "    model_name : str\n",
        "        Short, filesystemfriendly model identifier (e.g. ``telco_churn``).\n",
        "    version : str\n",
        "        Semantic or date version (e.g. ``1.0.0`` or ``20250512``).\n",
        "    initial_version : str\n",
        "        Version of the dataset the model was trained on.\n",
        "    best_run_id : str\n",
        "        Upstream experiment or MLflow run identifier.\n",
        "    copy_to_root : bool, default False\n",
        "        If ``True`` also copies ``model.pkl`` into the current working\n",
        "        directory for quick local testing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pathlib.Path\n",
        "        Path to the created model directory.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Packaging model {model_name} version {version}\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Directory layout\n",
        "    # ------------------------------------------------------------------\n",
        "    package_dir = Path(\"deployment\") / \"packages\"\n",
        "    package_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model_dir = package_dir / f\"{model_name}_v{version}\"\n",
        "    model_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Serialise model artefacts\n",
        "    # ------------------------------------------------------------------\n",
        "    model_path = model_dir / \"model.pkl\"\n",
        "    with open(model_path, \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    preprocessor_path = model_dir / \"preprocessor.pkl\"\n",
        "    with open(preprocessor_path, \"wb\") as f:\n",
        "        pickle.dump(preprocessor, f)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Metadata\n",
        "    # ------------------------------------------------------------------\n",
        "    metadata = {\n",
        "        \"name\": model_name,\n",
        "        \"version\": version,\n",
        "        \"created_at\": datetime.datetime.now().isoformat(),\n",
        "        \"data_version\": initial_version,\n",
        "        \"mlflow_run_id\": best_run_id,\n",
        "        \"python_version\": f\"{datetime.sys.version_info.major}.{datetime.sys.version_info.minor}\",\n",
        "        \"dependencies\": {\n",
        "            \"scikit-learn\": \"1.0.2\",\n",
        "            \"pandas\": \"1.3.5\",\n",
        "            \"numpy\": \"1.21.5\",\n",
        "        },\n",
        "        \"endpoints\": [\n",
        "            {\"name\": \"predict\", \"path\": f\"/api/v1/models/{model_name}/predict\", \"method\": \"POST\"},\n",
        "            {\"name\": \"metadata\", \"path\": f\"/api/v1/models/{model_name}/metadata\", \"method\": \"GET\"},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    with open(model_dir / \"metadata.json\", \"w\") as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Example request\n",
        "    # ------------------------------------------------------------------\n",
        "    example_input = (\n",
        "        data_splits[\"X_test\"].iloc[:2].to_dict(orient=\"records\")\n",
        "        if \"X_test\" in data_splits\n",
        "        else []\n",
        "    )\n",
        "    with open(model_dir / \"example_input.json\", \"w\") as f:\n",
        "        json.dump(example_input, f, indent=2)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Deployment config\n",
        "    # ------------------------------------------------------------------\n",
        "    config = {\n",
        "        \"serving\": {\"host\": \"0.0.0.0\", \"port\": 5000, \"workers\": 2, \"timeout\": 60},\n",
        "        \"deployment\": {\n",
        "            \"strategy\": \"blue-green\",\n",
        "            \"rollback_threshold\": {\"error_rate\": 0.05, \"latency_p95_ms\": 200},\n",
        "            \"scaling\": {\"min_replicas\": 2, \"max_replicas\": 5},\n",
        "        },\n",
        "        \"monitoring\": {\"metrics_interval_seconds\": 15, \"log_level\": \"INFO\"},\n",
        "    }\n",
        "\n",
        "    with open(model_dir / \"config.json\", \"w\") as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # README with correct loader path\n",
        "    # ------------------------------------------------------------------\n",
        "    readme = f\"\"\"# Telco Churn Prediction Model v{version}\n",
        "\n",
        "## Model Information\n",
        "- Name: {model_name}\n",
        "- Version: {version}\n",
        "- Packaged: {datetime.datetime.now().isoformat()}\n",
        "\n",
        "## Description\n",
        "This model predicts customer churn based on telco customer data.\n",
        "\n",
        "## Usage\n",
        "```python\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "PACKAGE_DIR = Path(__file__).parent  # points to the model package folder\n",
        "MODEL_FILE = PACKAGE_DIR / \"model.pkl\"\n",
        "\n",
        "with open(MODEL_FILE, \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Prepare input data (example)\n",
        "input_data = pd.DataFrame({\n",
        "    \"customer_id\": [\"CUST-12345\"],\n",
        "    \"gender\": [\"Male\"],\n",
        "    \"senior_citizen\": [0],\n",
        "    \"partner\": [\"Yes\"],\n",
        "    \"dependents\": [\"No\"],\n",
        "    \"tenure\": [24],\n",
        "    \"phone_service\": [\"Yes\"],\n",
        "    \"multiple_lines\": [\"Yes\"],\n",
        "    \"internet_service\": [\"Fiber optic\"],\n",
        "    \"online_security\": [\"No\"],\n",
        "    \"online_backup\": [\"Yes\"],\n",
        "    \"tech_support\": [\"No\"],\n",
        "    \"streaming_tv\": [\"Yes\"],\n",
        "    \"streaming_movies\": [\"Yes\"],\n",
        "    \"contract\": [\"Month-to-month\"],\n",
        "    \"paperless_billing\": [\"Yes\"],\n",
        "    \"payment_method\": [\"Electronic check\"],\n",
        "    \"monthly_charges\": [89.85],\n",
        "    \"total_charges\": [2156.45],\n",
        "})\n",
        "\n",
        "prediction = model.predict(input_data)\n",
        "probability = model.predict_proba(input_data)[:, 1]\n",
        "\n",
        "print(f\"Churn Prediction: {'Yes' if prediction[0] == 1 else 'No'}\")\n",
        "print(f\"Churn Probability: {probability[0]:.2f}\")\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "    (model_dir / \"README.md\").write_text(readme)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Optional convenience copy\n",
        "    # ------------------------------------------------------------------\n",
        "    if copy_to_root:\n",
        "        shutil.copy(model_path, Path.cwd() / \"model.pkl\")\n",
        "\n",
        "    print(f\"Package saved to {model_dir.relative_to(Path.cwd())}\")\n",
        "    return model_dir\n"
      ],
      "metadata": {
        "id": "RMsxaf9RypnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Create Model Serving API"
      ],
      "metadata": {
        "id": "ZBh76nOqWOR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_serving_api(model):\n",
        "    \"\"\"\n",
        "    Create a Flask API for serving model predictions\n",
        "\n",
        "    Args:\n",
        "        model: Trained model pipeline\n",
        "\n",
        "    Returns:\n",
        "        app: Flask application\n",
        "    \"\"\"\n",
        "    # Create Flask app\n",
        "    app = Flask(\"ChurnPredictionService\")\n",
        "\n",
        "    # Store model in app context\n",
        "    app.model = model\n",
        "\n",
        "    # Define prediction endpoint\n",
        "    @app.route('/api/v1/models/telco-churn/predict', methods=['POST'])\n",
        "    def predict():\n",
        "        # Get JSON input\n",
        "        data = request.json\n",
        "\n",
        "        if not data or not isinstance(data, list):\n",
        "            return jsonify({\n",
        "                'error': 'Invalid input format. Expected a list of customer records.'\n",
        "            }), 400\n",
        "\n",
        "        try:\n",
        "            # Convert to DataFrame\n",
        "            input_df = pd.DataFrame(data)\n",
        "\n",
        "            # Make predictions\n",
        "            predictions = app.model.predict(input_df)\n",
        "            probabilities = app.model.predict_proba(input_df)[:, 1]\n",
        "\n",
        "            # Prepare response\n",
        "            results = []\n",
        "            for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
        "                results.append({\n",
        "                    'customer_id': input_df.iloc[i].get('customer_id', f'customer_{i}'),\n",
        "                    'churn_prediction': bool(pred),\n",
        "                    'churn_probability': float(prob),\n",
        "                    'prediction_time': datetime.datetime.now().isoformat()\n",
        "                })\n",
        "\n",
        "            return jsonify({\n",
        "                'model_version': model_version,\n",
        "                'predictions': results\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            return jsonify({\n",
        "                'error': f'Prediction error: {str(e)}'\n",
        "            }), 500\n",
        "\n",
        "    # Define metadata endpoint\n",
        "    @app.route('/api/v1/models/telco-churn/metadata', methods=['GET'])\n",
        "    def metadata():\n",
        "        return jsonify({\n",
        "            'name': 'telco_churn_predictor',\n",
        "            'version': model_version,\n",
        "            'description': 'Telco customer churn prediction model',\n",
        "            'created_at': datetime.datetime.now().isoformat(),\n",
        "            'input_features': list(data_splits['X_train'].columns),\n",
        "            'output': {\n",
        "                'prediction': 'binary (0/1)',\n",
        "                'probability': 'float [0, 1]'\n",
        "            },\n",
        "            'performance_metrics': {\n",
        "                'accuracy': metrics_1['val_accuracy'],\n",
        "                'precision': metrics_1['val_precision'],\n",
        "                'recall': metrics_1['val_recall'],\n",
        "                'f1_score': metrics_1['val_f1'],\n",
        "                'roc_auc': metrics_1['val_roc_auc']\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # Define health check endpoint\n",
        "    @app.route('/api/v1/health', methods=['GET'])\n",
        "    def health():\n",
        "        return jsonify({\n",
        "            'status': 'healthy',\n",
        "            'timestamp': datetime.datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "    return app\n",
        "\n",
        "# Create the model serving API\n",
        "app = create_model_serving_api(best_model)\n",
        "\n",
        "# Create a sample server script\n",
        "server_dir = Path(\"deployment/server\")\n",
        "server_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "server_script = \"\"\"\n",
        "import pickle\n",
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import logging\n",
        "import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout),\n",
        "        logging.FileHandler('server.log')\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger('churn-predictor-api')\n",
        "\n",
        "# Load the model\n",
        "model_path = os.environ.get('MODEL_PATH', 'model.pkl')\n",
        "logger.info(f\"Loading model from {model_path}\")\n",
        "\n",
        "with open(model_path, 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Create Flask app\n",
        "app = Flask(\"ChurnPredictionService\")\n",
        "app.model = model\n",
        "\n",
        "@app.route('/api/v1/models/telco-churn/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Log request\n",
        "    logger.info(f\"Prediction request received: {request.remote_addr}\")\n",
        "\n",
        "    # Get JSON input\n",
        "    data = request.json\n",
        "\n",
        "    if not data or not isinstance(data, list):\n",
        "        logger.error(\"Invalid input format\")\n",
        "        return jsonify({\n",
        "            'error': 'Invalid input format. Expected a list of customer records.'\n",
        "        }), 400\n",
        "\n",
        "    try:\n",
        "        # Convert to DataFrame\n",
        "        input_df = pd.DataFrame(data)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = app.model.predict(input_df)\n",
        "        probabilities = app.model.predict_proba(input_df)[:, 1]\n",
        "\n",
        "        # Prepare response\n",
        "        results = []\n",
        "        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
        "            results.append({\n",
        "                'customer_id': input_df.iloc[i].get('customer_id', f'customer_{i}'),\n",
        "                'churn_prediction': bool(pred),\n",
        "                'churn_probability': float(prob),\n",
        "                'prediction_time': datetime.datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "        # Log successful prediction\n",
        "        logger.info(f\"Successful prediction for {len(results)} records\")\n",
        "\n",
        "        return jsonify({\n",
        "            'model_version': os.environ.get('MODEL_VERSION', 'unknown'),\n",
        "            'predictions': results\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Prediction error: {str(e)}\")\n",
        "        return jsonify({\n",
        "            'error': f'Prediction error: {str(e)}'\n",
        "        }), 500\n",
        "\n",
        "@app.route('/api/v1/models/telco-churn/metadata', methods=['GET'])\n",
        "def metadata():\n",
        "    return jsonify({\n",
        "        'name': 'telco_churn_predictor',\n",
        "        'version': os.environ.get('MODEL_VERSION', 'unknown'),\n",
        "        'description': 'Telco customer churn prediction model',\n",
        "        'created_at': os.environ.get('MODEL_CREATED_AT', 'unknown'),\n",
        "        'performance_metrics': {\n",
        "            'accuracy': float(os.environ.get('MODEL_ACCURACY', 0)),\n",
        "            'f1_score': float(os.environ.get('MODEL_F1', 0)),\n",
        "            'roc_auc': float(os.environ.get('MODEL_ROC_AUC', 0))\n",
        "        }\n",
        "    })\n",
        "\n",
        "@app.route('/api/v1/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\n",
        "        'status': 'healthy',\n",
        "        'timestamp': datetime.datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    port = int(os.environ.get('PORT', 5000))\n",
        "    host = os.environ.get('HOST', '0.0.0.0')\n",
        "    app.run(host=host, port=port)\n",
        "\"\"\"\n",
        "\n",
        "with open(server_dir / \"server.py\", 'w') as f:\n",
        "    f.write(server_script)\n",
        "\n",
        "print(f\"Server script created at {server_dir / 'server.py'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak0bFCuFWiax",
        "outputId": "9d32f807-6ba5-4c8e-b6c7-fd3a7bae7d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server script created at deployment/server/server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3 Implement Deployment Strategies"
      ],
      "metadata": {
        "id": "cG-6g-5hWpWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_deployment_scripts():\n",
        "    \"\"\"\n",
        "    Create scripts for implementing blue-green deployment\n",
        "    \"\"\"\n",
        "    deploy_dir = Path(\"deployment/scripts\")\n",
        "    deploy_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Create Docker file\n",
        "    dockerfile = \"\"\"FROM python:3.8-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "COPY . .\n",
        "\n",
        "ENV MODEL_PATH=./model.pkl\n",
        "ENV PORT=5000\n",
        "ENV HOST=0.0.0.0\n",
        "ENV MODEL_VERSION=1.0\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "\n",
        "EXPOSE 5000\n",
        "\n",
        "CMD [\"python\", \"server.py\"]\n",
        "\"\"\"\n",
        "\n",
        "    with open(deploy_dir / \"Dockerfile\", 'w') as f:\n",
        "        f.write(dockerfile)\n",
        "\n",
        "    # Create requirements file\n",
        "    requirements = \"\"\"Flask==2.0.1\n",
        "pandas==1.3.5\n",
        "numpy==1.21.5\n",
        "scikit-learn==1.0.2\n",
        "gunicorn==20.1.0\n",
        "prometheus-client==0.13.1\n",
        "\"\"\"\n",
        "\n",
        "    with open(deploy_dir / \"requirements.txt\", 'w') as f:\n",
        "        f.write(requirements)\n",
        "\n",
        "    # Create blue-green deployment script\n",
        "    deploy_script = \"\"\"#!/bin/bash\n",
        "# Blue-Green Deployment Script for Churn Prediction Model\n",
        "\n",
        "# Configuration\n",
        "MODEL_NAME=\"telco_churn_predictor\"\n",
        "MODEL_VERSION=$1\n",
        "DOCKER_REGISTRY=\"localhost:5000\"\n",
        "BLUE_PORT=5000\n",
        "GREEN_PORT=5001\n",
        "PROXY_PORT=8080\n",
        "HEALTH_CHECK_PATH=\"/api/v1/health\"\n",
        "MAX_HEALTH_CHECKS=10\n",
        "HEALTH_CHECK_INTERVAL=5\n",
        "\n",
        "# Check if model version is provided\n",
        "if [ -z \"$MODEL_VERSION\" ]; then\n",
        "    echo \"Error: Model version not provided\"\n",
        "    echo \"Usage: $0 <model_version>\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Deploying $MODEL_NAME version $MODEL_VERSION using Blue-Green strategy\"\n",
        "\n",
        "# Determine current active deployment (blue or green)\n",
        "CURRENT_ACTIVE=$(curl -s http://localhost:$PROXY_PORT/active 2>/dev/null || echo \"none\")\n",
        "\n",
        "if [ \"$CURRENT_ACTIVE\" == \"blue\" ]; then\n",
        "    NEW_COLOR=\"green\"\n",
        "    NEW_PORT=$GREEN_PORT\n",
        "    CURRENT_PORT=$BLUE_PORT\n",
        "elif [ \"$CURRENT_ACTIVE\" == \"green\" ]; then\n",
        "    NEW_COLOR=\"blue\"\n",
        "    NEW_PORT=$BLUE_PORT\n",
        "    CURRENT_PORT=$GREEN_PORT\n",
        "else\n",
        "    # First deployment or proxy not running\n",
        "    NEW_COLOR=\"blue\"\n",
        "    NEW_PORT=$BLUE_PORT\n",
        "    CURRENT_PORT=\"\"\n",
        "fi\n",
        "\n",
        "echo \"Current active deployment: $CURRENT_ACTIVE, deploying to $NEW_COLOR on port $NEW_PORT\"\n",
        "\n",
        "# Build and push new image\n",
        "echo \"Building Docker image for $NEW_COLOR deployment\"\n",
        "docker build -t $DOCKER_REGISTRY/$MODEL_NAME:$MODEL_VERSION-$NEW_COLOR \\\n",
        "    --build-arg MODEL_VERSION=$MODEL_VERSION \\\n",
        "    --build-arg PORT=$NEW_PORT \\\n",
        "    .\n",
        "\n",
        "echo \"Pushing Docker image to registry\"\n",
        "docker push $DOCKER_REGISTRY/$MODEL_NAME:$MODEL_VERSION-$NEW_COLOR\n",
        "\n",
        "# Deploy new version\n",
        "echo \"Deploying $NEW_COLOR version\"\n",
        "docker run -d --name $MODEL_NAME-$MODEL_VERSION-$NEW_COLOR \\\n",
        "    -p $NEW_PORT:5000 \\\n",
        "    -e MODEL_VERSION=$MODEL_VERSION \\\n",
        "    -e MODEL_COLOR=$NEW_COLOR \\\n",
        "    $DOCKER_REGISTRY/$MODEL_NAME:$MODEL_VERSION-$NEW_COLOR\n",
        "\n",
        "# Wait for new deployment to be ready\n",
        "echo \"Waiting for $NEW_COLOR deployment to be ready\"\n",
        "for i in $(seq 1 $MAX_HEALTH_CHECKS); do\n",
        "    echo \"Health check attempt $i/$MAX_HEALTH_CHECKS...\"\n",
        "    HEALTH_STATUS=$(curl -s http://localhost:$NEW_PORT$HEALTH_CHECK_PATH | grep -o '\"status\":\"healthy\"' || echo \"\")\n",
        "\n",
        "    if [ ! -z \"$HEALTH_STATUS\" ]; then\n",
        "        echo \"$NEW_COLOR deployment is healthy!\"\n",
        "        break\n",
        "    fi\n",
        "\n",
        "    if [ $i -eq $MAX_HEALTH_CHECKS ]; then\n",
        "        echo \"Error: $NEW_COLOR deployment failed health checks\"\n",
        "        echo \"Rolling back to $CURRENT_ACTIVE deployment\"\n",
        "        docker stop $MODEL_NAME-$MODEL_VERSION-$NEW_COLOR\n",
        "        docker rm $MODEL_NAME-$MODEL_VERSION-$NEW_COLOR\n",
        "        exit 1\n",
        "    fi\n",
        "\n",
        "    sleep $HEALTH_CHECK_INTERVAL\n",
        "done\n",
        "\n",
        "# Switch traffic to new deployment\n",
        "echo \"Updating proxy to route traffic to $NEW_COLOR deployment\"\n",
        "curl -s -X POST http://localhost:$PROXY_PORT/switch/$NEW_COLOR\n",
        "\n",
        "# Verify switch was successful\n",
        "NEW_ACTIVE=$(curl -s http://localhost:$PROXY_PORT/active)\n",
        "if [ \"$NEW_ACTIVE\" != \"$NEW_COLOR\" ]; then\n",
        "    echo \"Error: Failed to switch active deployment to $NEW_COLOR\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Traffic successfully routed to $NEW_COLOR deployment\"\n",
        "\n",
        "# Keep old deployment running for a while to allow in-flight requests to complete\n",
        "echo \"Waiting for in-flight requests to complete on old deployment\"\n",
        "sleep 30\n",
        "\n",
        "# Stop and remove old deployment if it exists\n",
        "if [ ! -z \"$CURRENT_PORT\" ]; then\n",
        "    OLD_CONTAINER_ID=$(docker ps -q --filter \"publish=$CURRENT_PORT\")\n",
        "    if [ ! -z \"$OLD_CONTAINER_ID\" ]; then\n",
        "        echo \"Stopping and removing old $CURRENT_ACTIVE deployment\"\n",
        "        docker stop $OLD_CONTAINER_ID\n",
        "        docker rm $OLD_CONTAINER_ID\n",
        "    fi\n",
        "fi\n",
        "\n",
        "echo \"Blue-Green deployment of $MODEL_NAME version $MODEL_VERSION completed successfully\"\n",
        "echo \"The model is now available at http://localhost:$PROXY_PORT\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(deploy_dir / \"deploy_blue_green.sh\", 'w') as f:\n",
        "        f.write(deploy_script)\n",
        "\n",
        "    # Create rollback script\n",
        "    rollback_script = \"\"\"#!/bin/bash\n",
        "# Rollback Script for Churn Prediction Model\n",
        "\n",
        "# Configuration\n",
        "MODEL_NAME=\"telco_churn_predictor\"\n",
        "PREVIOUS_VERSION=$1\n",
        "PROXY_PORT=8080\n",
        "\n",
        "# Check if previous version is provided\n",
        "if [ -z \"$PREVIOUS_VERSION\" ]; then\n",
        "    echo \"Error: Previous model version not provided\"\n",
        "    echo \"Usage: $0 <previous_version>\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Rolling back to $MODEL_NAME version $PREVIOUS_VERSION\"\n",
        "\n",
        "# Determine current active deployment (blue or green)\n",
        "CURRENT_ACTIVE=$(curl -s http://localhost:$PROXY_PORT/active 2>/dev/null || echo \"none\")\n",
        "\n",
        "if [ \"$CURRENT_ACTIVE\" == \"blue\" ]; then\n",
        "    ROLLBACK_COLOR=\"green\"\n",
        "elif [ \"$CURRENT_ACTIVE\" == \"green\" ]; then\n",
        "    ROLLBACK_COLOR=\"blue\"\n",
        "else\n",
        "    echo \"Error: No active deployment found\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Current active deployment: $CURRENT_ACTIVE, rolling back to $ROLLBACK_COLOR\"\n",
        "\n",
        "# Check if rollback image exists\n",
        "ROLLBACK_IMAGE_EXISTS=$(docker images -q $MODEL_NAME:$PREVIOUS_VERSION-$ROLLBACK_COLOR)\n",
        "if [ -z \"$ROLLBACK_IMAGE_EXISTS\" ]; then\n",
        "    echo \"Error: Rollback image $MODEL_NAME:$PREVIOUS_VERSION-$ROLLBACK_COLOR not found\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "# Deploy rollback version\n",
        "echo \"Deploying rollback version\"\n",
        "if [ \"$ROLLBACK_COLOR\" == \"blue\" ]; then\n",
        "    PORT=5000\n",
        "else\n",
        "    PORT=5001\n",
        "fi\n",
        "\n",
        "docker run -d --name $MODEL_NAME-$PREVIOUS_VERSION-$ROLLBACK_COLOR \\\n",
        "    -p $PORT:5000 \\\n",
        "    -e MODEL_VERSION=$PREVIOUS_VERSION \\\n",
        "    -e MODEL_COLOR=$ROLLBACK_COLOR \\\n",
        "    $MODEL_NAME:$PREVIOUS_VERSION-$ROLLBACK_COLOR\n",
        "\n",
        "# Wait for rollback deployment to be ready\n",
        "echo \"Waiting for rollback deployment to be ready\"\n",
        "for i in $(seq 1 10); do\n",
        "    echo \"Health check attempt $i/10...\"\n",
        "    HEALTH_STATUS=$(curl -s http://localhost:$PORT/api/v1/health | grep -o '\"status\":\"healthy\"' || echo \"\")\n",
        "\n",
        "    if [ ! -z \"$HEALTH_STATUS\" ]; then\n",
        "        echo \"Rollback deployment is healthy!\"\n",
        "        break\n",
        "    fi\n",
        "\n",
        "    if [ $i -eq 10 ]; then\n",
        "        echo \"Error: Rollback deployment failed health checks\"\n",
        "        docker stop $MODEL_NAME-$PREVIOUS_VERSION-$ROLLBACK_COLOR\n",
        "        docker rm $MODEL_NAME-$PREVIOUS_VERSION-$ROLLBACK_COLOR\n",
        "        exit 1\n",
        "    fi\n",
        "\n",
        "    sleep 5\n",
        "done\n",
        "\n",
        "# Switch traffic to rollback deployment\n",
        "echo \"Updating proxy to route traffic to rollback deployment\"\n",
        "curl -s -X POST http://localhost:$PROXY_PORT/switch/$ROLLBACK_COLOR\n",
        "\n",
        "# Verify switch was successful\n",
        "NEW_ACTIVE=$(curl -s http://localhost:$PROXY_PORT/active)\n",
        "if [ \"$NEW_ACTIVE\" != \"$ROLLBACK_COLOR\" ]; then\n",
        "    echo \"Error: Failed to switch active deployment\"\n",
        "    exit 1\n",
        "fi\n",
        "\n",
        "echo \"Traffic successfully routed to rollback deployment\"\n",
        "\n",
        "# Stop and remove current deployment\n",
        "OLD_CONTAINER_ID=$(docker ps -q --filter \"name=$MODEL_NAME\" --filter \"name=$CURRENT_ACTIVE\")\n",
        "if [ ! -z \"$OLD_CONTAINER_ID\" ]; then\n",
        "    echo \"Stopping and removing current deployment\"\n",
        "    docker stop $OLD_CONTAINER_ID\n",
        "    docker rm $OLD_CONTAINER_ID\n",
        "fi\n",
        "\n",
        "echo \"Rollback to $MODEL_NAME version $PREVIOUS_VERSION completed successfully\"\n",
        "echo \"The model is now available at http://localhost:$PROXY_PORT\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(deploy_dir / \"rollback.sh\", 'w') as f:\n",
        "        f.write(rollback_script)\n",
        "\n",
        "    # Make scripts executable\n",
        "    os.chmod(deploy_dir / \"deploy_blue_green.sh\", 0o755)\n",
        "    os.chmod(deploy_dir / \"rollback.sh\", 0o755)\n",
        "\n",
        "    print(f\"Deployment scripts created in {deploy_dir}\")\n",
        "    return deploy_dir\n",
        "\n",
        "# Create deployment scripts\n",
        "deploy_scripts_dir = create_deployment_scripts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATjUFYy3WsEO",
        "outputId": "3fcd9b05-8a18-4465-d66a-1c34b611b08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deployment scripts created in deployment/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4 Setup Monitoring Hooks"
      ],
      "metadata": {
        "id": "6LbFi6R9WuXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def create_monitoring_setup():\n",
        "    \"\"\"\n",
        "    Create monitoring setup for the deployed model.\n",
        "    Generates:\n",
        "       deployment/monitoring/prometheus.yml\n",
        "       deployment/monitoring/monitoring.py\n",
        "       deployment/monitoring/drift_detection.py\n",
        "    Returns\n",
        "    -------\n",
        "    pathlib.Path\n",
        "        Path to the monitoring directory.\n",
        "    \"\"\"\n",
        "    monitoring_dir = Path(\"deployment/monitoring\")\n",
        "    monitoring_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    # Prometheus configuration\n",
        "    # ------------------------------------------------------------------ #\n",
        "    prometheus_config = '''global:\n",
        "  scrape_interval: 15s\n",
        "  evaluation_interval: 15s\n",
        "\n",
        "scrape_configs:\n",
        "  - job_name: 'churn-predictor'\n",
        "    static_configs:\n",
        "      - targets: ['localhost:5000']\n",
        "    metrics_path: '/metrics'\n",
        "'''\n",
        "\n",
        "    (monitoring_dir / \"prometheus.yml\").write_text(prometheus_config)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    # Flask monitoring helpers\n",
        "    # ------------------------------------------------------------------ #\n",
        "    monitoring_script = '''import time\n",
        "from flask import request, Flask\n",
        "from prometheus_client import (\n",
        "    Counter,\n",
        "    Histogram,\n",
        "    Gauge,\n",
        "    generate_latest,\n",
        "    CONTENT_TYPE_LATEST,\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "# Prometheus metrics\n",
        "# ------------------------------------------------------------------ #\n",
        "REQUESTS = Counter(\n",
        "    \"churn_prediction_requests_total\",\n",
        "    \"Total number of prediction requests\",\n",
        "    [\"endpoint\", \"status\"],\n",
        ")\n",
        "LATENCY = Histogram(\n",
        "    \"churn_prediction_request_latency_seconds\",\n",
        "    \"Request latency in seconds\",\n",
        "    [\"endpoint\"],\n",
        ")\n",
        "PREDICTIONS = Counter(\n",
        "    \"churn_prediction_results_total\",\n",
        "    \"Total number of predictions by result\",\n",
        "    [\"prediction\"],\n",
        ")\n",
        "IN_PROGRESS = Gauge(\n",
        "    \"churn_prediction_requests_in_progress\",\n",
        "    \"Number of prediction requests in progress\",\n",
        ")\n",
        "MODEL_VERSION = Gauge(\n",
        "    \"churn_prediction_model_version\", \"Current model version\", [\"version\"]\n",
        ")\n",
        "\n",
        "\n",
        "def setup_monitoring(app: Flask, model_version: str) -> Flask:\n",
        "    \"\"\"\n",
        "    Attach Prometheus instrumentation to a Flask app.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    app : flask.Flask\n",
        "        The application instance.\n",
        "    model_version : str\n",
        "        Version string to expose as a metric.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    flask.Flask\n",
        "        The same app, instrumented.\n",
        "    \"\"\"\n",
        "    MODEL_VERSION.labels(version=model_version).set(1)\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Request lifecycle hooks\n",
        "    # -------------------------------------------------------------- #\n",
        "    @app.before_request\n",
        "    def _before_request():\n",
        "        request.start_time = time.time()\n",
        "        IN_PROGRESS.inc()\n",
        "\n",
        "    @app.after_request\n",
        "    def _after_request(response):\n",
        "        if hasattr(request, \"start_time\"):\n",
        "            LATENCY.labels(endpoint=request.endpoint).observe(\n",
        "                time.time() - request.start_time\n",
        "            )\n",
        "        IN_PROGRESS.dec()\n",
        "        REQUESTS.labels(endpoint=request.endpoint, status=response.status_code).inc()\n",
        "        return response\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # /metrics endpoint\n",
        "    # -------------------------------------------------------------- #\n",
        "    @app.route(\"/metrics\")\n",
        "    def metrics():\n",
        "        return generate_latest(), 200, {\"Content-Type\": CONTENT_TYPE_LATEST}\n",
        "\n",
        "    # -------------------------------------------------------------- #\n",
        "    # Helper for inference code\n",
        "    # -------------------------------------------------------------- #\n",
        "    def log_prediction(prediction):\n",
        "        PREDICTIONS.labels(\n",
        "            prediction=\"churn\" if prediction else \"no_churn\"\n",
        "        ).inc()\n",
        "\n",
        "    app.log_prediction = log_prediction  # type: ignore[attr-defined]\n",
        "    return app\n",
        "'''\n",
        "\n",
        "    (monitoring_dir / \"monitoring.py\").write_text(monitoring_script)\n",
        "\n",
        "    # ------------------------------------------------------------------ #\n",
        "    # Data-drift detection job\n",
        "    # ------------------------------------------------------------------ #\n",
        "    drift_detection_script = '''import json\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=\"drift_detection.log\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "logger = logging.getLogger(\"drift-detector\")\n",
        "\n",
        "\n",
        "def detect_drift(\n",
        "    reference_data_path: str,\n",
        "    current_data_path: str,\n",
        "    features_to_monitor: list[str],\n",
        "    threshold: float = 0.1,\n",
        "    output_dir: str = \"drift_reports\",\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Compare reference and production datasets with a KS test.\n",
        "\n",
        "    Returns a dictionary and writes a JSON report plus\n",
        "    distribution plots for each monitored feature.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting drift detection \")\n",
        "    out_dir = Path(output_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ref = pd.read_csv(reference_data_path)\n",
        "    cur = pd.read_csv(current_data_path)\n",
        "    logger.info(\"Loaded %d reference and %d current rows\", len(ref), len(cur))\n",
        "\n",
        "    report: dict = {\n",
        "        \"timestamp\": time.time(),\n",
        "        \"reference\": reference_data_path,\n",
        "        \"current\": current_data_path,\n",
        "        \"features\": features_to_monitor,\n",
        "        \"drift\": False,\n",
        "        \"drifted_features\": [],\n",
        "        \"metrics\": {},\n",
        "    }\n",
        "\n",
        "    for feat in features_to_monitor:\n",
        "        if feat not in ref or feat not in cur:\n",
        "            logger.warning(\"Feature %s missing in one of the datasets\", feat)\n",
        "            continue\n",
        "\n",
        "        ks_stat, p_value = ks_2samp(ref[feat], cur[feat])\n",
        "        drifted = p_value < threshold\n",
        "        if drifted:\n",
        "            report[\"drift\"] = True\n",
        "            report[\"drifted_features\"].append(feat)\n",
        "\n",
        "        report[\"metrics\"][feat] = {\n",
        "            \"ks_statistic\": float(ks_stat),\n",
        "            \"p_value\": float(p_value),\n",
        "            \"reference_mean\": float(ref[feat].mean()),\n",
        "            \"current_mean\": float(cur[feat].mean()),\n",
        "            \"reference_std\": float(ref[feat].std()),\n",
        "            \"current_std\": float(cur[feat].std()),\n",
        "            \"drift_detected\": drifted,\n",
        "        }\n",
        "\n",
        "        # plot distributions\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(ref[feat], alpha=0.5, label=\"Reference\")\n",
        "        plt.hist(cur[feat], alpha=0.5, label=\"Current\")\n",
        "        plt.title(f\"Distribution comparison  {feat}\")\n",
        "        plt.legend()\n",
        "        if drifted:\n",
        "            plt.annotate(\n",
        "                f\"DRIFT (p={p_value:.4f})\",\n",
        "                xy=(0.5, 0.92),\n",
        "                xycoords=\"axes fraction\",\n",
        "                ha=\"center\",\n",
        "                color=\"red\",\n",
        "                fontsize=12,\n",
        "            )\n",
        "        plt.savefig(out_dir / f\"drift_{feat}_{int(time.time())}.png\")\n",
        "        plt.close()\n",
        "        logger.info(\"%s  KS %.4f, p %.4f, drift %s\", feat, ks_stat, p_value, drifted)\n",
        "\n",
        "    json_path = out_dir / f\"drift_report_{int(time.time())}.json\"\n",
        "    json_path.write_text(json.dumps(report, indent=2))\n",
        "    logger.info(\"Drift report written to %s\", json_path)\n",
        "    return report\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    REF = \"data/features/telco_features_train.csv\"\n",
        "    CUR = \"data/production/current_data.csv\"\n",
        "    FEATURES = [\"tenure\", \"monthly_charges\", \"total_charges\", \"contract_type_code\", \"services_count\"]\n",
        "\n",
        "    rpt = detect_drift(REF, CUR, FEATURES)\n",
        "    if rpt[\"drift\"]:\n",
        "        logger.warning(\"Data drift detected! Consider retraining the model.\")\n",
        "'''\n",
        "\n",
        "    (monitoring_dir / \"drift_detection.py\").write_text(drift_detection_script)\n",
        "\n",
        "    print(f\"Monitoring setup written to {monitoring_dir}\")\n",
        "    return monitoring_dir\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------- #\n",
        "# Execute once to create the files\n",
        "# ---------------------------------------------------------------------- #\n",
        "if __name__ == \"__main__\":\n",
        "    create_monitoring_setup()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSfvPLEdWxml",
        "outputId": "31fba978-ee93-41ce-9609-72f91c5f2f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring setup written to deployment/monitoring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Production Monitoring & Observability"
      ],
      "metadata": {
        "id": "XHic4vxAXRD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Monitoring Dashboard Setup"
      ],
      "metadata": {
        "id": "TuXRmSaoXWib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_monitoring_dashboard():\n",
        "    \"\"\"\n",
        "    Create a monitoring dashboard setup for production\n",
        "    \"\"\"\n",
        "    dashboard_dir = Path(\"deployment/dashboards\")\n",
        "    dashboard_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Create a Grafana dashboard configuration\n",
        "    grafana_dashboard = \"\"\"{\n",
        "  \"annotations\": {\n",
        "    \"list\": [\n",
        "      {\n",
        "        \"builtIn\": 1,\n",
        "        \"datasource\": \"-- Grafana --\",\n",
        "        \"enable\": true,\n",
        "        \"hide\": true,\n",
        "        \"iconColor\": \"rgba(0, 211, 255, 1)\",\n",
        "        \"name\": \"Annotations & Alerts\",\n",
        "        \"type\": \"dashboard\"\n",
        "      },\n",
        "      {\n",
        "        \"datasource\": \"Prometheus\",\n",
        "        \"enable\": true,\n",
        "        \"expr\": \"resets(churn_prediction_model_version[1m]) > 0\",\n",
        "        \"iconColor\": \"rgba(255, 96, 96, 1)\",\n",
        "        \"name\": \"Model Version Changes\",\n",
        "        \"titleFormat\": \"Model Update\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  \"editable\": true,\n",
        "  \"gnetId\": null,\n",
        "  \"graphTooltip\": 0,\n",
        "  \"id\": 1,\n",
        "  \"links\": [],\n",
        "  \"panels\": [\n",
        "    {\n",
        "      \"datasource\": null,\n",
        "      \"gridPos\": {\n",
        "        \"h\": 3,\n",
        "        \"w\": 24,\n",
        "        \"x\": 0,\n",
        "        \"y\": 0\n",
        "      },\n",
        "      \"id\": 20,\n",
        "      \"options\": {\n",
        "        \"content\": \"# Telco Churn Prediction Model Dashboard\\\\nMonitoring metrics for the churn prediction model in production\",\n",
        "        \"mode\": \"markdown\"\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"title\": \"\",\n",
        "      \"type\": \"text\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Current model version deployed in production\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"mappings\": [],\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        },\n",
        "        \"overrides\": []\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 5,\n",
        "        \"w\": 4,\n",
        "        \"x\": 0,\n",
        "        \"y\": 3\n",
        "      },\n",
        "      \"id\": 18,\n",
        "      \"options\": {\n",
        "        \"colorMode\": \"value\",\n",
        "        \"graphMode\": \"none\",\n",
        "        \"justifyMode\": \"auto\",\n",
        "        \"orientation\": \"auto\",\n",
        "        \"reduceOptions\": {\n",
        "          \"calcs\": [\n",
        "            \"lastNotNull\"\n",
        "          ],\n",
        "          \"fields\": \"\",\n",
        "          \"values\": false\n",
        "        },\n",
        "        \"text\": {\n",
        "          \"valueSize\": 32\n",
        "        },\n",
        "        \"textMode\": \"name\"\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"churn_prediction_model_version\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"{{version}}\",\n",
        "          \"refId\": \"A\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Model Version\",\n",
        "      \"type\": \"stat\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Request rate for predictions\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"color\": {\n",
        "            \"mode\": \"palette-classic\"\n",
        "          },\n",
        "          \"mappings\": [],\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          \"unit\": \"reqps\"\n",
        "        },\n",
        "        \"overrides\": []\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 5,\n",
        "        \"w\": 6,\n",
        "        \"x\": 4,\n",
        "        \"y\": 3\n",
        "      },\n",
        "      \"id\": 14,\n",
        "      \"options\": {\n",
        "        \"colorMode\": \"value\",\n",
        "        \"graphMode\": \"area\",\n",
        "        \"justifyMode\": \"auto\",\n",
        "        \"orientation\": \"auto\",\n",
        "        \"reduceOptions\": {\n",
        "          \"calcs\": [\n",
        "            \"lastNotNull\"\n",
        "          ],\n",
        "          \"fields\": \"\",\n",
        "          \"values\": false\n",
        "        },\n",
        "        \"text\": {},\n",
        "        \"textMode\": \"auto\"\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"sum(rate(churn_prediction_requests_total{endpoint=\\\"predict\\\"}[1m]))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"Requests\",\n",
        "          \"refId\": \"A\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Prediction Request Rate\",\n",
        "      \"type\": \"stat\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Prediction distribution over time\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"color\": {\n",
        "            \"mode\": \"palette-classic\"\n",
        "          },\n",
        "          \"custom\": {\n",
        "            \"axisLabel\": \"\",\n",
        "            \"axisPlacement\": \"auto\",\n",
        "            \"barAlignment\": 0,\n",
        "            \"drawStyle\": \"line\",\n",
        "            \"fillOpacity\": 20,\n",
        "            \"gradientMode\": \"none\",\n",
        "            \"hideFrom\": {\n",
        "              \"legend\": false,\n",
        "              \"tooltip\": false,\n",
        "              \"viz\": false\n",
        "            },\n",
        "            \"lineInterpolation\": \"smooth\",\n",
        "            \"lineWidth\": 2,\n",
        "            \"pointSize\": 5,\n",
        "            \"scaleDistribution\": {\n",
        "              \"type\": \"linear\"\n",
        "            },\n",
        "            \"showPoints\": \"never\",\n",
        "            \"spanNulls\": false,\n",
        "            \"stacking\": {\n",
        "              \"group\": \"A\",\n",
        "              \"mode\": \"percent\"\n",
        "            },\n",
        "            \"thresholdsStyle\": {\n",
        "              \"mode\": \"off\"\n",
        "            }\n",
        "          },\n",
        "          \"mappings\": [],\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          \"unit\": \"percent\"\n",
        "        },\n",
        "        \"overrides\": [\n",
        "          {\n",
        "            \"matcher\": {\n",
        "              \"id\": \"byName\",\n",
        "              \"options\": \"Churn\"\n",
        "            },\n",
        "            \"properties\": [\n",
        "              {\n",
        "                \"id\": \"color\",\n",
        "                \"value\": {\n",
        "                  \"fixedColor\": \"red\",\n",
        "                  \"mode\": \"fixed\"\n",
        "                }\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          {\n",
        "            \"matcher\": {\n",
        "              \"id\": \"byName\",\n",
        "              \"options\": \"No Churn\"\n",
        "            },\n",
        "            \"properties\": [\n",
        "              {\n",
        "                \"id\": \"color\",\n",
        "                \"value\": {\n",
        "                  \"fixedColor\": \"green\",\n",
        "                  \"mode\": \"fixed\"\n",
        "                }\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 5,\n",
        "        \"w\": 14,\n",
        "        \"x\": 10,\n",
        "        \"y\": 3\n",
        "      },\n",
        "      \"id\": 16,\n",
        "      \"options\": {\n",
        "        \"legend\": {\n",
        "          \"displayMode\": \"list\",\n",
        "          \"placement\": \"bottom\"\n",
        "        },\n",
        "        \"tooltip\": {\n",
        "          \"mode\": \"single\"\n",
        "        }\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"rate(churn_prediction_results_total{prediction=\\\"churn\\\"}[5m]) / ignoring(prediction) sum by(job) (rate(churn_prediction_results_total[5m])) * 100\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"Churn\",\n",
        "          \"refId\": \"A\"\n",
        "        },\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"rate(churn_prediction_results_total{prediction=\\\"no_churn\\\"}[5m]) / ignoring(prediction) sum by(job) (rate(churn_prediction_results_total[5m])) * 100\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"No Churn\",\n",
        "          \"refId\": \"B\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Prediction Distribution\",\n",
        "      \"type\": \"timeseries\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Request latency histogram\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"color\": {\n",
        "            \"mode\": \"palette-classic\"\n",
        "          },\n",
        "          \"custom\": {\n",
        "            \"axisLabel\": \"\",\n",
        "            \"axisPlacement\": \"auto\",\n",
        "            \"barAlignment\": 0,\n",
        "            \"drawStyle\": \"line\",\n",
        "            \"fillOpacity\": 10,\n",
        "            \"gradientMode\": \"none\",\n",
        "            \"hideFrom\": {\n",
        "              \"legend\": false,\n",
        "              \"tooltip\": false,\n",
        "              \"viz\": false\n",
        "            },\n",
        "            \"lineInterpolation\": \"linear\",\n",
        "            \"lineWidth\": 1,\n",
        "            \"pointSize\": 5,\n",
        "            \"scaleDistribution\": {\n",
        "              \"type\": \"linear\"\n",
        "            },\n",
        "            \"showPoints\": \"never\",\n",
        "            \"spanNulls\": false,\n",
        "            \"stacking\": {\n",
        "              \"group\": \"A\",\n",
        "              \"mode\": \"none\"\n",
        "            },\n",
        "            \"thresholdsStyle\": {\n",
        "              \"mode\": \"off\"\n",
        "            }\n",
        "          },\n",
        "          \"mappings\": [],\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          \"unit\": \"s\"\n",
        "        },\n",
        "        \"overrides\": []\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 8,\n",
        "        \"w\": 12,\n",
        "        \"x\": 0,\n",
        "        \"y\": 8\n",
        "      },\n",
        "      \"id\": 10,\n",
        "      \"options\": {\n",
        "        \"legend\": {\n",
        "          \"displayMode\": \"list\",\n",
        "          \"placement\": \"bottom\"\n",
        "        },\n",
        "        \"tooltip\": {\n",
        "          \"mode\": \"single\"\n",
        "        }\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"histogram_quantile(0.5, sum by(le) (rate(churn_prediction_request_latency_seconds_bucket{endpoint=\\\"predict\\\"}[5m])))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"p50\",\n",
        "          \"refId\": \"A\"\n",
        "        },\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"histogram_quantile(0.9, sum by(le) (rate(churn_prediction_request_latency_seconds_bucket{endpoint=\\\"predict\\\"}[5m])))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"p90\",\n",
        "          \"refId\": \"B\"\n",
        "        },\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"histogram_quantile(0.95, sum by(le) (rate(churn_prediction_request_latency_seconds_bucket{endpoint=\\\"predict\\\"}[5m])))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"p95\",\n",
        "          \"refId\": \"C\"\n",
        "        },\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"histogram_quantile(0.99, sum by(le) (rate(churn_prediction_request_latency_seconds_bucket{endpoint=\\\"predict\\\"}[5m])))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"p99\",\n",
        "          \"refId\": \"D\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Prediction Latency\",\n",
        "      \"type\": \"timeseries\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Error rate for prediction requests\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"color\": {\n",
        "            \"mode\": \"thresholds\"\n",
        "          },\n",
        "          \"mappings\": [],\n",
        "          \"max\": 100,\n",
        "          \"min\": 0,\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              },\n",
        "              {\n",
        "                \"color\": \"orange\",\n",
        "                \"value\": 1\n",
        "              },\n",
        "              {\n",
        "                \"color\": \"red\",\n",
        "                \"value\": 5\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          \"unit\": \"percent\"\n",
        "        },\n",
        "        \"overrides\": []\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 8,\n",
        "        \"w\": 12,\n",
        "        \"x\": 12,\n",
        "        \"y\": 8\n",
        "      },\n",
        "      \"id\": 12,\n",
        "      \"options\": {\n",
        "        \"orientation\": \"auto\",\n",
        "        \"reduceOptions\": {\n",
        "          \"calcs\": [\n",
        "            \"lastNotNull\"\n",
        "          ],\n",
        "          \"fields\": \"\",\n",
        "          \"values\": false\n",
        "        },\n",
        "        \"showThresholdLabels\": false,\n",
        "        \"showThresholdMarkers\": true,\n",
        "        \"text\": {}\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"sum(rate(churn_prediction_requests_total{endpoint=\\\"predict\\\",status!=\\\"200\\\"}[5m])) / sum(rate(churn_prediction_requests_total{endpoint=\\\"predict\\\"}[5m])) * 100\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"Error Rate\",\n",
        "          \"refId\": \"A\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Error Rate\",\n",
        "      \"type\": \"gauge\"\n",
        "    },\n",
        "    {\n",
        "      \"datasource\": \"Prometheus\",\n",
        "      \"description\": \"Request rate over time by endpoint\",\n",
        "      \"fieldConfig\": {\n",
        "        \"defaults\": {\n",
        "          \"color\": {\n",
        "            \"mode\": \"palette-classic\"\n",
        "          },\n",
        "          \"custom\": {\n",
        "            \"axisLabel\": \"\",\n",
        "            \"axisPlacement\": \"auto\",\n",
        "            \"barAlignment\": 0,\n",
        "            \"drawStyle\": \"line\",\n",
        "            \"fillOpacity\": 10,\n",
        "            \"gradientMode\": \"none\",\n",
        "            \"hideFrom\": {\n",
        "              \"legend\": false,\n",
        "              \"tooltip\": false,\n",
        "              \"viz\": false\n",
        "            },\n",
        "            \"lineInterpolation\": \"linear\",\n",
        "            \"lineWidth\": 1,\n",
        "            \"pointSize\": 5,\n",
        "            \"scaleDistribution\": {\n",
        "              \"type\": \"linear\"\n",
        "            },\n",
        "            \"showPoints\": \"never\",\n",
        "            \"spanNulls\": false,\n",
        "            \"stacking\": {\n",
        "              \"group\": \"A\",\n",
        "              \"mode\": \"none\"\n",
        "            },\n",
        "            \"thresholdsStyle\": {\n",
        "              \"mode\": \"off\"\n",
        "            }\n",
        "          },\n",
        "          \"mappings\": [],\n",
        "          \"thresholds\": {\n",
        "            \"mode\": \"absolute\",\n",
        "            \"steps\": [\n",
        "              {\n",
        "                \"color\": \"green\",\n",
        "                \"value\": null\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          \"unit\": \"reqps\"\n",
        "        },\n",
        "        \"overrides\": []\n",
        "      },\n",
        "      \"gridPos\": {\n",
        "        \"h\": 9,\n",
        "        \"w\": 24,\n",
        "        \"x\": 0,\n",
        "        \"y\": 16\n",
        "      },\n",
        "      \"id\": 8,\n",
        "      \"options\": {\n",
        "        \"legend\": {\n",
        "          \"displayMode\": \"list\",\n",
        "          \"placement\": \"bottom\"\n",
        "        },\n",
        "        \"tooltip\": {\n",
        "          \"mode\": \"single\"\n",
        "        }\n",
        "      },\n",
        "      \"pluginVersion\": \"7.5.7\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"exemplar\": true,\n",
        "          \"expr\": \"sum by(endpoint) (rate(churn_prediction_requests_total[5m]))\",\n",
        "          \"interval\": \"\",\n",
        "          \"legendFormat\": \"{{endpoint}}\",\n",
        "          \"refId\": \"A\"\n",
        "        }\n",
        "      ],\n",
        "      \"title\": \"Request Rate by Endpoint\",\n",
        "      \"type\": \"timeseries\"\n",
        "    }\n",
        "  ],\n",
        "  \"refresh\": \"10s\",\n",
        "  \"schemaVersion\": 27,\n",
        "  \"style\": \"dark\",\n",
        "  \"tags\": [\n",
        "    \"mlops\",\n",
        "    \"machine learning\"\n",
        "  ],\n",
        "  \"templating\": {\n",
        "    \"list\": []\n",
        "  },\n",
        "  \"time\": {\n",
        "    \"from\": \"now-1h\",\n",
        "    \"to\": \"now\"\n",
        "  },\n",
        "  \"timepicker\": {},\n",
        "  \"timezone\": \"\",\n",
        "  \"title\": \"Telco Churn Prediction Dashboard\",\n",
        "  \"uid\": \"ML-telco-churn\",\n",
        "  \"version\": 1\n",
        "}\"\"\"\n",
        "\n",
        "    with open(dashboard_dir / \"telco_churn_dashboard.json\", 'w') as f:\n",
        "        f.write(grafana_dashboard)\n",
        "\n",
        "    print(f\"Monitoring dashboard configuration created in {dashboard_dir}\")\n",
        "    return dashboard_dir\n",
        "\n",
        "# Create monitoring dashboard\n",
        "dashboard_dir = create_monitoring_dashboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muxon2EHXYz_",
        "outputId": "3fee1a28-a4a6-4e97-e10b-b13f8ce23f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring dashboard configuration created in deployment/dashboards\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Setup Real-time Alerts"
      ],
      "metadata": {
        "id": "gaeRFnvnXdEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "def create_alerting_setup() -> Path:\n",
        "    \"\"\"Create alerting configuration files for Prometheus/Alertmanager.\n",
        "\n",
        "    Produces three files in ``deployment/alerts``:\n",
        "      - ``alert_rules.yml``\n",
        "      - ``alertmanager.yml``\n",
        "      - ``send_alert.py`` (stub example)\n",
        "    \"\"\"\n",
        "\n",
        "    alerts_dir = Path(\"deployment/alerts\")\n",
        "    alerts_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # --------------------------- alert_rules.yml ---------------------------\n",
        "    alert_rules = '''groups:\n",
        "- name: churn-prediction-alerts\n",
        "  rules:\n",
        "    - alert: HighLatency\n",
        "      expr: histogram_quantile(0.95, sum by(le) (rate(churn_prediction_request_latency_seconds_bucket{endpoint=\"predict\"}[5m]))) > 0.5\n",
        "      for: 5m\n",
        "      labels:\n",
        "        severity: warning\n",
        "      annotations:\n",
        "        summary: \"High prediction latency detected\"\n",
        "        description: \"95th percentile latency above 0.5s for 5min.\"\n",
        "'''\n",
        "    (alerts_dir / \"alert_rules.yml\").write_text(alert_rules)\n",
        "\n",
        "    # ------------------------- alertmanager.yml ---------------------------\n",
        "    alertmanager_config = '''global:\n",
        "  resolve_timeout: 5m\n",
        "route:\n",
        "  receiver: dev-null\n",
        "receivers:\n",
        "- name: dev-null\n",
        "'''\n",
        "    (alerts_dir / \"alertmanager.yml\").write_text(alertmanager_config)\n",
        "\n",
        "    # ---------------------------- send_alert.py ---------------------------\n",
        "    notification_script = '''#!/usr/bin/env python3\n",
        "\"\"\"Example stub: send alert messages to email & Slack.\n",
        "\n",
        "Replace SMTP/Slack settings before use.\n",
        "\"\"\"\n",
        "import sys\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Stub alert notifier  configure and extend as needed.\")\n",
        "'''\n",
        "    script_path = alerts_dir / \"send_alert.py\"\n",
        "    script_path.write_text(notification_script)\n",
        "    os.chmod(script_path, 0o755)\n",
        "\n",
        "    print(\"Wrote alerting configuration to\", alerts_dir)\n",
        "    return alerts_dir\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_alerting_setup()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ-MojwWXhFK",
        "outputId": "7b0e5934-1ccc-40cd-a119-ccc5656f0819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote alerting configuration to deployment/alerts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Governance & Continuous Improvement"
      ],
      "metadata": {
        "id": "fMb5PoLLZIOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1 Create Governance Framework"
      ],
      "metadata": {
        "id": "SnJ2Pv8EZPmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_governance_framework():\n",
        "    \"\"\"\n",
        "    Create a governance framework for ML Ops\n",
        "    \"\"\"\n",
        "    governance_dir = Path(\"governance\")\n",
        "    governance_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Create model card template\n",
        "    model_card = \"\"\"# Model Card: Telco Customer Churn Prediction\n",
        "\n",
        "## Model Details\n",
        "\n",
        "- **Model Name**: Telco Churn Predictor\n",
        "- **Version**: {model_version}\n",
        "- **Type**: Binary classification (Random Forest)\n",
        "- **Framework**: scikit-learn\n",
        "- **Date**: {date}\n",
        "- **License**: Internal use only\n",
        "- **Owner**: ML Ops Team\n",
        "\n",
        "## Intended Use\n",
        "\n",
        "- **Primary Use**: Predict the likelihood of customer churn in telecom services\n",
        "- **Intended Users**: Customer retention teams, marketing teams, service improvement teams\n",
        "- **Out-of-Scope Uses**: Should not be used for automated decision-making without human review, credit scoring, or determining service eligibility\n",
        "\n",
        "## Training Data\n",
        "\n",
        "- **Source**: Telco customer data\n",
        "- **Date Range**: {data_date_range}\n",
        "- **Size**: {data_size} records\n",
        "- **Preprocessing**: Feature engineering including:\n",
        "  - Categorical encoding\n",
        "  - Feature normalization\n",
        "  - Missing value imputation\n",
        "  - Derived features from raw attributes\n",
        "- **Data Split**:\n",
        "  - Training: 60%\n",
        "  - Validation: 20%\n",
        "  - Test: 20%\n",
        "\n",
        "## Evaluation Data\n",
        "\n",
        "- **Source**: Held-out test set from same distribution as training\n",
        "- **Size**: {test_size} records\n",
        "- **Preprocessing**: Same transformations as training data\n",
        "\n",
        "## Model Performance Metrics\n",
        "\n",
        "- **Accuracy**: {accuracy:.4f}\n",
        "- **Precision**: {precision:.4f}\n",
        "- **Recall**: {recall:.4f}\n",
        "- **F1 Score**: {f1:.4f}\n",
        "- **ROC AUC**: {roc_auc:.4f}\n",
        "- **Performance Notes**: Model demonstrates better precision than recall, meaning it is more likely to miss some customers who will churn than to incorrectly flag customers who won't churn.\n",
        "\n",
        "## Ethical Considerations\n",
        "\n",
        "- **Fairness Assessment**: Model was evaluated across demographic groups to ensure similar performance.\n",
        "- **Potential Biases**:\n",
        "  - Model may have lower accuracy for new customers with limited history\n",
        "  - Model performance varies by contract type (month-to-month vs. longer contracts)\n",
        "- **Mitigations**: Regular monitoring of prediction distribution across customer segments\n",
        "\n",
        "## Limitations\n",
        "\n",
        "- Model is trained on historical data and may not capture sudden market changes\n",
        "- Predictions reflect correlation, not causation\n",
        "- Model does not account for external market factors (competitor actions, market trends)\n",
        "- Performance degrades for customer segments underrepresented in training data\n",
        "\n",
        "## Monitoring and Maintenance\n",
        "\n",
        "- **Monitoring**:\n",
        "  - Prediction distribution monitoring (daily)\n",
        "  - Feature drift detection (weekly)\n",
        "  - Performance evaluation on new labeled data (monthly)\n",
        "- **Retraining Frequency**: Quarterly or upon significant drift detection\n",
        "- **Versioning**: All model versions stored in model registry with reproducible training pipeline\n",
        "\n",
        "## Feedback and Reporting Issues\n",
        "\n",
        "For issues, bias reports, or improvement suggestions:\n",
        "- Contact: ml-team@example.com\n",
        "- Submit ticket: [ML Ops Portal](http://mlops.example.com)\n",
        "- Report ethics concerns: ethics-hotline@example.com\n",
        "\"\"\"\n",
        "\n",
        "    with open(governance_dir / \"model_card_template.md\", 'w') as f:\n",
        "        f.write(model_card)\n",
        "\n",
        "    # Create data dictionary template\n",
        "    data_dictionary = \"\"\"# Data Dictionary: Telco Customer Dataset\n",
        "\n",
        "    ## Feature Descriptions\n",
        "\n",
        "### Customer Information\n",
        "| Feature           | Description                                        | Data Type | Example Values                   |\n",
        "|-------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| customer_id       | Unique identifier for each customer                | string    | CUST-00123                       |\n",
        "| gender            | Customer's gender                                 | string    | Male, Female                     |\n",
        "| senior_citizen    | Whether customer is a senior citizen (65+)         | integer   | 0 (No), 1 (Yes)                 |\n",
        "| partner           | Whether customer has a partner                     | string    | Yes, No                         |\n",
        "| dependents        | Whether customer has dependents                    | string    | Yes, No                         |\n",
        "\n",
        "### Account Information\n",
        "| Feature           | Description                                        | Data Type | Example Values                   |\n",
        "|-------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| tenure            | Number of months customer has been with company    | integer   | 0-72                            |\n",
        "| contract          | Contract term                                      | string    | Month-to-month, One year, Two year |\n",
        "| tech_support      | Whether customer has tech support                  | string    | Yes, No, No internet service    |\n",
        "\n",
        "### Services Information\n",
        "| Feature           | Description                                        | Data Type | Example Values                   |\n",
        "|-------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| phone_service     | Whether customer has phone service                 | string    | Yes, No                         |\n",
        "| multiple_lines    | Whether customer has multiple lines                | string    | Yes, No, No phone service       |\n",
        "| internet_service  | Customer's internet service provider               | string    | DSL, Fiber optic, No            |\n",
        "| online_security   | Whether customer has online security               | string    | Yes, No, No internet service    |\n",
        "| online_backup     | Whether customer has online backup                 | string    | Yes, No, No internet service    |\n",
        "| device_protection | Whether customer has device protection             | string    | Yes, No, No internet service    |\n",
        "| streaming_tv      | Whether customer has streaming TV                  | string    | Yes, No, No internet service    |\n",
        "| streaming_movies  | Whether customer has streaming movies              | string    | Yes, No, No internet service    |\n",
        "\n",
        "### Billing Information\n",
        "| Feature           | Description                                        | Data Type | Example Values                   |\n",
        "|-------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| payment_method    | Customer's payment method                          | string    | Electronic check, Mailed check, Bank transfer, Credit card |\n",
        "| paperless_billing | Whether customer uses paperless billing            | string    | Yes, No                         |\n",
        "| monthly_charges   | Amount charged to customer monthly                 | float     | 18.25 - 118.75                  |\n",
        "| total_charges     | Total amount charged to customer                   | float     | 18.8 - 8684.8                   |\n",
        "\n",
        "### Target Variable\n",
        "| Feature           | Description                                        | Data Type | Example Values                   |\n",
        "|-------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| churn             | Whether customer left within last month            | string    | Yes, No                         |\n",
        "| churn_binary      | Binary representation of churn                     | integer   | 0 (No), 1 (Yes)                 |\n",
        "\n",
        "### Engineered Features\n",
        "| Feature                | Description                                        | Data Type | Example Values                   |\n",
        "|------------------------|----------------------------------------------------|-----------|----------------------------------|\n",
        "| tenure_years           | Tenure in years (tenure / 12)                      | float     | 0.0 - 6.0                       |\n",
        "| tenure_group           | Bucketed tenure                                    | category  | 0-1 year, 1-2 years, etc.       |\n",
        "| avg_monthly_charges    | Average charge per month of tenure                 | float     | 18.25 - 118.75                  |\n",
        "| monthly_charges_category| Categorized monthly charges                        | category  | Low, Medium, High, Very High    |\n",
        "| services_count         | Count of services subscribed                       | integer   | 0 - 8                           |\n",
        "| contract_type_code     | Coded contract type                                | integer   | 0 (Month-to-month), 1 (One year), 2 (Two year) |\n",
        "\n",
        "## Data Quality Notes\n",
        "- Missing values may occur in `total_charges` for new customers with tenure=0\n",
        "- `churn_binary` is derived from `churn` by mapping 'Yes' to 1 and 'No' to 0\n",
        "- `multiple_lines` and all internet-specific services have conditional values based on having the parent service\n",
        "\"\"\"\n",
        "\n",
        "    with open(governance_dir / \"data_dictionary.md\", 'w') as f:\n",
        "        f.write(data_dictionary)\n",
        "\n",
        "    # Create model review checklist\n",
        "    review_checklist = \"\"\"# ML Model Review Checklist\n",
        "\n",
        "## Model Information\n",
        "- [ ] Model type and architecture clearly documented\n",
        "- [ ] Model version properly recorded\n",
        "- [ ] Training code version controlled\n",
        "- [ ] Hyperparameters documented\n",
        "- [ ] Dependencies and environment specifications captured\n",
        "\n",
        "## Data Validation\n",
        "- [ ] Training data lineage documented\n",
        "- [ ] Data quality metrics captured\n",
        "- [ ] Data preparation steps documented\n",
        "- [ ] Data split methodology documented\n",
        "- [ ] Data leakage risks assessed\n",
        "- [ ] Sensitive data handling compliant with policies\n",
        "\n",
        "## Model Performance\n",
        "- [ ] Performance metrics meet business requirements\n",
        "- [ ] Performance evaluated on appropriate test set\n",
        "- [ ] Performance consistent across relevant data segments\n",
        "- [ ] Comparison with baseline model documented\n",
        "- [ ] Edge cases and potential failure modes analyzed\n",
        "\n",
        "## Ethical & Fairness Considerations\n",
        "- [ ] Model evaluated for bias across protected attributes\n",
        "- [ ] Performance across demographic groups analyzed\n",
        "- [ ] Decision thresholds reviewed for fairness implications\n",
        "- [ ] Privacy implications considered\n",
        "- [ ] Model explainability needs assessed\n",
        "\n",
        "## Operational Readiness\n",
        "- [ ] Monitoring plan defined\n",
        "- [ ] Alerts and thresholds established\n",
        "- [ ] Drift detection mechanisms in place\n",
        "- [ ] Rollback procedure documented\n",
        "- [ ] Load testing completed\n",
        "- [ ] Latency requirements met\n",
        "\n",
        "## Documentation\n",
        "- [ ] Model card completed\n",
        "- [ ] API specifications documented\n",
        "- [ ] Example requests and responses provided\n",
        "- [ ] Known limitations clearly stated\n",
        "- [ ] Intended use cases and restrictions defined\n",
        "\n",
        "## Compliance & Risk\n",
        "- [ ] Regulatory requirements identified and addressed\n",
        "- [ ] Data usage complies with privacy policies\n",
        "- [ ] Model complies with company AI guidelines\n",
        "- [ ] Potential misuse scenarios considered\n",
        "- [ ] Appropriate access controls implemented\n",
        "\n",
        "## Approvals\n",
        "- [ ] Data science team approval\n",
        "- [ ] Engineering team approval\n",
        "- [ ] Business stakeholder approval\n",
        "- [ ] Legal/compliance approval (if applicable)\n",
        "- [ ] Security team approval (if applicable)\n",
        "\n",
        "## Reviewer Information\n",
        "- **Review Date**:\n",
        "- **Reviewer Name**:\n",
        "- **Model Version Reviewed**:\n",
        "- **Recommendation**:  Approve   Approve with Changes   Reject\n",
        "- **Comments**:\n",
        "\"\"\"\n",
        "\n",
        "    with open(governance_dir / \"model_review_checklist.md\", 'w') as f:\n",
        "        f.write(review_checklist)\n",
        "\n",
        "    # Create ethics guidelines\n",
        "    ethics_guidelines = \"\"\"# ML Ethics Guidelines\n",
        "\n",
        "## Core Principles\n",
        "\n",
        "1. **Fairness**: Models should not discriminate against individuals or groups based on protected attributes.\n",
        "\n",
        "2. **Transparency**: The operation and decision-making process of our ML systems should be explainable and understandable.\n",
        "\n",
        "3. **Privacy**: ML systems must respect user privacy and comply with data protection regulations.\n",
        "\n",
        "4. **Accountability**: Clear responsibility for ML systems must be established and maintained throughout their lifecycle.\n",
        "\n",
        "5. **Safety & Security**: ML systems should be designed to be robust, secure, and prevent potential harms.\n",
        "\n",
        "6. **Human Oversight**: ML systems should support human decision-making, not replace it without appropriate oversight.\n",
        "\n",
        "## Practical Implementation\n",
        "\n",
        "### Fairness Implementation\n",
        "\n",
        "- **Assessment**: Evaluate model performance across different demographic groups and protected attributes.\n",
        "- **Mitigation**: Implement bias mitigation techniques where disparities are found.\n",
        "- **Documentation**: Document fairness metrics and any tradeoffs made in model development.\n",
        "- **Monitoring**: Continuously monitor production models for emerging bias.\n",
        "\n",
        "#### Required Actions:\n",
        "- Conduct fairness analysis before any model deployment\n",
        "- Include demographic analysis in regular model reporting\n",
        "- Define fairness metrics relevant to each use case\n",
        "\n",
        "### Transparency Implementation\n",
        "\n",
        "- **Documentation**: Create clear documentation of data sources, model architecture, and design decisions.\n",
        "- **Interpretability**: For high-risk decisions, prioritize interpretable models or add explanation mechanisms.\n",
        "- **Communication**: Ensure affected users understand how automated decisions are made.\n",
        "- **Traceability**: Maintain complete audit trails of model inputs, outputs, and decisions.\n",
        "\n",
        "#### Required Actions:\n",
        "- Create and maintain model cards for all production models\n",
        "- Document feature importance and decision factors\n",
        "- Provide mechanisms for explaining individual predictions\n",
        "\n",
        "### Privacy Implementation\n",
        "\n",
        "- **Data Minimization**: Only collect and retain data necessary for the specific purpose.\n",
        "- **Anonymization**: De-identify personal data where possible.\n",
        "- **Security**: Implement appropriate security measures to protect sensitive data.\n",
        "- **Consent**: Ensure proper consent mechanisms for data collection and use.\n",
        "\n",
        "#### Required Actions:\n",
        "- Complete privacy impact assessment for each ML project\n",
        "- Implement data retention and deletion policies\n",
        "- Ensure model design respects user privacy preferences\n",
        "\n",
        "### Accountability Implementation\n",
        "\n",
        "- **Governance**: Establish clear roles and responsibilities for ML development and deployment.\n",
        "- **Review**: Implement multi-stakeholder review of high-risk ML applications.\n",
        "- **Auditability**: Enable third-party auditing of ML systems when appropriate.\n",
        "- **Redress**: Create mechanisms for challenging and correcting erroneous automated decisions.\n",
        "\n",
        "#### Required Actions:\n",
        "- Define ownership and responsibility for each model\n",
        "- Establish review committee for high-risk applications\n",
        "- Create clear feedback channels for affected users\n",
        "\n",
        "## Risk Assessment Framework\n",
        "\n",
        "| Risk Level | Description | Required Oversight |\n",
        "|------------|-------------|-------------------|\n",
        "| **Level 1 (Low)** | Models with minimal potential for harm; decisions easily reversible | Team lead review; standard documentation |\n",
        "| **Level 2 (Medium)** | Models affecting user experience or business operations; limited potential for harm | Cross-functional review; enhanced monitoring |\n",
        "| **Level 3 (High)** | Models making significant decisions affecting individuals; potential for discrimination or harm | Ethics board review; detailed impact assessment; enhanced explainability |\n",
        "| **Level 4 (Critical)** | Models with direct impact on physical safety, civil rights, or significant life decisions | Full ethics review; external audit; continuous human oversight |\n",
        "\n",
        "## Escalation Process\n",
        "\n",
        "1. **Identification**: Any team member who identifies an ethical concern should first discuss it with their team lead\n",
        "2. **Documentation**: Document the concern in the project's ethics log\n",
        "3. **Assessment**: Ethics representative assesses the concern's severity\n",
        "4. **Mediation**: For medium-risk issues, ethics representative works with team to address\n",
        "5. **Escalation**: High and critical issues escalated to Ethics Board\n",
        "6. **Resolution**: Implement required changes and document resolution\n",
        "7. **Follow-up**: Schedule follow-up review to ensure concerns have been addressed\n",
        "\n",
        "## Resources\n",
        "\n",
        "- Ethics Office: ethics@example.com\n",
        "- Ethics Board: ethics-board@example.com\n",
        "- Ethics Hotline: +1-800-555-0100\n",
        "- [Ethics Guidelines Portal](http://ethics.example.com)\n",
        "- [ML Fairness Tools](http://mltools.example.com/fairness)\n",
        "\"\"\"\n",
        "\n",
        "    with open(governance_dir / \"ethics_guidelines.md\", 'w') as f:\n",
        "        f.write(ethics_guidelines)\n",
        "\n",
        "    print(f\"Governance framework created in {governance_dir}\")\n",
        "    return governance_dir\n",
        "\n",
        "# Create governance framework\n",
        "governance_dir = create_governance_framework()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7kkMtXeZSes",
        "outputId": "769c67ce-5f60-4ebc-b6df-a1ab7622c89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Governance framework created in governance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Set Up Continuous Improvement Process"
      ],
      "metadata": {
        "id": "fnFFcQ_bZZDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_continuous_improvement_process():\n",
        "    \"\"\"\n",
        "    Create a continuous improvement process for ML models\n",
        "    \"\"\"\n",
        "    improvement_dir = Path(\"continuous_improvement\")\n",
        "    improvement_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Create model performance tracking script\n",
        "    performance_tracking = \"\"\"#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import logging\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    filename='model_performance_tracking.log'\n",
        ")\n",
        "logger = logging.getLogger('performance-tracker')\n",
        "\n",
        "def track_model_performance(\n",
        "    model_path,\n",
        "    labeled_data_path,\n",
        "    output_dir='performance_history',\n",
        "    model_version=None\n",
        "):\n",
        "    \\\"\\\"\\\"\n",
        "    Track model performance over time with new labeled data\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to the model file\n",
        "        labeled_data_path: Path to new labeled data\n",
        "        output_dir: Directory to save performance tracking\n",
        "        model_version: Model version (if None, extracted from path)\n",
        "\n",
        "    Returns:\n",
        "        performance_data: Dictionary with performance metrics\n",
        "    \\\"\\\"\\\"\n",
        "    logger.info(f\"Starting performance tracking for {model_path}\")\n",
        "\n",
        "    # Create output directory\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Extract model version if not provided\n",
        "    if model_version is None:\n",
        "        model_version = os.path.basename(model_path).split('_')[-1].replace('.pkl', '')\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        with open(model_path, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "        logger.info(f\"Loaded model from {model_path}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load model: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Load labeled data\n",
        "    try:\n",
        "        labeled_data = pd.read_csv(labeled_data_path)\n",
        "        logger.info(f\"Loaded labeled data from {labeled_data_path} with {len(labeled_data)} records\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load labeled data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Check if data has required columns\n",
        "    if 'churn' not in labeled_data.columns and 'churn_binary' not in labeled_data.columns:\n",
        "        logger.error(f\"Labeled data missing target column (churn or churn_binary)\")\n",
        "        return None\n",
        "\n",
        "    # Use churn_binary if available, otherwise convert churn to binary\n",
        "    if 'churn_binary' in labeled_data.columns:\n",
        "        y_true = labeled_data['churn_binary']\n",
        "    else:\n",
        "        y_true = labeled_data['churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    # Get features\n",
        "    X = labeled_data.drop(['churn', 'churn_binary'] if 'churn_binary' in labeled_data.columns else ['churn'], axis=1)\n",
        "\n",
        "    # Make predictions\n",
        "    try:\n",
        "        y_pred = model.predict(X)\n",
        "        y_prob = model.predict_proba(X)[:, 1]\n",
        "        logger.info(f\"Generated predictions for {len(X)} records\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to generate predictions: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    metrics = {\n",
        "        'timestamp': datetime.datetime.now().isoformat(),\n",
        "        'model_version': model_version,\n",
        "        'data_path': labeled_data_path,\n",
        "        'data_size': len(labeled_data),\n",
        "        'accuracy': float(accuracy_score(y_true, y_pred)),\n",
        "        'precision': float(precision_score(y_true, y_pred)),\n",
        "        'recall': float(recall_score(y_true, y_pred)),\n",
        "        'f1_score': float(f1_score(y_true, y_pred)),\n",
        "        'roc_auc': float(roc_auc_score(y_true, y_prob))\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Model performance: acc={metrics['accuracy']:.4f}, f1={metrics['f1_score']:.4f}, auc={metrics['roc_auc']:.4f}\")\n",
        "\n",
        "    # Load historical performance data if exists\n",
        "    history_path = output_path / \"performance_history.json\"\n",
        "    if history_path.exists():\n",
        "        with open(history_path, 'r') as f:\n",
        "            history = json.load(f)\n",
        "    else:\n",
        "        history = []\n",
        "\n",
        "    # Add current metrics to history\n",
        "    history.append(metrics)\n",
        "\n",
        "    # Save updated history\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "\n",
        "    # Generate performance trend plot\n",
        "    if len(history) > 1:\n",
        "        # Extract metrics over time\n",
        "        timestamps = [datetime.datetime.fromisoformat(entry['timestamp']) for entry in history]\n",
        "        accuracies = [entry['accuracy'] for entry in history]\n",
        "        f1_scores = [entry['f1_score'] for entry in history]\n",
        "        roc_aucs = [entry['roc_auc'] for entry in history]\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(timestamps, accuracies, 'o-', label='Accuracy')\n",
        "        plt.plot(timestamps, f1_scores, 's-', label='F1 Score')\n",
        "        plt.plot(timestamps, roc_aucs, '^-', label='ROC AUC')\n",
        "        plt.title(f\"Model Performance Over Time (Version {model_version})\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Score\")\n",
        "        plt.ylim(0, 1)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Format x-axis dates\n",
        "        plt.gcf().autofmt_xdate()\n",
        "\n",
        "        # Save plot\n",
        "        plot_path = output_path / f\"performance_trend_{datetime.datetime.now().strftime('%Y%m%d')}.png\"\n",
        "        plt.savefig(plot_path)\n",
        "        logger.info(f\"Generated performance trend plot at {plot_path}\")\n",
        "\n",
        "        # Add alert if performance degrades significantly\n",
        "        if metrics['f1_score'] < history[-2]['f1_score'] * 0.9:  # 10% degradation\n",
        "            logger.warning(f\"ALERT: Model performance degraded by more than 10% (F1 score: {history[-2]['f1_score']:.4f} -> {metrics['f1_score']:.4f})\")\n",
        "\n",
        "            # Create alert file\n",
        "            alert = {\n",
        "                \"timestamp\": metrics['timestamp'],\n",
        "                \"model_version\": model_version,\n",
        "                \"alert_type\": \"performance_degradation\",\n",
        "                \"metric\": \"f1_score\",\n",
        "                \"previous_value\": history[-2]['f1_score'],\n",
        "                \"current_value\": metrics['f1_score'],\n",
        "                \"degradation_pct\": (history[-2]['f1_score'] - metrics['f1_score']) / history[-2]['f1_score'] * 100\n",
        "            }\n",
        "\n",
        "            alerts_path = output_path / \"performance_alerts.json\"\n",
        "            if alerts_path.exists():\n",
        "                with open(alerts_path, 'r') as f:\n",
        "                    alerts = json.load(f)\n",
        "            else:\n",
        "                alerts = []\n",
        "\n",
        "            alerts.append(alert)\n",
        "\n",
        "            with open(alerts_path, 'w') as f:\n",
        "                json.dump(alerts, f, indent=2)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def main():\n",
        "    # This would typically be run as a scheduled job\n",
        "    model_path = \"models/telco_churn_predictor_v1.pkl\"\n",
        "    labeled_data_path = \"data/production/monthly_labeled_data.csv\"\n",
        "\n",
        "    performance_data = track_model_performance(\n",
        "        model_path,\n",
        "        labeled_data_path\n",
        "    )\n",
        "\n",
        "    # If significant degradation, trigger model retraining\n",
        "    if performance_data and performance_data.get('f1_score', 0) < 0.7:\n",
        "        logger.warning(\"Performance below threshold! Triggering model retraining.\")\n",
        "        # In a real system, this would call a retraining pipeline\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\"\"\"\n",
        "\n",
        "    with open(improvement_dir / \"track_performance.py\", 'w') as f:\n",
        "        f.write(performance_tracking)\n",
        "    os.chmod(improvement_dir / \"track_performance.py\", 0o755)\n",
        "\n",
        "    # Create improvement proposal template\n",
        "    improvement_template = \"\"\"# Model Improvement Proposal\n",
        "\n",
        "## Overview\n",
        "\n",
        "- **Proposal ID**: MIP-{proposal_id}\n",
        "- **Title**: {title}\n",
        "- **Author**: {author}\n",
        "- **Created Date**: {created_date}\n",
        "- **Status**: {status} (Draft | Under Review | Approved | Implemented | Rejected)\n",
        "- **Priority**: {priority} (Low | Medium | High | Critical)\n",
        "- **Target Implementation Date**: {target_date}\n",
        "\n",
        "## Background\n",
        "\n",
        "{background_text}\n",
        "\n",
        "## Current Limitations\n",
        "\n",
        "{limitations_text}\n",
        "\n",
        "## Proposed Solution\n",
        "\n",
        "{solution_text}\n",
        "\n",
        "### Expected Benefits\n",
        "\n",
        "- {benefit_1}\n",
        "- {benefit_2}\n",
        "- ...\n",
        "\n",
        "### Implementation Plan\n",
        "\n",
        "1. {step_1}\n",
        "2. {step_2}\n",
        "3. ...\n",
        "\n",
        "### Resources Required\n",
        "\n",
        "- **Engineering Resources**: {engineering_resources}\n",
        "- **Data Science Resources**: {ds_resources}\n",
        "- **Infrastructure**: {infrastructure}\n",
        "- **Timeline**: {timeline}\n",
        "\n",
        "### Success Metrics\n",
        "\n",
        "- **Primary KPI**: {primary_kpi}\n",
        "- **Secondary Metrics**: {secondary_metrics}\n",
        "- **Performance Target**: {performance_target}\n",
        "\n",
        "## Risks and Mitigations\n",
        "\n",
        "| Risk | Likelihood | Impact | Mitigation |\n",
        "|------|------------|--------|------------|\n",
        "| {risk_1} | {likelihood_1} | {impact_1} | {mitigation_1} |\n",
        "| {risk_2} | {likelihood_2} | {impact_2} | {mitigation_2} |\n",
        "\n",
        "## Alternatives Considered\n",
        "\n",
        "{alternatives_text}\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "- {dependency_1}\n",
        "- {dependency_2}\n",
        "- ...\n",
        "\n",
        "## Stakeholder Feedback\n",
        "\n",
        "- **Data Science**: {ds_feedback}\n",
        "- **Engineering**: {eng_feedback}\n",
        "- **Product**: {product_feedback}\n",
        "- **Business**: {business_feedback}\n",
        "\n",
        "## Decision Log\n",
        "\n",
        "| Date | Decision | Reasoning | Participants |\n",
        "|------|----------|-----------|--------------|\n",
        "| {decision_date_1} | {decision_1} | {reasoning_1} | {participants_1} |\n",
        "| {decision_date_2} | {decision_2} | {reasoning_2} | {participants_2} |\n",
        "\n",
        "## Implementation Checklist\n",
        "\n",
        "- [ ] Prototype developed and validated\n",
        "- [ ] Tests created\n",
        "- [ ] Documentation updated\n",
        "- [ ] Code reviewed\n",
        "- [ ] Performance benchmarked\n",
        "- [ ] Monitoring plan updated\n",
        "- [ ] Rollback procedures defined\n",
        "- [ ] Stakeholder sign-off\n",
        "\n",
        "## Post-Implementation Review\n",
        "\n",
        "To be completed after implementation:\n",
        "\n",
        "- **Actual Implementation Date**: {actual_date}\n",
        "- **Performance Outcome**: {performance_outcome}\n",
        "- **Lessons Learned**: {lessons_learned}\n",
        "- **Follow-up Actions**: {followup_actions}\"\"\"\n",
        "\n",
        "    with open(improvement_dir / \"improvement_proposal_template.md\", 'w') as f:\n",
        "        f.write(improvement_template)\n",
        "\n",
        "    # Create automated retraining pipeline\n",
        "    retraining_pipeline = \"\"\"#!/usr/bin/env python3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import datetime\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    filename='retraining_pipeline.log'\n",
        ")\n",
        "logger = logging.getLogger('retraining-pipeline')\n",
        "\n",
        "def check_retraining_triggers():\n",
        "    \\\"\\\"\\\"\n",
        "    Check if any retraining triggers have been activated\n",
        "\n",
        "    Returns:\n",
        "        should_retrain: Boolean indicating whether retraining should occur\n",
        "        trigger_info: Dictionary with trigger information\n",
        "    \\\"\\\"\\\"\n",
        "    triggers = {\n",
        "        'data_drift': False,\n",
        "        'performance_degradation': False,\n",
        "        'scheduled': False,\n",
        "        'manual': False\n",
        "    }\n",
        "\n",
        "    # Check for data drift trigger\n",
        "    drift_dir = Path(\"drift_reports\")\n",
        "    if drift_dir.exists():\n",
        "        # Get most recent drift report\n",
        "        drift_files = list(drift_dir.glob(\"drift_report_*.json\"))\n",
        "        if drift_files:\n",
        "            latest_drift_file = max(drift_files, key=lambda p: p.stat().st_mtime)\n",
        "            with open(latest_drift_file, 'r') as f:\n",
        "                drift_report = json.load(f)\n",
        "\n",
        "            # Check if drift was detected\n",
        "            if drift_report.get('drift_detected', False):\n",
        "                triggers['data_drift'] = True\n",
        "                logger.info(f\"Data drift trigger activated: {drift_report.get('drifted_features', [])}\")\n",
        "\n",
        "    # Check for performance degradation trigger\n",
        "    perf_dir = Path(\"continuous_improvement/performance_history\")\n",
        "    if perf_dir.exists():\n",
        "        alerts_file = perf_dir / \"performance_alerts.json\"\n",
        "        if alerts_file.exists():\n",
        "            with open(alerts_file, 'r') as f:\n",
        "                alerts = json.load(f)\n",
        "\n",
        "            # Check for recent alerts (within last 24 hours)\n",
        "            recent_alerts = [\n",
        "                alert for alert in alerts\n",
        "                if (datetime.datetime.now() - datetime.datetime.fromisoformat(alert['timestamp'])).total_seconds() < 86400\n",
        "            ]\n",
        "\n",
        "            if recent_alerts:\n",
        "                triggers['performance_degradation'] = True\n",
        "                logger.info(f\"Performance degradation trigger activated: {len(recent_alerts)} recent alerts\")\n",
        "\n",
        "    # Check for scheduled retraining trigger\n",
        "    # This would typically be a time-based check, e.g., quarterly\n",
        "    last_retrain_file = Path(\"models/last_retrain_date.txt\")\n",
        "    if last_retrain_file.exists():\n",
        "        with open(last_retrain_file, 'r') as f:\n",
        "            last_retrain_date = datetime.datetime.fromisoformat(f.read().strip())\n",
        "\n",
        "        # Check if it's been 90 days since last retraining\n",
        "        days_since_retrain = (datetime.datetime.now() - last_retrain_date).days\n",
        "        if days_since_retrain >= 90:\n",
        "            triggers['scheduled'] = True\n",
        "            logger.info(f\"Scheduled trigger activated: {days_since_retrain} days since last retraining\")\n",
        "    else:\n",
        "        # If no record exists, assume scheduled trigger\n",
        "        triggers['scheduled'] = True\n",
        "        logger.info(\"Scheduled trigger activated: No record of previous retraining\")\n",
        "\n",
        "    # Check for manual trigger\n",
        "    manual_trigger_file = Path(\"models/manual_retrain_trigger.txt\")\n",
        "    if manual_trigger_file.exists():\n",
        "        triggers['manual'] = True\n",
        "        logger.info(\"Manual trigger activated\")\n",
        "\n",
        "        # Remove the trigger file\n",
        "        manual_trigger_file.unlink()\n",
        "\n",
        "    # Determine if any trigger is activated\n",
        "    should_retrain = any(triggers.values())\n",
        "\n",
        "    trigger_info = {\n",
        "        'timestamp': datetime.datetime.now().isoformat(),\n",
        "        'triggers': triggers,\n",
        "        'should_retrain': should_retrain\n",
        "    }\n",
        "\n",
        "    # Save trigger information\n",
        "    trigger_dir = Path(\"models/retrain_triggers\")\n",
        "    trigger_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    with open(trigger_dir / f\"trigger_check_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\", 'w') as f:\n",
        "        json.dump(trigger_info, f, indent=2)\n",
        "\n",
        "    return should_retrain, trigger_info\n",
        "\n",
        "def prepare_training_data():\n",
        "    \\\"\\\"\\\"\n",
        "    Prepare data for model retraining\n",
        "\n",
        "    Returns:\n",
        "        data_path: Path to prepared training data\n",
        "        data_version: Version string for the data\n",
        "    \\\"\\\"\\\"\n",
        "    logger.info(\"Preparing training data\")\n",
        "\n",
        "    # Create data preparation directory\n",
        "    prep_dir = Path(\"data/retraining\")\n",
        "    prep_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # In a real system, this would likely:\n",
        "    # 1. Extract latest data from production database\n",
        "    # 2. Apply ETL processes\n",
        "    # 3. Join with historical data if appropriate\n",
        "    # 4. Apply feature engineering\n",
        "\n",
        "    # For this example, we'll simulate by copying the most recent data\n",
        "    features_dir = Path(\"data/features\")\n",
        "    if not features_dir.exists():\n",
        "        logger.error(\"Features directory does not exist\")\n",
        "        return None, None\n",
        "\n",
        "    # Find most recent feature file\n",
        "    feature_files = list(features_dir.glob(\"telco_features_*.csv\"))\n",
        "    if not feature_files:\n",
        "        logger.error(\"No feature files found\")\n",
        "        return None, None\n",
        "\n",
        "    latest_feature_file = max(feature_files, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "    # Create new data version\n",
        "    data_version = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    data_path = prep_dir / f\"training_data_{data_version}.csv\"\n",
        "\n",
        "    # Copy the data\n",
        "    import shutil\n",
        "    shutil.copy(latest_feature_file, data_path)\n",
        "\n",
        "    logger.info(f\"Training data prepared at {data_path}\")\n",
        "\n",
        "    return data_path, data_version\n",
        "\n",
        "def retrain_model(data_path, data_version):\n",
        "    \\\"\\\"\\\"\n",
        "    Retrain the model with new data\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to training data\n",
        "        data_version: Version string for the data\n",
        "\n",
        "    Returns:\n",
        "        model_info: Dictionary with model information\n",
        "    \\\"\\\"\\\"\n",
        "    logger.info(f\"Starting model retraining with data {data_path}\")\n",
        "\n",
        "    # In a real system, this would call the training pipeline directly\n",
        "    # Here we'll simulate by running a subprocess call to our training script\n",
        "\n",
        "    # Build command to run training script\n",
        "    cmd = [\n",
        "        sys.executable,  # Current Python interpreter\n",
        "        \"train_model.py\",  # Training script\n",
        "        \"--data\", str(data_path),\n",
        "        \"--version\", data_version\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Run the training process\n",
        "        logger.info(f\"Running command: {' '.join(cmd)}\")\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "\n",
        "        # Parse the output to get model info\n",
        "        output = result.stdout\n",
        "\n",
        "        # In a real system, the training script would return structured information\n",
        "        # Here we'll simulate by creating dummy model info\n",
        "        model_info = {\n",
        "            'status': 'success',\n",
        "            'model_version': f\"{data_version}_retrain\",\n",
        "            'data_version': data_version,\n",
        "            'training_time': str(datetime.timedelta(seconds=120)),  # Simulated\n",
        "            'metrics': {\n",
        "                'accuracy': 0.82,\n",
        "                'precision': 0.79,\n",
        "                'recall': 0.75,\n",
        "                'f1_score': 0.77,\n",
        "                'roc_auc': 0.85\n",
        "            },\n",
        "            'model_path': f\"models/telco_churn_predictor_v{data_version}_retrain.pkl\"\n",
        "        }\n",
        "\n",
        "        # In reality, this info would come from the training script output\n",
        "        logger.info(f\"Model retraining completed successfully: {model_info['model_path']}\")\n",
        "\n",
        "        # Update last retrain date\n",
        "        with open(\"models/last_retrain_date.txt\", 'w') as f:\n",
        "            f.write(datetime.datetime.now().isoformat())\n",
        "\n",
        "        return model_info\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        logger.error(f\"Model retraining failed: {e}\")\n",
        "        logger.error(f\"STDOUT: {e.stdout}\")\n",
        "        logger.error(f\"STDERR: {e.stderr}\")\n",
        "\n",
        "        return {\n",
        "            'status': 'failure',\n",
        "            'error': str(e),\n",
        "            'stdout': e.stdout,\n",
        "            'stderr': e.stderr\n",
        "        }\n",
        "\n",
        "def validate_retrained_model(model_info):\n",
        "    \\\"\\\"\\\"\n",
        "    Validate the retrained model before deployment\n",
        "\n",
        "    Args:\n",
        "        model_info: Dictionary with model information\n",
        "\n",
        "    Returns:\n",
        "        validation_results: Dictionary with validation results\n",
        "    \\\"\\\"\\\"\n",
        "    if model_info['status'] != 'success':\n",
        "        logger.error(\"Cannot validate failed model\")\n",
        "        return {'status': 'failure', 'reason': 'model_training_failed'}\n",
        "\n",
        "    logger.info(f\"Validating model {model_info['model_path']}\")\n",
        "\n",
        "    # In a real system, this would run a comprehensive validation suite\n",
        "    # Here we'll simulate validation checks\n",
        "\n",
        "    # Simulated validation results\n",
        "    validation_results = {\n",
        "        'status': 'success',\n",
        "        'timestamp': datetime.datetime.now().isoformat(),\n",
        "        'model_version': model_info['model_version'],\n",
        "        'data_version': model_info['data_version'],\n",
        "        'checks': {\n",
        "            'performance_check': True,\n",
        "            'bias_check': True,\n",
        "            'data_leakage_check': True,\n",
        "            'stability_check': True,\n",
        "            'prediction_distribution_check': True\n",
        "        },\n",
        "        'comparison': {\n",
        "            'baseline_version': 'current_production',\n",
        "            'baseline_f1': 0.74,  # Simulated\n",
        "            'new_f1': model_info['metrics']['f1_score'],\n",
        "            'improvement': model_info['metrics']['f1_score'] - 0.74\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Check if new model is better than baseline\n",
        "    if validation_results['comparison']['improvement'] <= 0:\n",
        "        validation_results['recommendation'] = 'reject'\n",
        "        validation_results['reason'] = 'no_improvement'\n",
        "        logger.warning(f\"Model validation failed: No improvement over baseline\")\n",
        "    else:\n",
        "        validation_results['recommendation'] = 'approve'\n",
        "        logger.info(f\"Model validation successful: Improvement of {validation_results['comparison']['improvement']:.4f} F1 score\")\n",
        "\n",
        "    # Save validation results\n",
        "    validation_dir = Path(\"models/validation_results\")\n",
        "    validation_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    with open(validation_dir / f\"validation_{model_info['model_version']}.json\", 'w') as f:\n",
        "        json.dump(validation_results, f, indent=2)\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "def notify_stakeholders(model_info, validation_results):\n",
        "    \\\"\\\"\\\"\n",
        "    Notify stakeholders about model retraining and validation\n",
        "\n",
        "    Args:\n",
        "        model_info: Dictionary with model information\n",
        "        validation_results: Dictionary with validation results\n",
        "    \\\"\\\"\\\"\n",
        "    # In a real system, this would send emails, Slack messages, etc.\n",
        "    # Here we'll just log the notification\n",
        "\n",
        "    if validation_results['recommendation'] == 'approve':\n",
        "        subject = f\"MODEL READY FOR REVIEW: New churn model v{model_info['model_version']}\"\n",
        "        message = f\\\"\\\"\\\"\n",
        "A new churn prediction model (v{model_info['model_version']}) has been trained and validated.\n",
        "\n",
        "Key information:\n",
        "- F1 Score: {model_info['metrics']['f1_score']:.4f} (previous: {validation_results['comparison']['baseline_f1']:.4f})\n",
        "- Improvement: {validation_results['comparison']['improvement']:.4f}\n",
        "- Data version: {model_info['data_version']}\n",
        "\n",
        "The model has passed all validation checks and is ready for review.\n",
        "Please review and approve the model for deployment.\n",
        "\n",
        "Model path: {model_info['model_path']}\n",
        "        \\\"\\\"\\\"\n",
        "    else:\n",
        "        subject = f\"MODEL TRAINING ALERT: Validation failed for v{model_info['model_version']}\"\n",
        "        message = f\\\"\\\"\\\"\n",
        "A new churn prediction model (v{model_info['model_version']}) has been trained but failed validation.\n",
        "\n",
        "Key information:\n",
        "- F1 Score: {model_info['metrics']['f1_score']:.4f} (previous: {validation_results['comparison']['baseline_f1']:.4f})\n",
        "- Change: {validation_results['comparison']['improvement']:.4f}\n",
        "- Data version: {model_info['data_version']}\n",
        "- Failure reason: {validation_results.get('reason', 'Unknown')}\n",
        "\n",
        "The model did not pass validation and requires manual review.\n",
        "\n",
        "Model path: {model_info['model_path']}\n",
        "        \\\"\\\"\\\"\n",
        "\n",
        "    logger.info(f\"Notification would be sent: {subject}\")\n",
        "    logger.info(message)\n",
        "\n",
        "    # Save notification\n",
        "    notifications_dir = Path(\"models/notifications\")\n",
        "    notifications_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    with open(notifications_dir / f\"notification_{model_info['model_version']}.txt\", 'w') as f:\n",
        "        f.write(f\"Subject: {subject}\\\\n\\\\n{message}\")\n",
        "\n",
        "def main():\n",
        "    \\\"\\\"\\\"Main retraining pipeline function\\\"\\\"\\\"\n",
        "    logger.info(\"Starting model retraining pipeline check\")\n",
        "\n",
        "    # Check if retraining should occur\n",
        "    should_retrain, trigger_info = check_retraining_triggers()\n",
        "\n",
        "    if not should_retrain:\n",
        "        logger.info(\"No retraining triggers activated. Exiting.\")\n",
        "        return\n",
        "\n",
        "    logger.info(f\"Retraining triggered by: {[k for k, v in trigger_info['triggers'].items() if v]}\")\n",
        "\n",
        "    # Prepare training data\n",
        "    data_path, data_version = prepare_training_data()\n",
        "    if data_path is None:\n",
        "        logger.error(\"Failed to prepare training data. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Retrain model\n",
        "    model_info = retrain_model(data_path, data_version)\n",
        "    if model_info['status'] != 'success':\n",
        "        logger.error(\"Model retraining failed. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Validate retrained model\n",
        "    validation_results = validate_retrained_model(model_info)\n",
        "\n",
        "    # Notify stakeholders\n",
        "    notify_stakeholders(model_info, validation_results)\n",
        "\n",
        "    logger.info(\"Retraining pipeline completed successfully\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\"\"\"\n",
        "\n",
        "    with open(improvement_dir / \"retraining_pipeline.py\", 'w') as f:\n",
        "        f.write(retraining_pipeline)\n",
        "    os.chmod(improvement_dir / \"retraining_pipeline.py\", 0o755)\n",
        "\n",
        "    print(f\"Continuous improvement process created in {improvement_dir}\")\n",
        "    return improvement_dir\n",
        "\n",
        "# Create continuous improvement process\n",
        "improvement_dir = create_continuous_improvement_process()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfx1NgU9ZbFu",
        "outputId": "faf5edc0-93b8-400e-a8ca-ba84f542b013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuous improvement process created in continuous_improvement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3 Create ML Ops Maturity Assessment"
      ],
      "metadata": {
        "id": "Kx_YGanFZhS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "def create_mlops_maturity_assessment() -> Path:\n",
        "    \"\"\"Generate the full MLOps maturityassessment framework:\n",
        "\n",
        "    * ``maturity_model.md``  descriptive maturity model\n",
        "    * ``assessment_questionnaire.md``  questionnaire template\n",
        "    * ``maturity_assessment.py``  executable scoring / reporting script\n",
        "\n",
        "    All files are written under ``maturity_assessment/``.\n",
        "    \"\"\"\n",
        "\n",
        "    assessment_dir = Path(\"maturity_assessment\")\n",
        "    assessment_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1. Maturity model markdown\n",
        "    # ------------------------------------------------------------------\n",
        "    maturity_model = \"\"\"# ML Ops Maturity Assessment Framework\n",
        "\n",
        "## Overview\n",
        "\n",
        "This framework provides a structured approach to assess and improve ML Ops maturity across the organization. It defines five maturity levels across six key dimensions of ML Ops practice.\n",
        "\n",
        "... (content unchanged for brevity  keep your full markdown here) ...\n",
        "\"\"\"\n",
        "    (assessment_dir / \"maturity_model.md\").write_text(maturity_model)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2. Questionnaire markdown (abridged here but include the full text)\n",
        "    # ------------------------------------------------------------------\n",
        "    assessment_questions = \"\"\"# ML Ops Maturity Assessment Questionnaire\n",
        "\n",
        "## Instructions\n",
        "- Answer each question based on current practices, not planned improvements\n",
        "... (rest of questionnaire markdown) ...\n",
        "\"\"\"\n",
        "    (assessment_dir / \"assessment_questionnaire.md\").write_text(assessment_questions)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3. Python scoring / reporting script\n",
        "    # ------------------------------------------------------------------\n",
        "    maturity_script = '''#!/usr/bin/env python3\n",
        "import json\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional libraries  comment out if unused\n",
        "import pandas as pd\n",
        "# import seaborn as sns  # not required but available\n",
        "\n",
        "##############################################################################\n",
        "# Utility functions\n",
        "##############################################################################\n",
        "\n",
        "def calculate_maturity_scores(responses):\n",
        "    \"\"\"Convert questionnaire responses to numeric scores and maturity levels.\"\"\"\n",
        "    response_values = {\n",
        "        \"Not Started\": 1,\n",
        "        \"Initial\": 2,\n",
        "        \"Defined\": 3,\n",
        "        \"Established\": 4,\n",
        "        \"Advanced\": 5,\n",
        "    }\n",
        "    dimensions = {\n",
        "        \"Data Management\": [\"1.1\", \"1.2\", \"1.3\", \"1.4\"],\n",
        "        \"Model Development\": [\"2.1\", \"2.2\", \"2.3\", \"2.4\"],\n",
        "        \"Deployment & Serving\": [\"3.1\", \"3.2\", \"3.3\", \"3.4\"],\n",
        "        \"Monitoring & Observability\": [\"4.1\", \"4.2\", \"4.3\", \"4.4\"],\n",
        "        \"Governance & Security\": [\"5.1\", \"5.2\", \"5.3\", \"5.4\"],\n",
        "        \"Infrastructure & Automation\": [\"6.1\", \"6.2\", \"6.3\"],\n",
        "    }\n",
        "\n",
        "    dim_scores = {}\n",
        "    all_scores = []\n",
        "    for dim, qs in dimensions.items():\n",
        "        scores = []\n",
        "        for q in qs:\n",
        "            val = responses.get(f\"Q{q}\")\n",
        "            if val in response_values:\n",
        "                scores.append(response_values[val])\n",
        "        dim_scores[dim] = np.mean(scores) if scores else 0\n",
        "        all_scores.extend(scores)\n",
        "\n",
        "    overall = np.mean(list(dim_scores.values())) if dim_scores else 0\n",
        "    levels = {\n",
        "        0: \"Not Assessed\",\n",
        "        1: \"Initial (Level 1)\",\n",
        "        2: \"Repeatable (Level 2)\",\n",
        "        3: \"Defined (Level 3)\",\n",
        "        4: \"Managed (Level 4)\",\n",
        "        5: \"Optimized (Level 5)\",\n",
        "    }\n",
        "    return {\n",
        "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "        \"dimensions\": {\n",
        "            d: {\"score\": s, \"level\": levels.get(round(s), \"Not Assessed\")} for d, s in dim_scores.items()\n",
        "        },\n",
        "        \"overall\": {\"score\": overall, \"level\": levels.get(round(overall), \"Not Assessed\")},\n",
        "    }\n",
        "\n",
        "\n",
        "def create_radar_chart(scores, out_file):\n",
        "    \"\"\"Save a radarchart PNG visualising dimension scores.\"\"\"\n",
        "    dims = list(scores[\"dimensions\"].keys())\n",
        "    vals = [scores[\"dimensions\"][d][\"score\"] for d in dims]\n",
        "    N = len(dims)\n",
        "    angles = [n / float(N) * 2 * np.pi for n in range(N)] + [0]\n",
        "    vals += vals[:1]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={\"polar\": True})\n",
        "    ax.plot(angles, vals, lw=2)\n",
        "    ax.fill(angles, vals, alpha=0.25)\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(dims)\n",
        "    ax.set_ylim(0, 5)\n",
        "    ax.set_yticks(range(1, 6))\n",
        "    ax.set_yticklabels([\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
        "    ax.set_title(\n",
        "        f\"ML Ops Maturity  Overall {scores['overall']['level']} ({scores['overall']['score']:.2f})\",\n",
        "        pad=20,\n",
        "    )\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(out_file)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def generate_report(scores, out_md):\n",
        "    \"\"\"Write a Markdown report summarising the assessment.\"\"\"\n",
        "    with open(out_md, \"w\") as fh:\n",
        "        fh.write(f\"# ML Ops Maturity Assessment Report\\n\\n\")\n",
        "        fh.write(f\"Date: {datetime.datetime.now().date()}\\n\\n\")\n",
        "        fh.write(\n",
        "            f\"Overall maturity: **{scores['overall']['level']}** (Score: {scores['overall']['score']:.2f})\\n\\n\"\n",
        "        )\n",
        "        fh.write(\"## Dimension breakdown\\n\")\n",
        "        for d, data in scores[\"dimensions\"].items():\n",
        "            fh.write(f\"* **{d}**  {data['level']} (Score: {data['score']:.2f})\\n\")\n",
        "        fh.write(\"\\n![Radar](maturity_radar.png)\\n\")\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# Demo entrypoint (can be removed in production)\n",
        "##############################################################################\n",
        "\n",
        "def main():\n",
        "    # Example hardcoded answers (replace with questionnaire responses)\n",
        "    answers = {f\"Q{i}.{j}\": \"Defined\" for i in range(1, 7) for j in range(1, 5)}\n",
        "    scores = calculate_maturity_scores(answers)\n",
        "    out_dir = Path(__file__).parent / \"results\"\n",
        "    out_dir.mkdir(exist_ok=True)\n",
        "    (out_dir / \"maturity_scores.json\").write_text(json.dumps(scores, indent=2))\n",
        "    create_radar_chart(scores, out_dir / \"maturity_radar.png\")\n",
        "    generate_report(scores, out_dir / \"assessment_report.md\")\n",
        "    print(\"Assessment complete  results in\", out_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "    script_path = assessment_dir / \"maturity_assessment.py\"\n",
        "    script_path.write_text(maturity_script)\n",
        "    os.chmod(script_path, 0o755)\n",
        "\n",
        "    print(\"Maturityassessment framework written to\", assessment_dir)\n",
        "    return assessment_dir\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_mlops_maturity_assessment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPeFnADmZiEl",
        "outputId": "09c96e94-833c-4270-df94-0859aff63ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maturityassessment framework written to maturity_assessment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Conclusion and Final Notes"
      ],
      "metadata": {
        "id": "VTkgTbExfemd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_final_notes():\n",
        "    \"\"\"\n",
        "    Create final notes and future directions document\n",
        "    \"\"\"\n",
        "    final_dir = Path(\"final_notes\")\n",
        "    final_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    final_notes = \"\"\"# ML Ops Technical Walkthrough: Conclusion and Future Directions\n",
        "\n",
        "## Summary of Completed Pipeline\n",
        "\n",
        "We have successfully implemented a complete ML Ops pipeline for a telco customer churn prediction use case, following industry best practices. The pipeline includes:\n",
        "\n",
        "1. **Data Intake & Feature Management**\n",
        "   - Data versioning and lineage tracking\n",
        "   - Data cleaning and validation\n",
        "   - Feature engineering and transformation\n",
        "   - Feature store for reusable features\n",
        "\n",
        "2. **Experimentation & Training**\n",
        "   - Experiment tracking with MLflow\n",
        "   - Reproducible training pipelines\n",
        "   - Model evaluation and comparison\n",
        "   - Model registry for versioning\n",
        "\n",
        "3. **Automated Validation (CI)**\n",
        "   - Validation test suite for ML components\n",
        "   - Feature pipeline validation\n",
        "   - Model prediction verification\n",
        "   - Lightweight retraining validation\n",
        "\n",
        "4. **Packaging & Continuous Delivery (CD)**\n",
        "   - Model packaging for deployment\n",
        "   - Flask API for model serving\n",
        "   - Blue-green deployment strategy\n",
        "   - Monitoring hooks setup\n",
        "\n",
        "5. **Production Monitoring & Observability**\n",
        "   - Performance metrics tracking\n",
        "   - Data drift detection\n",
        "   - Alerting and dashboarding\n",
        "   - Visualization of model behavior\n",
        "\n",
        "6. **Governance & Continuous Improvement**\n",
        "   - Model cards and documentation\n",
        "   - Ethics guidelines and governance framework\n",
        "   - Performance tracking and benchmarking\n",
        "   - Maturity assessment and improvement planning\n",
        "\n",
        "## Key Benefits of This Implementation\n",
        "\n",
        "- **Reproducibility**: All training runs are tracked and can be reproduced.\n",
        "- **Reliability**: Automated testing ensures model quality and stability.\n",
        "- **Velocity**: Streamlined pipeline allows faster iterations and deployments.\n",
        "- **Observability**: Comprehensive monitoring enables early issue detection.\n",
        "- **Governance**: Clear documentation and processes facilitate compliance.\n",
        "- **Scalability**: Modular design supports growth and additional models.\n",
        "\n",
        "## Limitations and Next Steps\n",
        "\n",
        "While this implementation demonstrates a complete ML Ops workflow, there are several areas for enhancement:\n",
        "\n",
        "### Limitations\n",
        "\n",
        "1. **Local Execution**: The current implementation runs locally and would need adaptation for cloud deployment.\n",
        "2. **Single Model Type**: The pipeline is tailored to RandomForest classification models and would need updates for deep learning.\n",
        "3. **Simplified Deployment**: The deployment strategy simulates blue-green deployment but doesn't implement actual infrastructure.\n",
        "4. **Basic Feature Store**: The feature store implementation is simplified using SQLite rather than a distributed system.\n",
        "5. **Limited Automated Testing**: The test suite could be expanded with more comprehensive tests.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Cloud Integration**\n",
        "   - Adapt pipeline for cloud deployment (AWS, Azure, or GCP)\n",
        "   - Implement cloud-native model registry and serving\n",
        "   - Use managed services for scaling and reliability\n",
        "\n",
        "2. **Extended Model Support**\n",
        "   - Add support for deep learning models\n",
        "   - Implement GPU/TPU training capabilities\n",
        "   - Add model compression for edge deployment\n",
        "\n",
        "3. **Enhanced Feature Engineering**\n",
        "   - Implement real-time feature pipelines\n",
        "   - Add feature selection and importance analysis\n",
        "   - Create feature-level monitoring\n",
        "\n",
        "4. **Advanced Monitoring**\n",
        "   - Implement explanations for model predictions\n",
        "   - Add model bias monitoring\n",
        "   - Create business impact metrics dashboard\n",
        "\n",
        "5. **Security Enhancements**\n",
        "   - Add authentication and authorization to APIs\n",
        "   - Implement model access audit logging\n",
        "   - Add data encryption throughout the pipeline\n",
        "\n",
        "6. **Pipeline Automation**\n",
        "   - Implement CI/CD for all pipeline components\n",
        "   - Create automated triggers for retraining\n",
        "   - Add workflow orchestration with Airflow or similar tool\n",
        "\n",
        "## Recommended Resources for Further Learning\n",
        "\n",
        "### Books\n",
        "- \"Building Machine Learning Pipelines\" by Hannes Hapke & Catherine Nelson\n",
        "- \"Practical MLOps\" by Noah Gift & Alfredo Deza\n",
        "- \"Machine Learning Engineering\" by Andriy Burkov\n",
        "\n",
        "### Courses\n",
        "- \"MLOps Specialization\" - DeepLearning.AI\n",
        "- \"Machine Learning Engineering for Production (MLOps)\" - Coursera\n",
        "- \"Deployment of Machine Learning Models\" - Udemy\n",
        "\n",
        "### Tools and Frameworks\n",
        "- Kubeflow - ML toolkit for Kubernetes\n",
        "- TFX (TensorFlow Extended) - End-to-end platform for deploying TensorFlow models\n",
        "- MLflow - Platform for managing ML lifecycle\n",
        "- Seldon Core - ML deployment on Kubernetes\n",
        "- Feast - Feature store for ML\n",
        "\n",
        "### Communities\n",
        "- MLOps Community\n",
        "- ML Engineers Slack group\n",
        "- DataTalks.Club\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This ML Ops pipeline implementation provides a foundation for reliable and scalable machine learning in production. By following the practices demonstrated here and leveraging the continuous improvement framework, organizations can progressively enhance their ML capabilities and deliver more value from their machine learning investments.\n",
        "\n",
        "Remember that ML Ops is not just about tools and technology, but also about processes and people. A successful ML Ops practice requires cross-functional collaboration between data scientists, engineers, and business stakeholders, supported by a culture of experimentation, learning, and continuous improvement.\n",
        "\"\"\"\n",
        "\n",
        "    with open(final_dir / \"conclusion_and_future_directions.md\", 'w') as f:\n",
        "        f.write(final_notes)\n",
        "\n",
        "    print(f\"Final notes created in {final_dir}\")\n",
        "    return final_dir\n",
        "\n",
        "# Create final notes\n",
        "final_dir = create_final_notes()\n",
        "\n",
        "print(\"\\nML Ops Technical Walkthrough complete!\")\n",
        "print(\"All sections have been implemented with executable code.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY8zhYtZgvAX",
        "outputId": "0e311485-72eb-4ee1-d960-715f950aabc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final notes created in final_notes\n",
            "\n",
            "ML Ops Technical Walkthrough complete!\n",
            "All sections have been implemented with executable code.\n"
          ]
        }
      ]
    }
  ]
}